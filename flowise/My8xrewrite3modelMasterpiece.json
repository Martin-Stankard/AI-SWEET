{
  "Tool": [],
  "ChatFlow": [
    {
      "id": "b025a56b-a4e6-4786-8fad-2200c64521c2",
      "name": "test001",
      "flowData": "{\n  \"nodes\": [\n    {\n      \"id\": \"chatOllama_0\",\n      \"position\": {\n        \"x\": -48.155947653638265,\n        \"y\": 187.9903546624563\n      },\n      \"type\": \"customNode\",\n      \"data\": {\n        \"id\": \"chatOllama_0\",\n        \"label\": \"ChatOllama\",\n        \"version\": 5,\n        \"name\": \"chatOllama\",\n        \"type\": \"ChatOllama\",\n        \"baseClasses\": [\n          \"ChatOllama\",\n          \"ChatOllama\",\n          \"BaseChatModel\",\n          \"BaseLanguageModel\",\n          \"Runnable\"\n        ],\n        \"category\": \"Chat Models\",\n        \"description\": \"Chat completion using open-source LLM on Ollama\",\n        \"inputParams\": [\n          {\n            \"label\": \"Base URL\",\n            \"name\": \"baseUrl\",\n            \"type\": \"string\",\n            \"default\": \"http://localhost:11434\",\n            \"id\": \"chatOllama_0-input-baseUrl-string\"\n          },\n          {\n            \"label\": \"Model Name\",\n            \"name\": \"modelName\",\n            \"type\": \"string\",\n            \"placeholder\": \"llama2\",\n            \"id\": \"chatOllama_0-input-modelName-string\"\n          },\n          {\n            \"label\": \"Temperature\",\n            \"name\": \"temperature\",\n            \"type\": \"number\",\n            \"description\": \"The temperature of the model. Increasing the temperature will make the model answer more creatively. (Default: 0.8). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 0.1,\n            \"default\": 0.9,\n            \"optional\": true,\n            \"id\": \"chatOllama_0-input-temperature-number\"\n          },\n          {\n            \"label\": \"Allow Image Uploads\",\n            \"name\": \"allowImageUploads\",\n            \"type\": \"boolean\",\n            \"description\": \"Allow image input. Refer to the <a href=\\\"https://docs.flowiseai.com/using-flowise/uploads#image\\\" target=\\\"_blank\\\">docs</a> for more details.\",\n            \"default\": false,\n            \"optional\": true,\n            \"id\": \"chatOllama_0-input-allowImageUploads-boolean\"\n          },\n          {\n            \"label\": \"Streaming\",\n            \"name\": \"streaming\",\n            \"type\": \"boolean\",\n            \"default\": true,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-streaming-boolean\"\n          },\n          {\n            \"label\": \"JSON Mode\",\n            \"name\": \"jsonMode\",\n            \"type\": \"boolean\",\n            \"description\": \"Coerces model outputs to only return JSON. Specify in the system prompt to return JSON. Ex: Format all responses as JSON object\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-jsonMode-boolean\"\n          },\n          {\n            \"label\": \"Keep Alive\",\n            \"name\": \"keepAlive\",\n            \"type\": \"string\",\n            \"description\": \"How long to keep connection alive. A duration string (such as \\\"10m\\\" or \\\"24h\\\")\",\n            \"default\": \"5m\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-keepAlive-string\"\n          },\n          {\n            \"label\": \"Top P\",\n            \"name\": \"topP\",\n            \"type\": \"number\",\n            \"description\": \"Works together with top-k. A higher value (e.g., 0.95) will lead to more diverse text, while a lower value (e.g., 0.5) will generate more focused and conservative text. (Default: 0.9). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 0.1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-topP-number\"\n          },\n          {\n            \"label\": \"Top K\",\n            \"name\": \"topK\",\n            \"type\": \"number\",\n            \"description\": \"Reduces the probability of generating nonsense. A higher value (e.g. 100) will give more diverse answers, while a lower value (e.g. 10) will be more conservative. (Default: 40). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-topK-number\"\n          },\n          {\n            \"label\": \"Mirostat\",\n            \"name\": \"mirostat\",\n            \"type\": \"number\",\n            \"description\": \"Enable Mirostat sampling for controlling perplexity. (default: 0, 0 = disabled, 1 = Mirostat, 2 = Mirostat 2.0). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-mirostat-number\"\n          },\n          {\n            \"label\": \"Mirostat ETA\",\n            \"name\": \"mirostatEta\",\n            \"type\": \"number\",\n            \"description\": \"Influences how quickly the algorithm responds to feedback from the generated text. A lower learning rate will result in slower adjustments, while a higher learning rate will make the algorithm more responsive. (Default: 0.1) Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 0.1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-mirostatEta-number\"\n          },\n          {\n            \"label\": \"Mirostat TAU\",\n            \"name\": \"mirostatTau\",\n            \"type\": \"number\",\n            \"description\": \"Controls the balance between coherence and diversity of the output. A lower value will result in more focused and coherent text. (Default: 5.0) Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 0.1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-mirostatTau-number\"\n          },\n          {\n            \"label\": \"Context Window Size\",\n            \"name\": \"numCtx\",\n            \"type\": \"number\",\n            \"description\": \"Sets the size of the context window used to generate the next token. (Default: 2048) Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-numCtx-number\"\n          },\n          {\n            \"label\": \"Number of GPU\",\n            \"name\": \"numGpu\",\n            \"type\": \"number\",\n            \"description\": \"The number of layers to send to the GPU(s). On macOS it defaults to 1 to enable metal support, 0 to disable. Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-numGpu-number\"\n          },\n          {\n            \"label\": \"Number of Thread\",\n            \"name\": \"numThread\",\n            \"type\": \"number\",\n            \"description\": \"Sets the number of threads to use during computation. By default, Ollama will detect this for optimal performance. It is recommended to set this value to the number of physical CPU cores your system has (as opposed to the logical number of cores). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-numThread-number\"\n          },\n          {\n            \"label\": \"Repeat Last N\",\n            \"name\": \"repeatLastN\",\n            \"type\": \"number\",\n            \"description\": \"Sets how far back for the model to look back to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-repeatLastN-number\"\n          },\n          {\n            \"label\": \"Repeat Penalty\",\n            \"name\": \"repeatPenalty\",\n            \"type\": \"number\",\n            \"description\": \"Sets how strongly to penalize repetitions. A higher value (e.g., 1.5) will penalize repetitions more strongly, while a lower value (e.g., 0.9) will be more lenient. (Default: 1.1). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 0.1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-repeatPenalty-number\"\n          },\n          {\n            \"label\": \"Stop Sequence\",\n            \"name\": \"stop\",\n            \"type\": \"string\",\n            \"rows\": 4,\n            \"placeholder\": \"AI assistant:\",\n            \"description\": \"Sets the stop sequences to use. Use comma to seperate different sequences. Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-stop-string\"\n          },\n          {\n            \"label\": \"Tail Free Sampling\",\n            \"name\": \"tfsZ\",\n            \"type\": \"number\",\n            \"description\": \"Tail free sampling is used to reduce the impact of less probable tokens from the output. A higher value (e.g., 2.0) will reduce the impact more, while a value of 1.0 disables this setting. (Default: 1). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 0.1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-tfsZ-number\"\n          }\n        ],\n        \"inputAnchors\": [\n          {\n            \"label\": \"Cache\",\n            \"name\": \"cache\",\n            \"type\": \"BaseCache\",\n            \"optional\": true,\n            \"id\": \"chatOllama_0-input-cache-BaseCache\"\n          }\n        ],\n        \"inputs\": {\n          \"cache\": \"\",\n          \"baseUrl\": \"http://host.docker.internal:11434\",\n          \"modelName\": \"llama3.2:latest\",\n          \"temperature\": 0.9,\n          \"allowImageUploads\": \"\",\n          \"streaming\": true,\n          \"jsonMode\": \"\",\n          \"keepAlive\": \"5m\",\n          \"topP\": \"\",\n          \"topK\": \"\",\n          \"mirostat\": \"\",\n          \"mirostatEta\": \"\",\n          \"mirostatTau\": \"\",\n          \"numCtx\": \"\",\n          \"numGpu\": \"\",\n          \"numThread\": \"\",\n          \"repeatLastN\": \"\",\n          \"repeatPenalty\": \"\",\n          \"stop\": \"\",\n          \"tfsZ\": \"\"\n        },\n        \"outputAnchors\": [\n          {\n            \"id\": \"chatOllama_0-output-chatOllama-ChatOllama|ChatOllama|BaseChatModel|BaseLanguageModel|Runnable\",\n            \"name\": \"chatOllama\",\n            \"label\": \"ChatOllama\",\n            \"description\": \"Chat completion using open-source LLM on Ollama\",\n            \"type\": \"ChatOllama | ChatOllama | BaseChatModel | BaseLanguageModel | Runnable\"\n          }\n        ],\n        \"outputs\": {},\n        \"selected\": false\n      },\n      \"width\": 300,\n      \"height\": 676,\n      \"selected\": false,\n      \"dragging\": false,\n      \"positionAbsolute\": {\n        \"x\": -48.155947653638265,\n        \"y\": 187.9903546624563\n      }\n    },\n    {\n      \"id\": \"bufferWindowMemory_0\",\n      \"position\": {\n        \"x\": 406.5952563937547,\n        \"y\": 470.71358541970403\n      },\n      \"type\": \"customNode\",\n      \"data\": {\n        \"id\": \"bufferWindowMemory_0\",\n        \"label\": \"Buffer Window Memory\",\n        \"version\": 2,\n        \"name\": \"bufferWindowMemory\",\n        \"type\": \"BufferWindowMemory\",\n        \"baseClasses\": [\n          \"BufferWindowMemory\",\n          \"BaseChatMemory\",\n          \"BaseMemory\"\n        ],\n        \"category\": \"Memory\",\n        \"description\": \"Uses a window of size k to surface the last k back-and-forth to use as memory\",\n        \"inputParams\": [\n          {\n            \"label\": \"Size\",\n            \"name\": \"k\",\n            \"type\": \"number\",\n            \"default\": \"4\",\n            \"description\": \"Window of size k to surface the last k back-and-forth to use as memory.\",\n            \"id\": \"bufferWindowMemory_0-input-k-number\"\n          },\n          {\n            \"label\": \"Session Id\",\n            \"name\": \"sessionId\",\n            \"type\": \"string\",\n            \"description\": \"If not specified, a random id will be used. Learn <a target=\\\"_blank\\\" href=\\\"https://docs.flowiseai.com/memory#ui-and-embedded-chat\\\">more</a>\",\n            \"default\": \"\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"bufferWindowMemory_0-input-sessionId-string\"\n          },\n          {\n            \"label\": \"Memory Key\",\n            \"name\": \"memoryKey\",\n            \"type\": \"string\",\n            \"default\": \"chat_history\",\n            \"additionalParams\": true,\n            \"id\": \"bufferWindowMemory_0-input-memoryKey-string\"\n          }\n        ],\n        \"inputAnchors\": [],\n        \"inputs\": {\n          \"k\": \"20\",\n          \"sessionId\": \"\",\n          \"memoryKey\": \"chat_history\"\n        },\n        \"outputAnchors\": [\n          {\n            \"id\": \"bufferWindowMemory_0-output-bufferWindowMemory-BufferWindowMemory|BaseChatMemory|BaseMemory\",\n            \"name\": \"bufferWindowMemory\",\n            \"label\": \"BufferWindowMemory\",\n            \"description\": \"Uses a window of size k to surface the last k back-and-forth to use as memory\",\n            \"type\": \"BufferWindowMemory | BaseChatMemory | BaseMemory\"\n          }\n        ],\n        \"outputs\": {},\n        \"selected\": false\n      },\n      \"width\": 300,\n      \"height\": 331,\n      \"selected\": false,\n      \"dragging\": false,\n      \"positionAbsolute\": {\n        \"x\": 406.5952563937547,\n        \"y\": 470.71358541970403\n      }\n    },\n    {\n      \"id\": \"calculator_0\",\n      \"position\": {\n        \"x\": 856.881418649058,\n        \"y\": 408.4825171663248\n      },\n      \"type\": \"customNode\",\n      \"data\": {\n        \"id\": \"calculator_0\",\n        \"label\": \"Calculator\",\n        \"version\": 1,\n        \"name\": \"calculator\",\n        \"type\": \"Calculator\",\n        \"baseClasses\": [\n          \"Calculator\",\n          \"Tool\",\n          \"StructuredTool\",\n          \"Runnable\"\n        ],\n        \"category\": \"Tools\",\n        \"description\": \"Perform calculations on response\",\n        \"inputParams\": [],\n        \"inputAnchors\": [],\n        \"inputs\": {},\n        \"outputAnchors\": [\n          {\n            \"id\": \"calculator_0-output-calculator-Calculator|Tool|StructuredTool|Runnable\",\n            \"name\": \"calculator\",\n            \"label\": \"Calculator\",\n            \"description\": \"Perform calculations on response\",\n            \"type\": \"Calculator | Tool | StructuredTool | Runnable\"\n          }\n        ],\n        \"outputs\": {},\n        \"selected\": false\n      },\n      \"width\": 300,\n      \"height\": 143,\n      \"positionAbsolute\": {\n        \"x\": 856.881418649058,\n        \"y\": 408.4825171663248\n      },\n      \"selected\": false\n    },\n    {\n      \"id\": \"toolAgent_0\",\n      \"position\": {\n        \"x\": 1478.8297281423434,\n        \"y\": 617.9847912536501\n      },\n      \"type\": \"customNode\",\n      \"data\": {\n        \"id\": \"toolAgent_0\",\n        \"label\": \"Tool Agent\",\n        \"version\": 2,\n        \"name\": \"toolAgent\",\n        \"type\": \"AgentExecutor\",\n        \"baseClasses\": [\n          \"AgentExecutor\",\n          \"BaseChain\",\n          \"Runnable\"\n        ],\n        \"category\": \"Agents\",\n        \"description\": \"Agent that uses Function Calling to pick the tools and args to call\",\n        \"inputParams\": [\n          {\n            \"label\": \"System Message\",\n            \"name\": \"systemMessage\",\n            \"type\": \"string\",\n            \"default\": \"You are a helpful AI assistant.\",\n            \"description\": \"If Chat Prompt Template is provided, this will be ignored\",\n            \"rows\": 4,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"toolAgent_0-input-systemMessage-string\"\n          },\n          {\n            \"label\": \"Max Iterations\",\n            \"name\": \"maxIterations\",\n            \"type\": \"number\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"toolAgent_0-input-maxIterations-number\"\n          }\n        ],\n        \"inputAnchors\": [\n          {\n            \"label\": \"Tools\",\n            \"name\": \"tools\",\n            \"type\": \"Tool\",\n            \"list\": true,\n            \"id\": \"toolAgent_0-input-tools-Tool\"\n          },\n          {\n            \"label\": \"Memory\",\n            \"name\": \"memory\",\n            \"type\": \"BaseChatMemory\",\n            \"id\": \"toolAgent_0-input-memory-BaseChatMemory\"\n          },\n          {\n            \"label\": \"Tool Calling Chat Model\",\n            \"name\": \"model\",\n            \"type\": \"BaseChatModel\",\n            \"description\": \"Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat\",\n            \"id\": \"toolAgent_0-input-model-BaseChatModel\"\n          },\n          {\n            \"label\": \"Chat Prompt Template\",\n            \"name\": \"chatPromptTemplate\",\n            \"type\": \"ChatPromptTemplate\",\n            \"description\": \"Override existing prompt with Chat Prompt Template. Human Message must includes {input} variable\",\n            \"optional\": true,\n            \"id\": \"toolAgent_0-input-chatPromptTemplate-ChatPromptTemplate\"\n          },\n          {\n            \"label\": \"Input Moderation\",\n            \"description\": \"Detect text that could generate harmful output and prevent it from being sent to the language model\",\n            \"name\": \"inputModeration\",\n            \"type\": \"Moderation\",\n            \"optional\": true,\n            \"list\": true,\n            \"id\": \"toolAgent_0-input-inputModeration-Moderation\"\n          }\n        ],\n        \"inputs\": {\n          \"tools\": [\n            \"{{calculator_0.data.instance}}\",\n            \"{{googleCustomSearch_0.data.instance}}\"\n          ],\n          \"memory\": \"{{bufferWindowMemory_0.data.instance}}\",\n          \"model\": \"{{chatOllama_0.data.instance}}\",\n          \"chatPromptTemplate\": \"\",\n          \"systemMessage\": \"You are a helpful AI assistant.\",\n          \"inputModeration\": \"\",\n          \"maxIterations\": \"\"\n        },\n        \"outputAnchors\": [\n          {\n            \"id\": \"toolAgent_0-output-toolAgent-AgentExecutor|BaseChain|Runnable\",\n            \"name\": \"toolAgent\",\n            \"label\": \"AgentExecutor\",\n            \"description\": \"Agent that uses Function Calling to pick the tools and args to call\",\n            \"type\": \"AgentExecutor | BaseChain | Runnable\"\n          }\n        ],\n        \"outputs\": {},\n        \"selected\": false\n      },\n      \"width\": 300,\n      \"height\": 486,\n      \"selected\": false,\n      \"positionAbsolute\": {\n        \"x\": 1478.8297281423434,\n        \"y\": 617.9847912536501\n      },\n      \"dragging\": false\n    },\n    {\n      \"id\": \"googleCustomSearch_0\",\n      \"position\": {\n        \"x\": 952.8378775520623,\n        \"y\": 62.07993028977239\n      },\n      \"type\": \"customNode\",\n      \"data\": {\n        \"id\": \"googleCustomSearch_0\",\n        \"label\": \"Google Custom Search\",\n        \"version\": 1,\n        \"name\": \"googleCustomSearch\",\n        \"type\": \"GoogleCustomSearchAPI\",\n        \"baseClasses\": [\n          \"GoogleCustomSearchAPI\",\n          \"Tool\",\n          \"StructuredTool\",\n          \"Runnable\"\n        ],\n        \"category\": \"Tools\",\n        \"description\": \"Wrapper around Google Custom Search API - a real-time API to access Google search results\",\n        \"inputParams\": [\n          {\n            \"label\": \"Connect Credential\",\n            \"name\": \"credential\",\n            \"type\": \"credential\",\n            \"credentialNames\": [\n              \"googleCustomSearchApi\"\n            ],\n            \"id\": \"googleCustomSearch_0-input-credential-credential\"\n          }\n        ],\n        \"inputAnchors\": [],\n        \"inputs\": {},\n        \"outputAnchors\": [\n          {\n            \"id\": \"googleCustomSearch_0-output-googleCustomSearch-GoogleCustomSearchAPI|Tool|StructuredTool|Runnable\",\n            \"name\": \"googleCustomSearch\",\n            \"label\": \"GoogleCustomSearchAPI\",\n            \"description\": \"Wrapper around Google Custom Search API - a real-time API to access Google search results\",\n            \"type\": \"GoogleCustomSearchAPI | Tool | StructuredTool | Runnable\"\n          }\n        ],\n        \"outputs\": {},\n        \"selected\": false\n      },\n      \"width\": 300,\n      \"height\": 276,\n      \"selected\": false,\n      \"positionAbsolute\": {\n        \"x\": 952.8378775520623,\n        \"y\": 62.07993028977239\n      },\n      \"dragging\": false\n    }\n  ],\n  \"edges\": [\n    {\n      \"source\": \"calculator_0\",\n      \"sourceHandle\": \"calculator_0-output-calculator-Calculator|Tool|StructuredTool|Runnable\",\n      \"target\": \"toolAgent_0\",\n      \"targetHandle\": \"toolAgent_0-input-tools-Tool\",\n      \"type\": \"buttonedge\",\n      \"id\": \"calculator_0-calculator_0-output-calculator-Calculator|Tool|StructuredTool|Runnable-toolAgent_0-toolAgent_0-input-tools-Tool\"\n    },\n    {\n      \"source\": \"chatOllama_0\",\n      \"sourceHandle\": \"chatOllama_0-output-chatOllama-ChatOllama|ChatOllama|BaseChatModel|BaseLanguageModel|Runnable\",\n      \"target\": \"toolAgent_0\",\n      \"targetHandle\": \"toolAgent_0-input-model-BaseChatModel\",\n      \"type\": \"buttonedge\",\n      \"id\": \"chatOllama_0-chatOllama_0-output-chatOllama-ChatOllama|ChatOllama|BaseChatModel|BaseLanguageModel|Runnable-toolAgent_0-toolAgent_0-input-model-BaseChatModel\"\n    },\n    {\n      \"source\": \"bufferWindowMemory_0\",\n      \"sourceHandle\": \"bufferWindowMemory_0-output-bufferWindowMemory-BufferWindowMemory|BaseChatMemory|BaseMemory\",\n      \"target\": \"toolAgent_0\",\n      \"targetHandle\": \"toolAgent_0-input-memory-BaseChatMemory\",\n      \"type\": \"buttonedge\",\n      \"id\": \"bufferWindowMemory_0-bufferWindowMemory_0-output-bufferWindowMemory-BufferWindowMemory|BaseChatMemory|BaseMemory-toolAgent_0-toolAgent_0-input-memory-BaseChatMemory\"\n    },\n    {\n      \"source\": \"googleCustomSearch_0\",\n      \"sourceHandle\": \"googleCustomSearch_0-output-googleCustomSearch-GoogleCustomSearchAPI|Tool|StructuredTool|Runnable\",\n      \"target\": \"toolAgent_0\",\n      \"targetHandle\": \"toolAgent_0-input-tools-Tool\",\n      \"type\": \"buttonedge\",\n      \"id\": \"googleCustomSearch_0-googleCustomSearch_0-output-googleCustomSearch-GoogleCustomSearchAPI|Tool|StructuredTool|Runnable-toolAgent_0-toolAgent_0-input-tools-Tool\"\n    }\n  ]\n}",
      "type": "CHATFLOW"
    },
    {
      "id": "1c52cb06-1128-42cb-8027-732684a6486d",
      "name": "docstore001",
      "flowData": "{\n  \"nodes\": [\n    {\n      \"id\": \"conversationalRetrievalQAChain_0\",\n      \"position\": {\n        \"x\": 1281.8162972627697,\n        \"y\": 33.59820622109811\n      },\n      \"type\": \"customNode\",\n      \"data\": {\n        \"id\": \"conversationalRetrievalQAChain_0\",\n        \"label\": \"Conversational Retrieval QA Chain\",\n        \"version\": 3,\n        \"name\": \"conversationalRetrievalQAChain\",\n        \"type\": \"ConversationalRetrievalQAChain\",\n        \"baseClasses\": [\n          \"ConversationalRetrievalQAChain\",\n          \"BaseChain\",\n          \"Runnable\"\n        ],\n        \"category\": \"Chains\",\n        \"description\": \"Document QA - built on RetrievalQAChain to provide a chat history component\",\n        \"inputParams\": [\n          {\n            \"label\": \"Return Source Documents\",\n            \"name\": \"returnSourceDocuments\",\n            \"type\": \"boolean\",\n            \"optional\": true,\n            \"id\": \"conversationalRetrievalQAChain_0-input-returnSourceDocuments-boolean\"\n          },\n          {\n            \"label\": \"Rephrase Prompt\",\n            \"name\": \"rephrasePrompt\",\n            \"type\": \"string\",\n            \"description\": \"Using previous chat history, rephrase question into a standalone question\",\n            \"warning\": \"Prompt must include input variables: {chat_history} and {question}\",\n            \"rows\": 4,\n            \"additionalParams\": true,\n            \"optional\": true,\n            \"default\": \"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone Question:\",\n            \"id\": \"conversationalRetrievalQAChain_0-input-rephrasePrompt-string\"\n          },\n          {\n            \"label\": \"Response Prompt\",\n            \"name\": \"responsePrompt\",\n            \"type\": \"string\",\n            \"description\": \"Taking the rephrased question, search for answer from the provided context\",\n            \"warning\": \"Prompt must include input variable: {context}\",\n            \"rows\": 4,\n            \"additionalParams\": true,\n            \"optional\": true,\n            \"default\": \"I want you to act as a document that I am having a conversation with. Your name is \\\"AI Assistant\\\". Using the provided context, answer the user's question to the best of your ability using the resources provided.\\nIf there is nothing in the context relevant to the question at hand, just say \\\"Hmm, I'm not sure\\\" and stop after that. Refuse to answer any question not about the info. Never break character.\\n------------\\n{context}\\n------------\\nREMEMBER: If there is no relevant information within the context, just say \\\"Hmm, I'm not sure\\\". Don't try to make up an answer. Never break character.\",\n            \"id\": \"conversationalRetrievalQAChain_0-input-responsePrompt-string\"\n          }\n        ],\n        \"inputAnchors\": [\n          {\n            \"label\": \"Chat Model\",\n            \"name\": \"model\",\n            \"type\": \"BaseChatModel\",\n            \"id\": \"conversationalRetrievalQAChain_0-input-model-BaseChatModel\"\n          },\n          {\n            \"label\": \"Vector Store Retriever\",\n            \"name\": \"vectorStoreRetriever\",\n            \"type\": \"BaseRetriever\",\n            \"id\": \"conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever\"\n          },\n          {\n            \"label\": \"Memory\",\n            \"name\": \"memory\",\n            \"type\": \"BaseMemory\",\n            \"optional\": true,\n            \"description\": \"If left empty, a default BufferMemory will be used\",\n            \"id\": \"conversationalRetrievalQAChain_0-input-memory-BaseMemory\"\n          },\n          {\n            \"label\": \"Input Moderation\",\n            \"description\": \"Detect text that could generate harmful output and prevent it from being sent to the language model\",\n            \"name\": \"inputModeration\",\n            \"type\": \"Moderation\",\n            \"optional\": true,\n            \"list\": true,\n            \"id\": \"conversationalRetrievalQAChain_0-input-inputModeration-Moderation\"\n          }\n        ],\n        \"inputs\": {\n          \"model\": \"{{chatOllama_0.data.instance}}\",\n          \"vectorStoreRetriever\": \"{{documentStoreVS_0.data.instance}}\",\n          \"memory\": \"\",\n          \"returnSourceDocuments\": \"\",\n          \"rephrasePrompt\": \"You are an AWESOME software engineer, technical writer, product manager, system engineer, cloud architect and engineer in test.\\n\\nChat History: {chat_history}\\n\\nUser question: {question}\\n\\nRewrite the question, better.\",\n          \"responsePrompt\": \"I want you to act as a document that I am having a conversation with. Your name is \\\"AI Assistant\\\". Using the provided context, answer the user's question to the best of your ability using the resources provided.\\nIf there is nothing in the context relevant to the question at hand, just say \\\"Hmm, I'm not sure\\\" and stop after that. Refuse to answer any question not about the info. Never break character.\\n------------\\n{context}\\n------------\\nREMEMBER: If there is no relevant information within the context, just say \\\"Hmm, I'm not sure, Possible RAG need\\\", then continue on with answering the question as if you are an AWESOME software engineer, technical writer, product manager, system engineer, cloud architect and engineer in test. \",\n          \"inputModeration\": \"\"\n        },\n        \"outputAnchors\": [\n          {\n            \"id\": \"conversationalRetrievalQAChain_0-output-conversationalRetrievalQAChain-ConversationalRetrievalQAChain|BaseChain|Runnable\",\n            \"name\": \"conversationalRetrievalQAChain\",\n            \"label\": \"ConversationalRetrievalQAChain\",\n            \"description\": \"Document QA - built on RetrievalQAChain to provide a chat history component\",\n            \"type\": \"ConversationalRetrievalQAChain | BaseChain | Runnable\"\n          }\n        ],\n        \"outputs\": {},\n        \"selected\": false\n      },\n      \"width\": 300,\n      \"height\": 532,\n      \"selected\": false,\n      \"positionAbsolute\": {\n        \"x\": 1281.8162972627697,\n        \"y\": 33.59820622109811\n      },\n      \"dragging\": false\n    },\n    {\n      \"id\": \"chatOllama_0\",\n      \"position\": {\n        \"x\": 421.4243944326728,\n        \"y\": -667.9602964837745\n      },\n      \"type\": \"customNode\",\n      \"data\": {\n        \"id\": \"chatOllama_0\",\n        \"label\": \"ChatOllama\",\n        \"version\": 5,\n        \"name\": \"chatOllama\",\n        \"type\": \"ChatOllama\",\n        \"baseClasses\": [\n          \"ChatOllama\",\n          \"ChatOllama\",\n          \"BaseChatModel\",\n          \"BaseLanguageModel\",\n          \"Runnable\"\n        ],\n        \"category\": \"Chat Models\",\n        \"description\": \"Chat completion using open-source LLM on Ollama\",\n        \"inputParams\": [\n          {\n            \"label\": \"Base URL\",\n            \"name\": \"baseUrl\",\n            \"type\": \"string\",\n            \"default\": \"http://localhost:11434\",\n            \"id\": \"chatOllama_0-input-baseUrl-string\"\n          },\n          {\n            \"label\": \"Model Name\",\n            \"name\": \"modelName\",\n            \"type\": \"string\",\n            \"placeholder\": \"llama2\",\n            \"id\": \"chatOllama_0-input-modelName-string\"\n          },\n          {\n            \"label\": \"Temperature\",\n            \"name\": \"temperature\",\n            \"type\": \"number\",\n            \"description\": \"The temperature of the model. Increasing the temperature will make the model answer more creatively. (Default: 0.8). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 0.1,\n            \"default\": 0.9,\n            \"optional\": true,\n            \"id\": \"chatOllama_0-input-temperature-number\"\n          },\n          {\n            \"label\": \"Allow Image Uploads\",\n            \"name\": \"allowImageUploads\",\n            \"type\": \"boolean\",\n            \"description\": \"Allow image input. Refer to the <a href=\\\"https://docs.flowiseai.com/using-flowise/uploads#image\\\" target=\\\"_blank\\\">docs</a> for more details.\",\n            \"default\": false,\n            \"optional\": true,\n            \"id\": \"chatOllama_0-input-allowImageUploads-boolean\"\n          },\n          {\n            \"label\": \"Streaming\",\n            \"name\": \"streaming\",\n            \"type\": \"boolean\",\n            \"default\": true,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-streaming-boolean\"\n          },\n          {\n            \"label\": \"JSON Mode\",\n            \"name\": \"jsonMode\",\n            \"type\": \"boolean\",\n            \"description\": \"Coerces model outputs to only return JSON. Specify in the system prompt to return JSON. Ex: Format all responses as JSON object\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-jsonMode-boolean\"\n          },\n          {\n            \"label\": \"Keep Alive\",\n            \"name\": \"keepAlive\",\n            \"type\": \"string\",\n            \"description\": \"How long to keep connection alive. A duration string (such as \\\"10m\\\" or \\\"24h\\\")\",\n            \"default\": \"5m\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-keepAlive-string\"\n          },\n          {\n            \"label\": \"Top P\",\n            \"name\": \"topP\",\n            \"type\": \"number\",\n            \"description\": \"Works together with top-k. A higher value (e.g., 0.95) will lead to more diverse text, while a lower value (e.g., 0.5) will generate more focused and conservative text. (Default: 0.9). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 0.1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-topP-number\"\n          },\n          {\n            \"label\": \"Top K\",\n            \"name\": \"topK\",\n            \"type\": \"number\",\n            \"description\": \"Reduces the probability of generating nonsense. A higher value (e.g. 100) will give more diverse answers, while a lower value (e.g. 10) will be more conservative. (Default: 40). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-topK-number\"\n          },\n          {\n            \"label\": \"Mirostat\",\n            \"name\": \"mirostat\",\n            \"type\": \"number\",\n            \"description\": \"Enable Mirostat sampling for controlling perplexity. (default: 0, 0 = disabled, 1 = Mirostat, 2 = Mirostat 2.0). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-mirostat-number\"\n          },\n          {\n            \"label\": \"Mirostat ETA\",\n            \"name\": \"mirostatEta\",\n            \"type\": \"number\",\n            \"description\": \"Influences how quickly the algorithm responds to feedback from the generated text. A lower learning rate will result in slower adjustments, while a higher learning rate will make the algorithm more responsive. (Default: 0.1) Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 0.1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-mirostatEta-number\"\n          },\n          {\n            \"label\": \"Mirostat TAU\",\n            \"name\": \"mirostatTau\",\n            \"type\": \"number\",\n            \"description\": \"Controls the balance between coherence and diversity of the output. A lower value will result in more focused and coherent text. (Default: 5.0) Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 0.1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-mirostatTau-number\"\n          },\n          {\n            \"label\": \"Context Window Size\",\n            \"name\": \"numCtx\",\n            \"type\": \"number\",\n            \"description\": \"Sets the size of the context window used to generate the next token. (Default: 2048) Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-numCtx-number\"\n          },\n          {\n            \"label\": \"Number of GPU\",\n            \"name\": \"numGpu\",\n            \"type\": \"number\",\n            \"description\": \"The number of layers to send to the GPU(s). On macOS it defaults to 1 to enable metal support, 0 to disable. Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-numGpu-number\"\n          },\n          {\n            \"label\": \"Number of Thread\",\n            \"name\": \"numThread\",\n            \"type\": \"number\",\n            \"description\": \"Sets the number of threads to use during computation. By default, Ollama will detect this for optimal performance. It is recommended to set this value to the number of physical CPU cores your system has (as opposed to the logical number of cores). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-numThread-number\"\n          },\n          {\n            \"label\": \"Repeat Last N\",\n            \"name\": \"repeatLastN\",\n            \"type\": \"number\",\n            \"description\": \"Sets how far back for the model to look back to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-repeatLastN-number\"\n          },\n          {\n            \"label\": \"Repeat Penalty\",\n            \"name\": \"repeatPenalty\",\n            \"type\": \"number\",\n            \"description\": \"Sets how strongly to penalize repetitions. A higher value (e.g., 1.5) will penalize repetitions more strongly, while a lower value (e.g., 0.9) will be more lenient. (Default: 1.1). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 0.1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-repeatPenalty-number\"\n          },\n          {\n            \"label\": \"Stop Sequence\",\n            \"name\": \"stop\",\n            \"type\": \"string\",\n            \"rows\": 4,\n            \"placeholder\": \"AI assistant:\",\n            \"description\": \"Sets the stop sequences to use. Use comma to seperate different sequences. Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-stop-string\"\n          },\n          {\n            \"label\": \"Tail Free Sampling\",\n            \"name\": \"tfsZ\",\n            \"type\": \"number\",\n            \"description\": \"Tail free sampling is used to reduce the impact of less probable tokens from the output. A higher value (e.g., 2.0) will reduce the impact more, while a value of 1.0 disables this setting. (Default: 1). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 0.1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-tfsZ-number\"\n          }\n        ],\n        \"inputAnchors\": [\n          {\n            \"label\": \"Cache\",\n            \"name\": \"cache\",\n            \"type\": \"BaseCache\",\n            \"optional\": true,\n            \"id\": \"chatOllama_0-input-cache-BaseCache\"\n          }\n        ],\n        \"inputs\": {\n          \"cache\": \"\",\n          \"baseUrl\": \"http://host.docker.internal:11434\",\n          \"modelName\": \"llama3.2:latest\",\n          \"temperature\": \"0.2\",\n          \"allowImageUploads\": \"\",\n          \"streaming\": true,\n          \"jsonMode\": \"\",\n          \"keepAlive\": \"5m\",\n          \"topP\": \"\",\n          \"topK\": \"\",\n          \"mirostat\": \"\",\n          \"mirostatEta\": \"\",\n          \"mirostatTau\": \"\",\n          \"numCtx\": \"\",\n          \"numGpu\": \"\",\n          \"numThread\": \"\",\n          \"repeatLastN\": \"\",\n          \"repeatPenalty\": \"\",\n          \"stop\": \"\",\n          \"tfsZ\": \"\"\n        },\n        \"outputAnchors\": [\n          {\n            \"id\": \"chatOllama_0-output-chatOllama-ChatOllama|ChatOllama|BaseChatModel|BaseLanguageModel|Runnable\",\n            \"name\": \"chatOllama\",\n            \"label\": \"ChatOllama\",\n            \"description\": \"Chat completion using open-source LLM on Ollama\",\n            \"type\": \"ChatOllama | ChatOllama | BaseChatModel | BaseLanguageModel | Runnable\"\n          }\n        ],\n        \"outputs\": {},\n        \"selected\": false\n      },\n      \"width\": 300,\n      \"height\": 676,\n      \"selected\": false,\n      \"positionAbsolute\": {\n        \"x\": 421.4243944326728,\n        \"y\": -667.9602964837745\n      },\n      \"dragging\": false\n    },\n    {\n      \"id\": \"documentStoreVS_0\",\n      \"position\": {\n        \"x\": -347.06150570448796,\n        \"y\": -62.40405044568408\n      },\n      \"type\": \"customNode\",\n      \"data\": {\n        \"id\": \"documentStoreVS_0\",\n        \"label\": \"Document Store (Vector)\",\n        \"version\": 1,\n        \"name\": \"documentStoreVS\",\n        \"type\": \"DocumentStoreVS\",\n        \"baseClasses\": [\n          \"DocumentStoreVS\"\n        ],\n        \"category\": \"Vector Stores\",\n        \"description\": \"Search and retrieve documents from Document Store\",\n        \"inputParams\": [\n          {\n            \"label\": \"Select Store\",\n            \"name\": \"selectedStore\",\n            \"type\": \"asyncOptions\",\n            \"loadMethod\": \"listStores\",\n            \"id\": \"documentStoreVS_0-input-selectedStore-asyncOptions\"\n          }\n        ],\n        \"inputAnchors\": [],\n        \"inputs\": {\n          \"selectedStore\": \"648c8e18-ad10-4f84-be38-616aef8ab904\"\n        },\n        \"outputAnchors\": [\n          {\n            \"name\": \"output\",\n            \"label\": \"Output\",\n            \"type\": \"options\",\n            \"description\": \"\",\n            \"options\": [\n              {\n                \"id\": \"documentStoreVS_0-output-retriever-BaseRetriever\",\n                \"name\": \"retriever\",\n                \"label\": \"Retriever\",\n                \"description\": \"\",\n                \"type\": \"BaseRetriever\"\n              },\n              {\n                \"id\": \"documentStoreVS_0-output-vectorStore-VectorStore\",\n                \"name\": \"vectorStore\",\n                \"label\": \"Vector Store\",\n                \"description\": \"\",\n                \"type\": \"VectorStore\"\n              }\n            ],\n            \"default\": \"retriever\"\n          }\n        ],\n        \"outputs\": {\n          \"output\": \"retriever\"\n        },\n        \"selected\": false\n      },\n      \"width\": 300,\n      \"height\": 312,\n      \"selected\": false,\n      \"positionAbsolute\": {\n        \"x\": -347.06150570448796,\n        \"y\": -62.40405044568408\n      },\n      \"dragging\": false\n    }\n  ],\n  \"edges\": [\n    {\n      \"source\": \"chatOllama_0\",\n      \"sourceHandle\": \"chatOllama_0-output-chatOllama-ChatOllama|ChatOllama|BaseChatModel|BaseLanguageModel|Runnable\",\n      \"target\": \"conversationalRetrievalQAChain_0\",\n      \"targetHandle\": \"conversationalRetrievalQAChain_0-input-model-BaseChatModel\",\n      \"type\": \"buttonedge\",\n      \"id\": \"chatOllama_0-chatOllama_0-output-chatOllama-ChatOllama|ChatOllama|BaseChatModel|BaseLanguageModel|Runnable-conversationalRetrievalQAChain_0-conversationalRetrievalQAChain_0-input-model-BaseChatModel\"\n    },\n    {\n      \"source\": \"documentStoreVS_0\",\n      \"sourceHandle\": \"documentStoreVS_0-output-retriever-BaseRetriever\",\n      \"target\": \"conversationalRetrievalQAChain_0\",\n      \"targetHandle\": \"conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever\",\n      \"type\": \"buttonedge\",\n      \"id\": \"documentStoreVS_0-documentStoreVS_0-output-retriever-BaseRetriever-conversationalRetrievalQAChain_0-conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever\"\n    }\n  ]\n}",
      "type": "CHATFLOW"
    }
  ],
  "AgentFlow": [
    {
      "id": "ce952be3-a702-4545-b333-9e8da35f63a7",
      "name": "rewrite it 8 times with RAG and 3 models",
      "flowData": "{\n  \"nodes\": [\n    {\n      \"id\": \"seqStart_0\",\n      \"position\": {\n        \"x\": 1332.0550069950223,\n        \"y\": -677.7969453102942\n      },\n      \"type\": \"customNode\",\n      \"data\": {\n        \"id\": \"seqStart_0\",\n        \"label\": \"Start\",\n        \"version\": 2,\n        \"name\": \"seqStart\",\n        \"type\": \"Start\",\n        \"baseClasses\": [\n          \"Start\"\n        ],\n        \"category\": \"Sequential Agents\",\n        \"description\": \"Starting point of the conversation\",\n        \"inputParams\": [],\n        \"inputAnchors\": [\n          {\n            \"label\": \"Chat Model\",\n            \"name\": \"model\",\n            \"type\": \"BaseChatModel\",\n            \"description\": \"Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat\",\n            \"id\": \"seqStart_0-input-model-BaseChatModel\"\n          },\n          {\n            \"label\": \"Agent Memory\",\n            \"name\": \"agentMemory\",\n            \"type\": \"BaseCheckpointSaver\",\n            \"description\": \"Save the state of the agent\",\n            \"optional\": true,\n            \"id\": \"seqStart_0-input-agentMemory-BaseCheckpointSaver\"\n          },\n          {\n            \"label\": \"State\",\n            \"name\": \"state\",\n            \"type\": \"State\",\n            \"description\": \"State is an object that is updated by nodes in the graph, passing from one node to another. By default, state contains \\\"messages\\\" that got updated with each message sent and received.\",\n            \"optional\": true,\n            \"id\": \"seqStart_0-input-state-State\"\n          },\n          {\n            \"label\": \"Input Moderation\",\n            \"description\": \"Detect text that could generate harmful output and prevent it from being sent to the language model\",\n            \"name\": \"inputModeration\",\n            \"type\": \"Moderation\",\n            \"optional\": true,\n            \"list\": true,\n            \"id\": \"seqStart_0-input-inputModeration-Moderation\"\n          }\n        ],\n        \"inputs\": {\n          \"model\": \"{{chatOllama_0.data.instance}}\",\n          \"agentMemory\": \"{{postgresAgentMemory_0.data.instance}}\",\n          \"state\": \"{{seqState_0.data.instance}}\",\n          \"inputModeration\": \"\"\n        },\n        \"outputAnchors\": [\n          {\n            \"id\": \"seqStart_0-output-seqStart-Start\",\n            \"name\": \"seqStart\",\n            \"label\": \"Start\",\n            \"description\": \"Starting point of the conversation\",\n            \"type\": \"Start\"\n          }\n        ],\n        \"outputs\": {},\n        \"selected\": false\n      },\n      \"width\": 300,\n      \"height\": 383,\n      \"selected\": false,\n      \"positionAbsolute\": {\n        \"x\": 1332.0550069950223,\n        \"y\": -677.7969453102942\n      },\n      \"dragging\": false\n    },\n    {\n      \"id\": \"chatOllama_0\",\n      \"position\": {\n        \"x\": 730.0065959001012,\n        \"y\": -1209.5312156105783\n      },\n      \"type\": \"customNode\",\n      \"data\": {\n        \"id\": \"chatOllama_0\",\n        \"label\": \"ChatOllama\",\n        \"version\": 5,\n        \"name\": \"chatOllama\",\n        \"type\": \"ChatOllama\",\n        \"baseClasses\": [\n          \"ChatOllama\",\n          \"ChatOllama\",\n          \"BaseChatModel\",\n          \"BaseLanguageModel\",\n          \"Runnable\"\n        ],\n        \"category\": \"Chat Models\",\n        \"description\": \"Chat completion using open-source LLM on Ollama\",\n        \"inputParams\": [\n          {\n            \"label\": \"Base URL\",\n            \"name\": \"baseUrl\",\n            \"type\": \"string\",\n            \"default\": \"http://localhost:11434\",\n            \"id\": \"chatOllama_0-input-baseUrl-string\"\n          },\n          {\n            \"label\": \"Model Name\",\n            \"name\": \"modelName\",\n            \"type\": \"string\",\n            \"placeholder\": \"llama2\",\n            \"id\": \"chatOllama_0-input-modelName-string\"\n          },\n          {\n            \"label\": \"Temperature\",\n            \"name\": \"temperature\",\n            \"type\": \"number\",\n            \"description\": \"The temperature of the model. Increasing the temperature will make the model answer more creatively. (Default: 0.8). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 0.1,\n            \"default\": 0.9,\n            \"optional\": true,\n            \"id\": \"chatOllama_0-input-temperature-number\"\n          },\n          {\n            \"label\": \"Allow Image Uploads\",\n            \"name\": \"allowImageUploads\",\n            \"type\": \"boolean\",\n            \"description\": \"Allow image input. Refer to the <a href=\\\"https://docs.flowiseai.com/using-flowise/uploads#image\\\" target=\\\"_blank\\\">docs</a> for more details.\",\n            \"default\": false,\n            \"optional\": true,\n            \"id\": \"chatOllama_0-input-allowImageUploads-boolean\"\n          },\n          {\n            \"label\": \"Streaming\",\n            \"name\": \"streaming\",\n            \"type\": \"boolean\",\n            \"default\": true,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-streaming-boolean\"\n          },\n          {\n            \"label\": \"JSON Mode\",\n            \"name\": \"jsonMode\",\n            \"type\": \"boolean\",\n            \"description\": \"Coerces model outputs to only return JSON. Specify in the system prompt to return JSON. Ex: Format all responses as JSON object\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-jsonMode-boolean\"\n          },\n          {\n            \"label\": \"Keep Alive\",\n            \"name\": \"keepAlive\",\n            \"type\": \"string\",\n            \"description\": \"How long to keep connection alive. A duration string (such as \\\"10m\\\" or \\\"24h\\\")\",\n            \"default\": \"5m\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-keepAlive-string\"\n          },\n          {\n            \"label\": \"Top P\",\n            \"name\": \"topP\",\n            \"type\": \"number\",\n            \"description\": \"Works together with top-k. A higher value (e.g., 0.95) will lead to more diverse text, while a lower value (e.g., 0.5) will generate more focused and conservative text. (Default: 0.9). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 0.1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-topP-number\"\n          },\n          {\n            \"label\": \"Top K\",\n            \"name\": \"topK\",\n            \"type\": \"number\",\n            \"description\": \"Reduces the probability of generating nonsense. A higher value (e.g. 100) will give more diverse answers, while a lower value (e.g. 10) will be more conservative. (Default: 40). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-topK-number\"\n          },\n          {\n            \"label\": \"Mirostat\",\n            \"name\": \"mirostat\",\n            \"type\": \"number\",\n            \"description\": \"Enable Mirostat sampling for controlling perplexity. (default: 0, 0 = disabled, 1 = Mirostat, 2 = Mirostat 2.0). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-mirostat-number\"\n          },\n          {\n            \"label\": \"Mirostat ETA\",\n            \"name\": \"mirostatEta\",\n            \"type\": \"number\",\n            \"description\": \"Influences how quickly the algorithm responds to feedback from the generated text. A lower learning rate will result in slower adjustments, while a higher learning rate will make the algorithm more responsive. (Default: 0.1) Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 0.1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-mirostatEta-number\"\n          },\n          {\n            \"label\": \"Mirostat TAU\",\n            \"name\": \"mirostatTau\",\n            \"type\": \"number\",\n            \"description\": \"Controls the balance between coherence and diversity of the output. A lower value will result in more focused and coherent text. (Default: 5.0) Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 0.1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-mirostatTau-number\"\n          },\n          {\n            \"label\": \"Context Window Size\",\n            \"name\": \"numCtx\",\n            \"type\": \"number\",\n            \"description\": \"Sets the size of the context window used to generate the next token. (Default: 2048) Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-numCtx-number\"\n          },\n          {\n            \"label\": \"Number of GPU\",\n            \"name\": \"numGpu\",\n            \"type\": \"number\",\n            \"description\": \"The number of layers to send to the GPU(s). On macOS it defaults to 1 to enable metal support, 0 to disable. Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-numGpu-number\"\n          },\n          {\n            \"label\": \"Number of Thread\",\n            \"name\": \"numThread\",\n            \"type\": \"number\",\n            \"description\": \"Sets the number of threads to use during computation. By default, Ollama will detect this for optimal performance. It is recommended to set this value to the number of physical CPU cores your system has (as opposed to the logical number of cores). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-numThread-number\"\n          },\n          {\n            \"label\": \"Repeat Last N\",\n            \"name\": \"repeatLastN\",\n            \"type\": \"number\",\n            \"description\": \"Sets how far back for the model to look back to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-repeatLastN-number\"\n          },\n          {\n            \"label\": \"Repeat Penalty\",\n            \"name\": \"repeatPenalty\",\n            \"type\": \"number\",\n            \"description\": \"Sets how strongly to penalize repetitions. A higher value (e.g., 1.5) will penalize repetitions more strongly, while a lower value (e.g., 0.9) will be more lenient. (Default: 1.1). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 0.1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-repeatPenalty-number\"\n          },\n          {\n            \"label\": \"Stop Sequence\",\n            \"name\": \"stop\",\n            \"type\": \"string\",\n            \"rows\": 4,\n            \"placeholder\": \"AI assistant:\",\n            \"description\": \"Sets the stop sequences to use. Use comma to seperate different sequences. Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-stop-string\"\n          },\n          {\n            \"label\": \"Tail Free Sampling\",\n            \"name\": \"tfsZ\",\n            \"type\": \"number\",\n            \"description\": \"Tail free sampling is used to reduce the impact of less probable tokens from the output. A higher value (e.g., 2.0) will reduce the impact more, while a value of 1.0 disables this setting. (Default: 1). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 0.1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_0-input-tfsZ-number\"\n          }\n        ],\n        \"inputAnchors\": [\n          {\n            \"label\": \"Cache\",\n            \"name\": \"cache\",\n            \"type\": \"BaseCache\",\n            \"optional\": true,\n            \"id\": \"chatOllama_0-input-cache-BaseCache\"\n          }\n        ],\n        \"inputs\": {\n          \"cache\": \"\",\n          \"baseUrl\": \"http://host.docker.internal:11434\",\n          \"modelName\": \"llama3.2:latest\",\n          \"temperature\": 0.9,\n          \"allowImageUploads\": \"\",\n          \"streaming\": true,\n          \"jsonMode\": \"\",\n          \"keepAlive\": \"5m\",\n          \"topP\": \"\",\n          \"topK\": \"\",\n          \"mirostat\": \"\",\n          \"mirostatEta\": \"\",\n          \"mirostatTau\": \"\",\n          \"numCtx\": \"\",\n          \"numGpu\": \"\",\n          \"numThread\": \"\",\n          \"repeatLastN\": \"\",\n          \"repeatPenalty\": \"\",\n          \"stop\": \"\",\n          \"tfsZ\": \"\"\n        },\n        \"outputAnchors\": [\n          {\n            \"id\": \"chatOllama_0-output-chatOllama-ChatOllama|ChatOllama|BaseChatModel|BaseLanguageModel|Runnable\",\n            \"name\": \"chatOllama\",\n            \"label\": \"ChatOllama\",\n            \"description\": \"Chat completion using open-source LLM on Ollama\",\n            \"type\": \"ChatOllama | ChatOllama | BaseChatModel | BaseLanguageModel | Runnable\"\n          }\n        ],\n        \"outputs\": {},\n        \"selected\": false\n      },\n      \"width\": 300,\n      \"height\": 676,\n      \"selected\": false,\n      \"positionAbsolute\": {\n        \"x\": 730.0065959001012,\n        \"y\": -1209.5312156105783\n      },\n      \"dragging\": false\n    },\n    {\n      \"id\": \"seqEnd_0\",\n      \"position\": {\n        \"x\": 7050.3032847285485,\n        \"y\": -619.9612733159985\n      },\n      \"type\": \"customNode\",\n      \"data\": {\n        \"id\": \"seqEnd_0\",\n        \"label\": \"End\",\n        \"version\": 2,\n        \"name\": \"seqEnd\",\n        \"type\": \"End\",\n        \"baseClasses\": [\n          \"End\"\n        ],\n        \"category\": \"Sequential Agents\",\n        \"description\": \"End conversation\",\n        \"inputParams\": [],\n        \"inputAnchors\": [\n          {\n            \"label\": \"Agent | Condition | LLM | Tool Node\",\n            \"name\": \"sequentialNode\",\n            \"type\": \"Agent | Condition | LLMNode | ToolNode\",\n            \"id\": \"seqEnd_0-input-sequentialNode-Agent | Condition | LLMNode | ToolNode\"\n          }\n        ],\n        \"inputs\": {\n          \"sequentialNode\": \"{{seqAgent_7.data.instance}}\"\n        },\n        \"outputAnchors\": [],\n        \"outputs\": {},\n        \"selected\": false\n      },\n      \"width\": 300,\n      \"height\": 143,\n      \"positionAbsolute\": {\n        \"x\": 7050.3032847285485,\n        \"y\": -619.9612733159985\n      },\n      \"selected\": false,\n      \"dragging\": false\n    },\n    {\n      \"id\": \"postgresAgentMemory_0\",\n      \"position\": {\n        \"x\": 259.45825252089674,\n        \"y\": -1115.5249288995713\n      },\n      \"type\": \"customNode\",\n      \"data\": {\n        \"id\": \"postgresAgentMemory_0\",\n        \"label\": \"Postgres Agent Memory\",\n        \"version\": 1,\n        \"name\": \"postgresAgentMemory\",\n        \"type\": \"AgentMemory\",\n        \"baseClasses\": [\n          \"AgentMemory\",\n          \"BaseCheckpointSaver\"\n        ],\n        \"category\": \"Memory\",\n        \"description\": \"Memory for agentflow to remember the state of the conversation using Postgres database\",\n        \"inputParams\": [\n          {\n            \"label\": \"Connect Credential\",\n            \"name\": \"credential\",\n            \"type\": \"credential\",\n            \"credentialNames\": [\n              \"PostgresApi\"\n            ],\n            \"optional\": true,\n            \"id\": \"postgresAgentMemory_0-input-credential-credential\"\n          },\n          {\n            \"label\": \"Host\",\n            \"name\": \"host\",\n            \"type\": \"string\",\n            \"id\": \"postgresAgentMemory_0-input-host-string\"\n          },\n          {\n            \"label\": \"Database\",\n            \"name\": \"database\",\n            \"type\": \"string\",\n            \"id\": \"postgresAgentMemory_0-input-database-string\"\n          },\n          {\n            \"label\": \"Port\",\n            \"name\": \"port\",\n            \"type\": \"number\",\n            \"default\": \"5432\",\n            \"id\": \"postgresAgentMemory_0-input-port-number\"\n          },\n          {\n            \"label\": \"Additional Connection Configuration\",\n            \"name\": \"additionalConfig\",\n            \"type\": \"json\",\n            \"additionalParams\": true,\n            \"optional\": true,\n            \"id\": \"postgresAgentMemory_0-input-additionalConfig-json\"\n          }\n        ],\n        \"inputAnchors\": [],\n        \"inputs\": {\n          \"host\": \"host.docker.internal\",\n          \"database\": \"flowiserecords\",\n          \"port\": \"5432\",\n          \"additionalConfig\": \"\"\n        },\n        \"outputAnchors\": [\n          {\n            \"id\": \"postgresAgentMemory_0-output-postgresAgentMemory-AgentMemory|BaseCheckpointSaver\",\n            \"name\": \"postgresAgentMemory\",\n            \"label\": \"AgentMemory\",\n            \"description\": \"Memory for agentflow to remember the state of the conversation using Postgres database\",\n            \"type\": \"AgentMemory | BaseCheckpointSaver\"\n          }\n        ],\n        \"outputs\": {},\n        \"selected\": false\n      },\n      \"width\": 300,\n      \"height\": 625,\n      \"selected\": false,\n      \"positionAbsolute\": {\n        \"x\": 259.45825252089674,\n        \"y\": -1115.5249288995713\n      },\n      \"dragging\": false\n    },\n    {\n      \"id\": \"documentStoreVS_0\",\n      \"position\": {\n        \"x\": 1737.8206882566978,\n        \"y\": -2378.207527352746\n      },\n      \"type\": \"customNode\",\n      \"data\": {\n        \"id\": \"documentStoreVS_0\",\n        \"label\": \"Document Store (Vector)\",\n        \"version\": 1,\n        \"name\": \"documentStoreVS\",\n        \"type\": \"DocumentStoreVS\",\n        \"baseClasses\": [\n          \"DocumentStoreVS\"\n        ],\n        \"category\": \"Vector Stores\",\n        \"description\": \"Search and retrieve documents from Document Store\",\n        \"inputParams\": [\n          {\n            \"label\": \"Select Store\",\n            \"name\": \"selectedStore\",\n            \"type\": \"asyncOptions\",\n            \"loadMethod\": \"listStores\",\n            \"id\": \"documentStoreVS_0-input-selectedStore-asyncOptions\"\n          }\n        ],\n        \"inputAnchors\": [],\n        \"inputs\": {\n          \"selectedStore\": \"648c8e18-ad10-4f84-be38-616aef8ab904\"\n        },\n        \"outputAnchors\": [\n          {\n            \"name\": \"output\",\n            \"label\": \"Output\",\n            \"type\": \"options\",\n            \"description\": \"\",\n            \"options\": [\n              {\n                \"id\": \"documentStoreVS_0-output-retriever-BaseRetriever\",\n                \"name\": \"retriever\",\n                \"label\": \"Retriever\",\n                \"description\": \"\",\n                \"type\": \"BaseRetriever\"\n              },\n              {\n                \"id\": \"documentStoreVS_0-output-vectorStore-VectorStore\",\n                \"name\": \"vectorStore\",\n                \"label\": \"Vector Store\",\n                \"description\": \"\",\n                \"type\": \"VectorStore\"\n              }\n            ],\n            \"default\": \"retriever\"\n          }\n        ],\n        \"outputs\": {\n          \"output\": \"retriever\"\n        },\n        \"selected\": false\n      },\n      \"width\": 300,\n      \"height\": 312,\n      \"selected\": false,\n      \"dragging\": false,\n      \"positionAbsolute\": {\n        \"x\": 1737.8206882566978,\n        \"y\": -2378.207527352746\n      }\n    },\n    {\n      \"id\": \"chatOllama_1\",\n      \"position\": {\n        \"x\": 1319.8073705647666,\n        \"y\": 376.48864237819873\n      },\n      \"type\": \"customNode\",\n      \"data\": {\n        \"id\": \"chatOllama_1\",\n        \"label\": \"ChatOllama\",\n        \"version\": 5,\n        \"name\": \"chatOllama\",\n        \"type\": \"ChatOllama\",\n        \"baseClasses\": [\n          \"ChatOllama\",\n          \"ChatOllama\",\n          \"BaseChatModel\",\n          \"BaseLanguageModel\",\n          \"Runnable\"\n        ],\n        \"category\": \"Chat Models\",\n        \"description\": \"Chat completion using open-source LLM on Ollama\",\n        \"inputParams\": [\n          {\n            \"label\": \"Base URL\",\n            \"name\": \"baseUrl\",\n            \"type\": \"string\",\n            \"default\": \"http://localhost:11434\",\n            \"id\": \"chatOllama_1-input-baseUrl-string\"\n          },\n          {\n            \"label\": \"Model Name\",\n            \"name\": \"modelName\",\n            \"type\": \"string\",\n            \"placeholder\": \"llama2\",\n            \"id\": \"chatOllama_1-input-modelName-string\"\n          },\n          {\n            \"label\": \"Temperature\",\n            \"name\": \"temperature\",\n            \"type\": \"number\",\n            \"description\": \"The temperature of the model. Increasing the temperature will make the model answer more creatively. (Default: 0.8). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 0.1,\n            \"default\": 0.9,\n            \"optional\": true,\n            \"id\": \"chatOllama_1-input-temperature-number\"\n          },\n          {\n            \"label\": \"Allow Image Uploads\",\n            \"name\": \"allowImageUploads\",\n            \"type\": \"boolean\",\n            \"description\": \"Allow image input. Refer to the <a href=\\\"https://docs.flowiseai.com/using-flowise/uploads#image\\\" target=\\\"_blank\\\">docs</a> for more details.\",\n            \"default\": false,\n            \"optional\": true,\n            \"id\": \"chatOllama_1-input-allowImageUploads-boolean\"\n          },\n          {\n            \"label\": \"Streaming\",\n            \"name\": \"streaming\",\n            \"type\": \"boolean\",\n            \"default\": true,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_1-input-streaming-boolean\"\n          },\n          {\n            \"label\": \"JSON Mode\",\n            \"name\": \"jsonMode\",\n            \"type\": \"boolean\",\n            \"description\": \"Coerces model outputs to only return JSON. Specify in the system prompt to return JSON. Ex: Format all responses as JSON object\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_1-input-jsonMode-boolean\"\n          },\n          {\n            \"label\": \"Keep Alive\",\n            \"name\": \"keepAlive\",\n            \"type\": \"string\",\n            \"description\": \"How long to keep connection alive. A duration string (such as \\\"10m\\\" or \\\"24h\\\")\",\n            \"default\": \"5m\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_1-input-keepAlive-string\"\n          },\n          {\n            \"label\": \"Top P\",\n            \"name\": \"topP\",\n            \"type\": \"number\",\n            \"description\": \"Works together with top-k. A higher value (e.g., 0.95) will lead to more diverse text, while a lower value (e.g., 0.5) will generate more focused and conservative text. (Default: 0.9). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 0.1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_1-input-topP-number\"\n          },\n          {\n            \"label\": \"Top K\",\n            \"name\": \"topK\",\n            \"type\": \"number\",\n            \"description\": \"Reduces the probability of generating nonsense. A higher value (e.g. 100) will give more diverse answers, while a lower value (e.g. 10) will be more conservative. (Default: 40). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_1-input-topK-number\"\n          },\n          {\n            \"label\": \"Mirostat\",\n            \"name\": \"mirostat\",\n            \"type\": \"number\",\n            \"description\": \"Enable Mirostat sampling for controlling perplexity. (default: 0, 0 = disabled, 1 = Mirostat, 2 = Mirostat 2.0). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_1-input-mirostat-number\"\n          },\n          {\n            \"label\": \"Mirostat ETA\",\n            \"name\": \"mirostatEta\",\n            \"type\": \"number\",\n            \"description\": \"Influences how quickly the algorithm responds to feedback from the generated text. A lower learning rate will result in slower adjustments, while a higher learning rate will make the algorithm more responsive. (Default: 0.1) Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 0.1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_1-input-mirostatEta-number\"\n          },\n          {\n            \"label\": \"Mirostat TAU\",\n            \"name\": \"mirostatTau\",\n            \"type\": \"number\",\n            \"description\": \"Controls the balance between coherence and diversity of the output. A lower value will result in more focused and coherent text. (Default: 5.0) Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 0.1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_1-input-mirostatTau-number\"\n          },\n          {\n            \"label\": \"Context Window Size\",\n            \"name\": \"numCtx\",\n            \"type\": \"number\",\n            \"description\": \"Sets the size of the context window used to generate the next token. (Default: 2048) Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_1-input-numCtx-number\"\n          },\n          {\n            \"label\": \"Number of GPU\",\n            \"name\": \"numGpu\",\n            \"type\": \"number\",\n            \"description\": \"The number of layers to send to the GPU(s). On macOS it defaults to 1 to enable metal support, 0 to disable. Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_1-input-numGpu-number\"\n          },\n          {\n            \"label\": \"Number of Thread\",\n            \"name\": \"numThread\",\n            \"type\": \"number\",\n            \"description\": \"Sets the number of threads to use during computation. By default, Ollama will detect this for optimal performance. It is recommended to set this value to the number of physical CPU cores your system has (as opposed to the logical number of cores). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_1-input-numThread-number\"\n          },\n          {\n            \"label\": \"Repeat Last N\",\n            \"name\": \"repeatLastN\",\n            \"type\": \"number\",\n            \"description\": \"Sets how far back for the model to look back to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_1-input-repeatLastN-number\"\n          },\n          {\n            \"label\": \"Repeat Penalty\",\n            \"name\": \"repeatPenalty\",\n            \"type\": \"number\",\n            \"description\": \"Sets how strongly to penalize repetitions. A higher value (e.g., 1.5) will penalize repetitions more strongly, while a lower value (e.g., 0.9) will be more lenient. (Default: 1.1). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 0.1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_1-input-repeatPenalty-number\"\n          },\n          {\n            \"label\": \"Stop Sequence\",\n            \"name\": \"stop\",\n            \"type\": \"string\",\n            \"rows\": 4,\n            \"placeholder\": \"AI assistant:\",\n            \"description\": \"Sets the stop sequences to use. Use comma to seperate different sequences. Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_1-input-stop-string\"\n          },\n          {\n            \"label\": \"Tail Free Sampling\",\n            \"name\": \"tfsZ\",\n            \"type\": \"number\",\n            \"description\": \"Tail free sampling is used to reduce the impact of less probable tokens from the output. A higher value (e.g., 2.0) will reduce the impact more, while a value of 1.0 disables this setting. (Default: 1). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 0.1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_1-input-tfsZ-number\"\n          }\n        ],\n        \"inputAnchors\": [\n          {\n            \"label\": \"Cache\",\n            \"name\": \"cache\",\n            \"type\": \"BaseCache\",\n            \"optional\": true,\n            \"id\": \"chatOllama_1-input-cache-BaseCache\"\n          }\n        ],\n        \"inputs\": {\n          \"cache\": \"\",\n          \"baseUrl\": \"http://host.docker.internal:11434\",\n          \"modelName\": \"gemma:latest\",\n          \"temperature\": 0.9,\n          \"allowImageUploads\": \"\",\n          \"streaming\": true,\n          \"jsonMode\": \"\",\n          \"keepAlive\": \"5m\",\n          \"topP\": \"\",\n          \"topK\": \"\",\n          \"mirostat\": \"\",\n          \"mirostatEta\": \"\",\n          \"mirostatTau\": \"\",\n          \"numCtx\": \"\",\n          \"numGpu\": \"\",\n          \"numThread\": \"\",\n          \"repeatLastN\": \"\",\n          \"repeatPenalty\": \"\",\n          \"stop\": \"\",\n          \"tfsZ\": \"\"\n        },\n        \"outputAnchors\": [\n          {\n            \"id\": \"chatOllama_1-output-chatOllama-ChatOllama|ChatOllama|BaseChatModel|BaseLanguageModel|Runnable\",\n            \"name\": \"chatOllama\",\n            \"label\": \"ChatOllama\",\n            \"description\": \"Chat completion using open-source LLM on Ollama\",\n            \"type\": \"ChatOllama | ChatOllama | BaseChatModel | BaseLanguageModel | Runnable\"\n          }\n        ],\n        \"outputs\": {},\n        \"selected\": false\n      },\n      \"width\": 300,\n      \"height\": 676,\n      \"selected\": false,\n      \"positionAbsolute\": {\n        \"x\": 1319.8073705647666,\n        \"y\": 376.48864237819873\n      },\n      \"dragging\": false\n    },\n    {\n      \"id\": \"chatOllama_2\",\n      \"position\": {\n        \"x\": 942.603826427905,\n        \"y\": 363.8030392303813\n      },\n      \"type\": \"customNode\",\n      \"data\": {\n        \"id\": \"chatOllama_2\",\n        \"label\": \"ChatOllama\",\n        \"version\": 5,\n        \"name\": \"chatOllama\",\n        \"type\": \"ChatOllama\",\n        \"baseClasses\": [\n          \"ChatOllama\",\n          \"ChatOllama\",\n          \"BaseChatModel\",\n          \"BaseLanguageModel\",\n          \"Runnable\"\n        ],\n        \"category\": \"Chat Models\",\n        \"description\": \"Chat completion using open-source LLM on Ollama\",\n        \"inputParams\": [\n          {\n            \"label\": \"Base URL\",\n            \"name\": \"baseUrl\",\n            \"type\": \"string\",\n            \"default\": \"http://localhost:11434\",\n            \"id\": \"chatOllama_2-input-baseUrl-string\"\n          },\n          {\n            \"label\": \"Model Name\",\n            \"name\": \"modelName\",\n            \"type\": \"string\",\n            \"placeholder\": \"llama2\",\n            \"id\": \"chatOllama_2-input-modelName-string\"\n          },\n          {\n            \"label\": \"Temperature\",\n            \"name\": \"temperature\",\n            \"type\": \"number\",\n            \"description\": \"The temperature of the model. Increasing the temperature will make the model answer more creatively. (Default: 0.8). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 0.1,\n            \"default\": 0.9,\n            \"optional\": true,\n            \"id\": \"chatOllama_2-input-temperature-number\"\n          },\n          {\n            \"label\": \"Allow Image Uploads\",\n            \"name\": \"allowImageUploads\",\n            \"type\": \"boolean\",\n            \"description\": \"Allow image input. Refer to the <a href=\\\"https://docs.flowiseai.com/using-flowise/uploads#image\\\" target=\\\"_blank\\\">docs</a> for more details.\",\n            \"default\": false,\n            \"optional\": true,\n            \"id\": \"chatOllama_2-input-allowImageUploads-boolean\"\n          },\n          {\n            \"label\": \"Streaming\",\n            \"name\": \"streaming\",\n            \"type\": \"boolean\",\n            \"default\": true,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_2-input-streaming-boolean\"\n          },\n          {\n            \"label\": \"JSON Mode\",\n            \"name\": \"jsonMode\",\n            \"type\": \"boolean\",\n            \"description\": \"Coerces model outputs to only return JSON. Specify in the system prompt to return JSON. Ex: Format all responses as JSON object\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_2-input-jsonMode-boolean\"\n          },\n          {\n            \"label\": \"Keep Alive\",\n            \"name\": \"keepAlive\",\n            \"type\": \"string\",\n            \"description\": \"How long to keep connection alive. A duration string (such as \\\"10m\\\" or \\\"24h\\\")\",\n            \"default\": \"5m\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_2-input-keepAlive-string\"\n          },\n          {\n            \"label\": \"Top P\",\n            \"name\": \"topP\",\n            \"type\": \"number\",\n            \"description\": \"Works together with top-k. A higher value (e.g., 0.95) will lead to more diverse text, while a lower value (e.g., 0.5) will generate more focused and conservative text. (Default: 0.9). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 0.1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_2-input-topP-number\"\n          },\n          {\n            \"label\": \"Top K\",\n            \"name\": \"topK\",\n            \"type\": \"number\",\n            \"description\": \"Reduces the probability of generating nonsense. A higher value (e.g. 100) will give more diverse answers, while a lower value (e.g. 10) will be more conservative. (Default: 40). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_2-input-topK-number\"\n          },\n          {\n            \"label\": \"Mirostat\",\n            \"name\": \"mirostat\",\n            \"type\": \"number\",\n            \"description\": \"Enable Mirostat sampling for controlling perplexity. (default: 0, 0 = disabled, 1 = Mirostat, 2 = Mirostat 2.0). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_2-input-mirostat-number\"\n          },\n          {\n            \"label\": \"Mirostat ETA\",\n            \"name\": \"mirostatEta\",\n            \"type\": \"number\",\n            \"description\": \"Influences how quickly the algorithm responds to feedback from the generated text. A lower learning rate will result in slower adjustments, while a higher learning rate will make the algorithm more responsive. (Default: 0.1) Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 0.1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_2-input-mirostatEta-number\"\n          },\n          {\n            \"label\": \"Mirostat TAU\",\n            \"name\": \"mirostatTau\",\n            \"type\": \"number\",\n            \"description\": \"Controls the balance between coherence and diversity of the output. A lower value will result in more focused and coherent text. (Default: 5.0) Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 0.1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_2-input-mirostatTau-number\"\n          },\n          {\n            \"label\": \"Context Window Size\",\n            \"name\": \"numCtx\",\n            \"type\": \"number\",\n            \"description\": \"Sets the size of the context window used to generate the next token. (Default: 2048) Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_2-input-numCtx-number\"\n          },\n          {\n            \"label\": \"Number of GPU\",\n            \"name\": \"numGpu\",\n            \"type\": \"number\",\n            \"description\": \"The number of layers to send to the GPU(s). On macOS it defaults to 1 to enable metal support, 0 to disable. Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_2-input-numGpu-number\"\n          },\n          {\n            \"label\": \"Number of Thread\",\n            \"name\": \"numThread\",\n            \"type\": \"number\",\n            \"description\": \"Sets the number of threads to use during computation. By default, Ollama will detect this for optimal performance. It is recommended to set this value to the number of physical CPU cores your system has (as opposed to the logical number of cores). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_2-input-numThread-number\"\n          },\n          {\n            \"label\": \"Repeat Last N\",\n            \"name\": \"repeatLastN\",\n            \"type\": \"number\",\n            \"description\": \"Sets how far back for the model to look back to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_2-input-repeatLastN-number\"\n          },\n          {\n            \"label\": \"Repeat Penalty\",\n            \"name\": \"repeatPenalty\",\n            \"type\": \"number\",\n            \"description\": \"Sets how strongly to penalize repetitions. A higher value (e.g., 1.5) will penalize repetitions more strongly, while a lower value (e.g., 0.9) will be more lenient. (Default: 1.1). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 0.1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_2-input-repeatPenalty-number\"\n          },\n          {\n            \"label\": \"Stop Sequence\",\n            \"name\": \"stop\",\n            \"type\": \"string\",\n            \"rows\": 4,\n            \"placeholder\": \"AI assistant:\",\n            \"description\": \"Sets the stop sequences to use. Use comma to seperate different sequences. Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_2-input-stop-string\"\n          },\n          {\n            \"label\": \"Tail Free Sampling\",\n            \"name\": \"tfsZ\",\n            \"type\": \"number\",\n            \"description\": \"Tail free sampling is used to reduce the impact of less probable tokens from the output. A higher value (e.g., 2.0) will reduce the impact more, while a value of 1.0 disables this setting. (Default: 1). Refer to <a target=\\\"_blank\\\" href=\\\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\\\">docs</a> for more details\",\n            \"step\": 0.1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOllama_2-input-tfsZ-number\"\n          }\n        ],\n        \"inputAnchors\": [\n          {\n            \"label\": \"Cache\",\n            \"name\": \"cache\",\n            \"type\": \"BaseCache\",\n            \"optional\": true,\n            \"id\": \"chatOllama_2-input-cache-BaseCache\"\n          }\n        ],\n        \"inputs\": {\n          \"cache\": \"\",\n          \"baseUrl\": \"http://host.docker.internal:11434\",\n          \"modelName\": \"mistral:latest\",\n          \"temperature\": 0.9,\n          \"allowImageUploads\": \"\",\n          \"streaming\": true,\n          \"jsonMode\": \"\",\n          \"keepAlive\": \"5m\",\n          \"topP\": \"\",\n          \"topK\": \"\",\n          \"mirostat\": \"\",\n          \"mirostatEta\": \"\",\n          \"mirostatTau\": \"\",\n          \"numCtx\": \"\",\n          \"numGpu\": \"\",\n          \"numThread\": \"\",\n          \"repeatLastN\": \"\",\n          \"repeatPenalty\": \"\",\n          \"stop\": \"\",\n          \"tfsZ\": \"\"\n        },\n        \"outputAnchors\": [\n          {\n            \"id\": \"chatOllama_2-output-chatOllama-ChatOllama|ChatOllama|BaseChatModel|BaseLanguageModel|Runnable\",\n            \"name\": \"chatOllama\",\n            \"label\": \"ChatOllama\",\n            \"description\": \"Chat completion using open-source LLM on Ollama\",\n            \"type\": \"ChatOllama | ChatOllama | BaseChatModel | BaseLanguageModel | Runnable\"\n          }\n        ],\n        \"outputs\": {},\n        \"selected\": false\n      },\n      \"width\": 300,\n      \"height\": 676,\n      \"selected\": false,\n      \"positionAbsolute\": {\n        \"x\": 942.603826427905,\n        \"y\": 363.8030392303813\n      },\n      \"dragging\": false\n    },\n    {\n      \"id\": \"retrieverTool_0\",\n      \"position\": {\n        \"x\": 2622.311205430048,\n        \"y\": -2101.042821808064\n      },\n      \"type\": \"customNode\",\n      \"data\": {\n        \"id\": \"retrieverTool_0\",\n        \"label\": \"Retriever Tool\",\n        \"version\": 3,\n        \"name\": \"retrieverTool\",\n        \"type\": \"RetrieverTool\",\n        \"baseClasses\": [\n          \"RetrieverTool\",\n          \"DynamicTool\",\n          \"Tool\",\n          \"StructuredTool\",\n          \"Runnable\"\n        ],\n        \"category\": \"Tools\",\n        \"description\": \"Use a retriever as allowed tool for agent\",\n        \"inputParams\": [\n          {\n            \"label\": \"Retriever Name\",\n            \"name\": \"name\",\n            \"type\": \"string\",\n            \"placeholder\": \"search_state_of_union\",\n            \"id\": \"retrieverTool_0-input-name-string\"\n          },\n          {\n            \"label\": \"Retriever Description\",\n            \"name\": \"description\",\n            \"type\": \"string\",\n            \"description\": \"When should agent uses to retrieve documents\",\n            \"rows\": 3,\n            \"placeholder\": \"Searches and returns documents regarding the state-of-the-union.\",\n            \"id\": \"retrieverTool_0-input-description-string\"\n          },\n          {\n            \"label\": \"Return Source Documents\",\n            \"name\": \"returnSourceDocuments\",\n            \"type\": \"boolean\",\n            \"optional\": true,\n            \"id\": \"retrieverTool_0-input-returnSourceDocuments-boolean\"\n          },\n          {\n            \"label\": \"Additional Metadata Filter\",\n            \"name\": \"retrieverToolMetadataFilter\",\n            \"type\": \"json\",\n            \"description\": \"Add additional metadata filter on top of the existing filter from vector store\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"hint\": {\n              \"label\": \"What can you filter?\",\n              \"value\": \"Add additional filters to vector store. You can also filter with flow config, including the current \\\"state\\\":\\n- `$flow.sessionId`\\n- `$flow.chatId`\\n- `$flow.chatflowId`\\n- `$flow.input`\\n- `$flow.state`\\n\"\n            },\n            \"id\": \"retrieverTool_0-input-retrieverToolMetadataFilter-json\"\n          }\n        ],\n        \"inputAnchors\": [\n          {\n            \"label\": \"Retriever\",\n            \"name\": \"retriever\",\n            \"type\": \"BaseRetriever\",\n            \"id\": \"retrieverTool_0-input-retriever-BaseRetriever\"\n          }\n        ],\n        \"inputs\": {\n          \"name\": \"raggin\",\n          \"description\": \"Searches and retrieves information about software development.\",\n          \"retriever\": \"{{documentStoreVS_0.data.instance}}\",\n          \"returnSourceDocuments\": \"\",\n          \"retrieverToolMetadataFilter\": \"\"\n        },\n        \"outputAnchors\": [\n          {\n            \"id\": \"retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable\",\n            \"name\": \"retrieverTool\",\n            \"label\": \"RetrieverTool\",\n            \"description\": \"Use a retriever as allowed tool for agent\",\n            \"type\": \"RetrieverTool | DynamicTool | Tool | StructuredTool | Runnable\"\n          }\n        ],\n        \"outputs\": {},\n        \"selected\": false\n      },\n      \"width\": 300,\n      \"height\": 656,\n      \"selected\": false,\n      \"positionAbsolute\": {\n        \"x\": 2622.311205430048,\n        \"y\": -2101.042821808064\n      },\n      \"dragging\": false\n    },\n    {\n      \"id\": \"seqAgent_0\",\n      \"position\": {\n        \"x\": 2648.9343216005295,\n        \"y\": -733.5498173924054\n      },\n      \"type\": \"customNode\",\n      \"data\": {\n        \"id\": \"seqAgent_0\",\n        \"label\": \"Agent\",\n        \"version\": 4,\n        \"name\": \"seqAgent\",\n        \"type\": \"Agent\",\n        \"baseClasses\": [\n          \"Agent\"\n        ],\n        \"category\": \"Sequential Agents\",\n        \"description\": \"Agent that can execute tools\",\n        \"inputParams\": [\n          {\n            \"label\": \"Agent Name\",\n            \"name\": \"agentName\",\n            \"type\": \"string\",\n            \"placeholder\": \"Agent\",\n            \"id\": \"seqAgent_0-input-agentName-string\"\n          },\n          {\n            \"label\": \"System Prompt\",\n            \"name\": \"systemMessagePrompt\",\n            \"type\": \"string\",\n            \"rows\": 4,\n            \"optional\": true,\n            \"default\": \"You are a research assistant who can search for up-to-date info using search engine.\",\n            \"id\": \"seqAgent_0-input-systemMessagePrompt-string\"\n          },\n          {\n            \"label\": \"Prepend Messages History\",\n            \"name\": \"messageHistory\",\n            \"description\": \"Prepend a list of messages between System Prompt and Human Prompt. This is useful when you want to provide few shot examples\",\n            \"type\": \"code\",\n            \"hideCodeExecute\": true,\n            \"codeExample\": \"const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\\n\\nreturn [\\n    new HumanMessage(\\\"What is 333382 🦜 1932?\\\"),\\n    new AIMessage({\\n        content: \\\"\\\",\\n        tool_calls: [\\n        {\\n            id: \\\"12345\\\",\\n            name: \\\"calulator\\\",\\n            args: {\\n                number1: 333382,\\n                number2: 1932,\\n                operation: \\\"divide\\\",\\n            },\\n        },\\n        ],\\n    }),\\n    new ToolMessage({\\n        tool_call_id: \\\"12345\\\",\\n        content: \\\"The answer is 172.558.\\\",\\n    }),\\n    new AIMessage(\\\"The answer is 172.558.\\\"),\\n]\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_0-input-messageHistory-code\"\n          },\n          {\n            \"label\": \"Conversation History\",\n            \"name\": \"conversationHistorySelection\",\n            \"type\": \"options\",\n            \"options\": [\n              {\n                \"label\": \"User Question\",\n                \"name\": \"user_question\",\n                \"description\": \"Use the user question from the historical conversation messages as input.\"\n              },\n              {\n                \"label\": \"Last Conversation Message\",\n                \"name\": \"last_message\",\n                \"description\": \"Use the last conversation message from the historical conversation messages as input.\"\n              },\n              {\n                \"label\": \"All Conversation Messages\",\n                \"name\": \"all_messages\",\n                \"description\": \"Use all conversation messages from the historical conversation messages as input.\"\n              },\n              {\n                \"label\": \"Empty\",\n                \"name\": \"empty\",\n                \"description\": \"Do not use any messages from the conversation history. Ensure to use either System Prompt, Human Prompt, or Messages History.\"\n              }\n            ],\n            \"default\": \"all_messages\",\n            \"optional\": true,\n            \"description\": \"Select which messages from the conversation history to include in the prompt. The selected messages will be inserted between the System Prompt (if defined) and [Messages History, Human Prompt].\",\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_0-input-conversationHistorySelection-options\"\n          },\n          {\n            \"label\": \"Human Prompt\",\n            \"name\": \"humanMessagePrompt\",\n            \"type\": \"string\",\n            \"description\": \"This prompt will be added at the end of the messages as human message\",\n            \"rows\": 4,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_0-input-humanMessagePrompt-string\"\n          },\n          {\n            \"label\": \"Require Approval\",\n            \"name\": \"interrupt\",\n            \"description\": \"Pause execution and request user approval before running tools.\\nIf enabled, the agent will prompt the user with customizable approve/reject options\\nand will proceed only after approval. This requires a configured agent memory to manage\\nthe state and handle approval requests.\\nIf no tools are invoked, the agent proceeds without interruption.\",\n            \"type\": \"boolean\",\n            \"optional\": true,\n            \"id\": \"seqAgent_0-input-interrupt-boolean\"\n          },\n          {\n            \"label\": \"Format Prompt Values\",\n            \"name\": \"promptValues\",\n            \"description\": \"Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value\",\n            \"type\": \"json\",\n            \"optional\": true,\n            \"acceptVariable\": true,\n            \"list\": true,\n            \"id\": \"seqAgent_0-input-promptValues-json\"\n          },\n          {\n            \"label\": \"Approval Prompt\",\n            \"name\": \"approvalPrompt\",\n            \"description\": \"Prompt for approval. Only applicable if \\\"Require Approval\\\" is enabled\",\n            \"type\": \"string\",\n            \"default\": \"You are about to execute tool: {tools}. Ask if user want to proceed\",\n            \"rows\": 4,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_0-input-approvalPrompt-string\"\n          },\n          {\n            \"label\": \"Approve Button Text\",\n            \"name\": \"approveButtonText\",\n            \"description\": \"Text for approve button. Only applicable if \\\"Require Approval\\\" is enabled\",\n            \"type\": \"string\",\n            \"default\": \"Yes\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_0-input-approveButtonText-string\"\n          },\n          {\n            \"label\": \"Reject Button Text\",\n            \"name\": \"rejectButtonText\",\n            \"description\": \"Text for reject button. Only applicable if \\\"Require Approval\\\" is enabled\",\n            \"type\": \"string\",\n            \"default\": \"No\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_0-input-rejectButtonText-string\"\n          },\n          {\n            \"label\": \"Update State\",\n            \"name\": \"updateStateMemory\",\n            \"type\": \"tabs\",\n            \"tabIdentifier\": \"selectedUpdateStateMemoryTab\",\n            \"additionalParams\": true,\n            \"default\": \"updateStateMemoryUI\",\n            \"tabs\": [\n              {\n                \"label\": \"Update State (Table)\",\n                \"name\": \"updateStateMemoryUI\",\n                \"type\": \"datagrid\",\n                \"hint\": {\n                  \"label\": \"How to use\",\n                  \"value\": \"\\n1. Key and value pair to be updated. For example: if you have the following State:\\n    | Key       | Operation     | Default Value     |\\n    |-----------|---------------|-------------------|\\n    | user      | Replace       |                   |\\n\\n    You can update the \\\"user\\\" value with the following:\\n    | Key       | Value     |\\n    |-----------|-----------|\\n    | user      | john doe  |\\n\\n2. If you want to use the Agent's output as the value to update state, it is available as available as `$flow.output` with the following structure:\\n    ```json\\n    {\\n        \\\"content\\\": \\\"Hello! How can I assist you today?\\\",\\n        \\\"usedTools\\\": [\\n            {\\n                \\\"tool\\\": \\\"tool-name\\\",\\n                \\\"toolInput\\\": \\\"{foo: var}\\\",\\n                \\\"toolOutput\\\": \\\"This is the tool's output\\\"\\n            }\\n        ],\\n        \\\"sourceDocuments\\\": [\\n            {\\n                \\\"pageContent\\\": \\\"This is the page content\\\",\\n                \\\"metadata\\\": \\\"{foo: var}\\\"\\n            }\\n        ]\\n    }\\n    ```\\n\\n    For example, if the `toolOutput` is the value you want to update the state with, you can do the following:\\n    | Key       | Value                                     |\\n    |-----------|-------------------------------------------|\\n    | user      | `$flow.output.usedTools[0].toolOutput`  |\\n\\n3. You can get default flow config, including the current \\\"state\\\":\\n    - `$flow.sessionId`\\n    - `$flow.chatId`\\n    - `$flow.chatflowId`\\n    - `$flow.input`\\n    - `$flow.state`\\n\\n4. You can get custom variables: `$vars.<variable-name>`\\n\\n\"\n                },\n                \"description\": \"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values\",\n                \"datagrid\": [\n                  {\n                    \"field\": \"key\",\n                    \"headerName\": \"Key\",\n                    \"type\": \"asyncSingleSelect\",\n                    \"loadMethod\": \"loadStateKeys\",\n                    \"flex\": 0.5,\n                    \"editable\": true\n                  },\n                  {\n                    \"field\": \"value\",\n                    \"headerName\": \"Value\",\n                    \"type\": \"freeSolo\",\n                    \"valueOptions\": [\n                      {\n                        \"label\": \"Agent Output (string)\",\n                        \"value\": \"$flow.output.content\"\n                      },\n                      {\n                        \"label\": \"Used Tools (array)\",\n                        \"value\": \"$flow.output.usedTools\"\n                      },\n                      {\n                        \"label\": \"First Tool Output (string)\",\n                        \"value\": \"$flow.output.usedTools[0].toolOutput\"\n                      },\n                      {\n                        \"label\": \"Source Documents (array)\",\n                        \"value\": \"$flow.output.sourceDocuments\"\n                      },\n                      {\n                        \"label\": \"Global variable (string)\",\n                        \"value\": \"$vars.<variable-name>\"\n                      },\n                      {\n                        \"label\": \"Input Question (string)\",\n                        \"value\": \"$flow.input\"\n                      },\n                      {\n                        \"label\": \"Session Id (string)\",\n                        \"value\": \"$flow.sessionId\"\n                      },\n                      {\n                        \"label\": \"Chat Id (string)\",\n                        \"value\": \"$flow.chatId\"\n                      },\n                      {\n                        \"label\": \"Chatflow Id (string)\",\n                        \"value\": \"$flow.chatflowId\"\n                      }\n                    ],\n                    \"editable\": true,\n                    \"flex\": 1\n                  }\n                ],\n                \"optional\": true,\n                \"additionalParams\": true\n              },\n              {\n                \"label\": \"Update State (Code)\",\n                \"name\": \"updateStateMemoryCode\",\n                \"type\": \"code\",\n                \"hint\": {\n                  \"label\": \"How to use\",\n                  \"value\": \"\\n1. Return the key value JSON object. For example: if you have the following State:\\n    ```json\\n    {\\n        \\\"user\\\": null\\n    }\\n    ```\\n\\n    You can update the \\\"user\\\" value by returning the following:\\n    ```js\\n    return {\\n        \\\"user\\\": \\\"john doe\\\"\\n    }\\n    ```\\n\\n2. If you want to use the agent's output as the value to update state, it is available as `$flow.output` with the following structure:\\n    ```json\\n    {\\n        \\\"content\\\": \\\"Hello! How can I assist you today?\\\",\\n        \\\"usedTools\\\": [\\n            {\\n                \\\"tool\\\": \\\"tool-name\\\",\\n                \\\"toolInput\\\": \\\"{foo: var}\\\",\\n                \\\"toolOutput\\\": \\\"This is the tool's output\\\"\\n            }\\n        ],\\n        \\\"sourceDocuments\\\": [\\n            {\\n                \\\"pageContent\\\": \\\"This is the page content\\\",\\n                \\\"metadata\\\": \\\"{foo: var}\\\"\\n            }\\n        ]\\n    }\\n    ```\\n\\n    For example, if the `toolOutput` is the value you want to update the state with, you can return the following:\\n    ```js\\n    return {\\n        \\\"user\\\": $flow.output.usedTools[0].toolOutput\\n    }\\n    ```\\n\\n3. You can also get default flow config, including the current \\\"state\\\":\\n    - `$flow.sessionId`\\n    - `$flow.chatId`\\n    - `$flow.chatflowId`\\n    - `$flow.input`\\n    - `$flow.state`\\n\\n4. You can get custom variables: `$vars.<variable-name>`\\n\\n\"\n                },\n                \"description\": \"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. Must return an object representing the state\",\n                \"hideCodeExecute\": true,\n                \"codeExample\": \"const result = $flow.output;\\n\\n/* Suppose we have a custom State schema like this:\\n* {\\n    aggregate: {\\n        value: (x, y) => x.concat(y),\\n        default: () => []\\n    }\\n  }\\n*/\\n\\nreturn {\\n  aggregate: [result.content]\\n};\",\n                \"optional\": true,\n                \"additionalParams\": true\n              }\n            ],\n            \"id\": \"seqAgent_0-input-updateStateMemory-tabs\"\n          },\n          {\n            \"label\": \"Max Iterations\",\n            \"name\": \"maxIterations\",\n            \"type\": \"number\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_0-input-maxIterations-number\"\n          }\n        ],\n        \"inputAnchors\": [\n          {\n            \"label\": \"Tools\",\n            \"name\": \"tools\",\n            \"type\": \"Tool\",\n            \"list\": true,\n            \"optional\": true,\n            \"id\": \"seqAgent_0-input-tools-Tool\"\n          },\n          {\n            \"label\": \"Start | Agent | Condition | LLM | Tool Node\",\n            \"name\": \"sequentialNode\",\n            \"type\": \"Start | Agent | Condition | LLMNode | ToolNode\",\n            \"list\": true,\n            \"id\": \"seqAgent_0-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode\"\n          },\n          {\n            \"label\": \"Chat Model\",\n            \"name\": \"model\",\n            \"type\": \"BaseChatModel\",\n            \"optional\": true,\n            \"description\": \"Overwrite model to be used for this agent\",\n            \"id\": \"seqAgent_0-input-model-BaseChatModel\"\n          }\n        ],\n        \"inputs\": {\n          \"agentName\": \"llama1\",\n          \"systemMessagePrompt\": \"You will edit and improve the previous response.\",\n          \"messageHistory\": \"\",\n          \"conversationHistorySelection\": \"all_messages\",\n          \"humanMessagePrompt\": \"\",\n          \"tools\": [\n            \"{{retrieverTool_0.data.instance}}\"\n          ],\n          \"sequentialNode\": [\n            \"{{seqAgent_2.data.instance}}\"\n          ],\n          \"model\": \"\",\n          \"interrupt\": \"\",\n          \"promptValues\": \"\",\n          \"approvalPrompt\": \"You are about to execute tool: {tools}. Ask if user want to proceed\",\n          \"approveButtonText\": \"Yes\",\n          \"rejectButtonText\": \"No\",\n          \"updateStateMemory\": \"updateStateMemoryUI\",\n          \"maxIterations\": \"\"\n        },\n        \"outputAnchors\": [\n          {\n            \"id\": \"seqAgent_0-output-seqAgent-Agent\",\n            \"name\": \"seqAgent\",\n            \"label\": \"Agent\",\n            \"description\": \"Agent that can execute tools\",\n            \"type\": \"Agent\"\n          }\n        ],\n        \"outputs\": {},\n        \"selected\": false\n      },\n      \"width\": 300,\n      \"height\": 879,\n      \"selected\": false,\n      \"positionAbsolute\": {\n        \"x\": 2648.9343216005295,\n        \"y\": -733.5498173924054\n      },\n      \"dragging\": false\n    },\n    {\n      \"id\": \"seqAgent_1\",\n      \"position\": {\n        \"x\": 3191.8164588101795,\n        \"y\": -1070.0875151733458\n      },\n      \"type\": \"customNode\",\n      \"data\": {\n        \"id\": \"seqAgent_1\",\n        \"label\": \"Agent\",\n        \"version\": 4,\n        \"name\": \"seqAgent\",\n        \"type\": \"Agent\",\n        \"baseClasses\": [\n          \"Agent\"\n        ],\n        \"category\": \"Sequential Agents\",\n        \"description\": \"Agent that can execute tools\",\n        \"inputParams\": [\n          {\n            \"label\": \"Agent Name\",\n            \"name\": \"agentName\",\n            \"type\": \"string\",\n            \"placeholder\": \"Agent\",\n            \"id\": \"seqAgent_1-input-agentName-string\"\n          },\n          {\n            \"label\": \"System Prompt\",\n            \"name\": \"systemMessagePrompt\",\n            \"type\": \"string\",\n            \"rows\": 4,\n            \"optional\": true,\n            \"default\": \"You are a research assistant who can search for up-to-date info using search engine.\",\n            \"id\": \"seqAgent_1-input-systemMessagePrompt-string\"\n          },\n          {\n            \"label\": \"Prepend Messages History\",\n            \"name\": \"messageHistory\",\n            \"description\": \"Prepend a list of messages between System Prompt and Human Prompt. This is useful when you want to provide few shot examples\",\n            \"type\": \"code\",\n            \"hideCodeExecute\": true,\n            \"codeExample\": \"const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\\n\\nreturn [\\n    new HumanMessage(\\\"What is 333382 🦜 1932?\\\"),\\n    new AIMessage({\\n        content: \\\"\\\",\\n        tool_calls: [\\n        {\\n            id: \\\"12345\\\",\\n            name: \\\"calulator\\\",\\n            args: {\\n                number1: 333382,\\n                number2: 1932,\\n                operation: \\\"divide\\\",\\n            },\\n        },\\n        ],\\n    }),\\n    new ToolMessage({\\n        tool_call_id: \\\"12345\\\",\\n        content: \\\"The answer is 172.558.\\\",\\n    }),\\n    new AIMessage(\\\"The answer is 172.558.\\\"),\\n]\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_1-input-messageHistory-code\"\n          },\n          {\n            \"label\": \"Conversation History\",\n            \"name\": \"conversationHistorySelection\",\n            \"type\": \"options\",\n            \"options\": [\n              {\n                \"label\": \"User Question\",\n                \"name\": \"user_question\",\n                \"description\": \"Use the user question from the historical conversation messages as input.\"\n              },\n              {\n                \"label\": \"Last Conversation Message\",\n                \"name\": \"last_message\",\n                \"description\": \"Use the last conversation message from the historical conversation messages as input.\"\n              },\n              {\n                \"label\": \"All Conversation Messages\",\n                \"name\": \"all_messages\",\n                \"description\": \"Use all conversation messages from the historical conversation messages as input.\"\n              },\n              {\n                \"label\": \"Empty\",\n                \"name\": \"empty\",\n                \"description\": \"Do not use any messages from the conversation history. Ensure to use either System Prompt, Human Prompt, or Messages History.\"\n              }\n            ],\n            \"default\": \"all_messages\",\n            \"optional\": true,\n            \"description\": \"Select which messages from the conversation history to include in the prompt. The selected messages will be inserted between the System Prompt (if defined) and [Messages History, Human Prompt].\",\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_1-input-conversationHistorySelection-options\"\n          },\n          {\n            \"label\": \"Human Prompt\",\n            \"name\": \"humanMessagePrompt\",\n            \"type\": \"string\",\n            \"description\": \"This prompt will be added at the end of the messages as human message\",\n            \"rows\": 4,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_1-input-humanMessagePrompt-string\"\n          },\n          {\n            \"label\": \"Require Approval\",\n            \"name\": \"interrupt\",\n            \"description\": \"Pause execution and request user approval before running tools.\\nIf enabled, the agent will prompt the user with customizable approve/reject options\\nand will proceed only after approval. This requires a configured agent memory to manage\\nthe state and handle approval requests.\\nIf no tools are invoked, the agent proceeds without interruption.\",\n            \"type\": \"boolean\",\n            \"optional\": true,\n            \"id\": \"seqAgent_1-input-interrupt-boolean\"\n          },\n          {\n            \"label\": \"Format Prompt Values\",\n            \"name\": \"promptValues\",\n            \"description\": \"Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value\",\n            \"type\": \"json\",\n            \"optional\": true,\n            \"acceptVariable\": true,\n            \"list\": true,\n            \"id\": \"seqAgent_1-input-promptValues-json\"\n          },\n          {\n            \"label\": \"Approval Prompt\",\n            \"name\": \"approvalPrompt\",\n            \"description\": \"Prompt for approval. Only applicable if \\\"Require Approval\\\" is enabled\",\n            \"type\": \"string\",\n            \"default\": \"You are about to execute tool: {tools}. Ask if user want to proceed\",\n            \"rows\": 4,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_1-input-approvalPrompt-string\"\n          },\n          {\n            \"label\": \"Approve Button Text\",\n            \"name\": \"approveButtonText\",\n            \"description\": \"Text for approve button. Only applicable if \\\"Require Approval\\\" is enabled\",\n            \"type\": \"string\",\n            \"default\": \"Yes\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_1-input-approveButtonText-string\"\n          },\n          {\n            \"label\": \"Reject Button Text\",\n            \"name\": \"rejectButtonText\",\n            \"description\": \"Text for reject button. Only applicable if \\\"Require Approval\\\" is enabled\",\n            \"type\": \"string\",\n            \"default\": \"No\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_1-input-rejectButtonText-string\"\n          },\n          {\n            \"label\": \"Update State\",\n            \"name\": \"updateStateMemory\",\n            \"type\": \"tabs\",\n            \"tabIdentifier\": \"selectedUpdateStateMemoryTab\",\n            \"additionalParams\": true,\n            \"default\": \"updateStateMemoryUI\",\n            \"tabs\": [\n              {\n                \"label\": \"Update State (Table)\",\n                \"name\": \"updateStateMemoryUI\",\n                \"type\": \"datagrid\",\n                \"hint\": {\n                  \"label\": \"How to use\",\n                  \"value\": \"\\n1. Key and value pair to be updated. For example: if you have the following State:\\n    | Key       | Operation     | Default Value     |\\n    |-----------|---------------|-------------------|\\n    | user      | Replace       |                   |\\n\\n    You can update the \\\"user\\\" value with the following:\\n    | Key       | Value     |\\n    |-----------|-----------|\\n    | user      | john doe  |\\n\\n2. If you want to use the Agent's output as the value to update state, it is available as available as `$flow.output` with the following structure:\\n    ```json\\n    {\\n        \\\"content\\\": \\\"Hello! How can I assist you today?\\\",\\n        \\\"usedTools\\\": [\\n            {\\n                \\\"tool\\\": \\\"tool-name\\\",\\n                \\\"toolInput\\\": \\\"{foo: var}\\\",\\n                \\\"toolOutput\\\": \\\"This is the tool's output\\\"\\n            }\\n        ],\\n        \\\"sourceDocuments\\\": [\\n            {\\n                \\\"pageContent\\\": \\\"This is the page content\\\",\\n                \\\"metadata\\\": \\\"{foo: var}\\\"\\n            }\\n        ]\\n    }\\n    ```\\n\\n    For example, if the `toolOutput` is the value you want to update the state with, you can do the following:\\n    | Key       | Value                                     |\\n    |-----------|-------------------------------------------|\\n    | user      | `$flow.output.usedTools[0].toolOutput`  |\\n\\n3. You can get default flow config, including the current \\\"state\\\":\\n    - `$flow.sessionId`\\n    - `$flow.chatId`\\n    - `$flow.chatflowId`\\n    - `$flow.input`\\n    - `$flow.state`\\n\\n4. You can get custom variables: `$vars.<variable-name>`\\n\\n\"\n                },\n                \"description\": \"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values\",\n                \"datagrid\": [\n                  {\n                    \"field\": \"key\",\n                    \"headerName\": \"Key\",\n                    \"type\": \"asyncSingleSelect\",\n                    \"loadMethod\": \"loadStateKeys\",\n                    \"flex\": 0.5,\n                    \"editable\": true\n                  },\n                  {\n                    \"field\": \"value\",\n                    \"headerName\": \"Value\",\n                    \"type\": \"freeSolo\",\n                    \"valueOptions\": [\n                      {\n                        \"label\": \"Agent Output (string)\",\n                        \"value\": \"$flow.output.content\"\n                      },\n                      {\n                        \"label\": \"Used Tools (array)\",\n                        \"value\": \"$flow.output.usedTools\"\n                      },\n                      {\n                        \"label\": \"First Tool Output (string)\",\n                        \"value\": \"$flow.output.usedTools[0].toolOutput\"\n                      },\n                      {\n                        \"label\": \"Source Documents (array)\",\n                        \"value\": \"$flow.output.sourceDocuments\"\n                      },\n                      {\n                        \"label\": \"Global variable (string)\",\n                        \"value\": \"$vars.<variable-name>\"\n                      },\n                      {\n                        \"label\": \"Input Question (string)\",\n                        \"value\": \"$flow.input\"\n                      },\n                      {\n                        \"label\": \"Session Id (string)\",\n                        \"value\": \"$flow.sessionId\"\n                      },\n                      {\n                        \"label\": \"Chat Id (string)\",\n                        \"value\": \"$flow.chatId\"\n                      },\n                      {\n                        \"label\": \"Chatflow Id (string)\",\n                        \"value\": \"$flow.chatflowId\"\n                      }\n                    ],\n                    \"editable\": true,\n                    \"flex\": 1\n                  }\n                ],\n                \"optional\": true,\n                \"additionalParams\": true\n              },\n              {\n                \"label\": \"Update State (Code)\",\n                \"name\": \"updateStateMemoryCode\",\n                \"type\": \"code\",\n                \"hint\": {\n                  \"label\": \"How to use\",\n                  \"value\": \"\\n1. Return the key value JSON object. For example: if you have the following State:\\n    ```json\\n    {\\n        \\\"user\\\": null\\n    }\\n    ```\\n\\n    You can update the \\\"user\\\" value by returning the following:\\n    ```js\\n    return {\\n        \\\"user\\\": \\\"john doe\\\"\\n    }\\n    ```\\n\\n2. If you want to use the agent's output as the value to update state, it is available as `$flow.output` with the following structure:\\n    ```json\\n    {\\n        \\\"content\\\": \\\"Hello! How can I assist you today?\\\",\\n        \\\"usedTools\\\": [\\n            {\\n                \\\"tool\\\": \\\"tool-name\\\",\\n                \\\"toolInput\\\": \\\"{foo: var}\\\",\\n                \\\"toolOutput\\\": \\\"This is the tool's output\\\"\\n            }\\n        ],\\n        \\\"sourceDocuments\\\": [\\n            {\\n                \\\"pageContent\\\": \\\"This is the page content\\\",\\n                \\\"metadata\\\": \\\"{foo: var}\\\"\\n            }\\n        ]\\n    }\\n    ```\\n\\n    For example, if the `toolOutput` is the value you want to update the state with, you can return the following:\\n    ```js\\n    return {\\n        \\\"user\\\": $flow.output.usedTools[0].toolOutput\\n    }\\n    ```\\n\\n3. You can also get default flow config, including the current \\\"state\\\":\\n    - `$flow.sessionId`\\n    - `$flow.chatId`\\n    - `$flow.chatflowId`\\n    - `$flow.input`\\n    - `$flow.state`\\n\\n4. You can get custom variables: `$vars.<variable-name>`\\n\\n\"\n                },\n                \"description\": \"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. Must return an object representing the state\",\n                \"hideCodeExecute\": true,\n                \"codeExample\": \"const result = $flow.output;\\n\\n/* Suppose we have a custom State schema like this:\\n* {\\n    aggregate: {\\n        value: (x, y) => x.concat(y),\\n        default: () => []\\n    }\\n  }\\n*/\\n\\nreturn {\\n  aggregate: [result.content]\\n};\",\n                \"optional\": true,\n                \"additionalParams\": true\n              }\n            ],\n            \"id\": \"seqAgent_1-input-updateStateMemory-tabs\"\n          },\n          {\n            \"label\": \"Max Iterations\",\n            \"name\": \"maxIterations\",\n            \"type\": \"number\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_1-input-maxIterations-number\"\n          }\n        ],\n        \"inputAnchors\": [\n          {\n            \"label\": \"Tools\",\n            \"name\": \"tools\",\n            \"type\": \"Tool\",\n            \"list\": true,\n            \"optional\": true,\n            \"id\": \"seqAgent_1-input-tools-Tool\"\n          },\n          {\n            \"label\": \"Start | Agent | Condition | LLM | Tool Node\",\n            \"name\": \"sequentialNode\",\n            \"type\": \"Start | Agent | Condition | LLMNode | ToolNode\",\n            \"list\": true,\n            \"id\": \"seqAgent_1-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode\"\n          },\n          {\n            \"label\": \"Chat Model\",\n            \"name\": \"model\",\n            \"type\": \"BaseChatModel\",\n            \"optional\": true,\n            \"description\": \"Overwrite model to be used for this agent\",\n            \"id\": \"seqAgent_1-input-model-BaseChatModel\"\n          }\n        ],\n        \"inputs\": {\n          \"agentName\": \"mistral1\",\n          \"systemMessagePrompt\": \"You will edit and improve the previous response.\",\n          \"messageHistory\": \"\",\n          \"conversationHistorySelection\": \"all_messages\",\n          \"humanMessagePrompt\": \"\",\n          \"tools\": [\n            \"{{retrieverTool_0.data.instance}}\"\n          ],\n          \"sequentialNode\": [\n            \"{{seqAgent_0.data.instance}}\"\n          ],\n          \"model\": \"{{chatOllama_2.data.instance}}\",\n          \"interrupt\": \"\",\n          \"promptValues\": \"\",\n          \"approvalPrompt\": \"You are about to execute tool: {tools}. Ask if user want to proceed\",\n          \"approveButtonText\": \"Yes\",\n          \"rejectButtonText\": \"No\",\n          \"updateStateMemory\": \"updateStateMemoryUI\",\n          \"maxIterations\": \"\"\n        },\n        \"outputAnchors\": [\n          {\n            \"id\": \"seqAgent_1-output-seqAgent-Agent\",\n            \"name\": \"seqAgent\",\n            \"label\": \"Agent\",\n            \"description\": \"Agent that can execute tools\",\n            \"type\": \"Agent\"\n          }\n        ],\n        \"outputs\": {},\n        \"selected\": false\n      },\n      \"width\": 300,\n      \"height\": 879,\n      \"selected\": false,\n      \"positionAbsolute\": {\n        \"x\": 3191.8164588101795,\n        \"y\": -1070.0875151733458\n      },\n      \"dragging\": false\n    },\n    {\n      \"id\": \"seqAgent_2\",\n      \"position\": {\n        \"x\": 2081.0114946937774,\n        \"y\": -482.69137698865586\n      },\n      \"type\": \"customNode\",\n      \"data\": {\n        \"id\": \"seqAgent_2\",\n        \"label\": \"Agent\",\n        \"version\": 4,\n        \"name\": \"seqAgent\",\n        \"type\": \"Agent\",\n        \"baseClasses\": [\n          \"Agent\"\n        ],\n        \"category\": \"Sequential Agents\",\n        \"description\": \"Agent that can execute tools\",\n        \"inputParams\": [\n          {\n            \"label\": \"Agent Name\",\n            \"name\": \"agentName\",\n            \"type\": \"string\",\n            \"placeholder\": \"Agent\",\n            \"id\": \"seqAgent_2-input-agentName-string\"\n          },\n          {\n            \"label\": \"System Prompt\",\n            \"name\": \"systemMessagePrompt\",\n            \"type\": \"string\",\n            \"rows\": 4,\n            \"optional\": true,\n            \"default\": \"You are a research assistant who can search for up-to-date info using search engine.\",\n            \"id\": \"seqAgent_2-input-systemMessagePrompt-string\"\n          },\n          {\n            \"label\": \"Prepend Messages History\",\n            \"name\": \"messageHistory\",\n            \"description\": \"Prepend a list of messages between System Prompt and Human Prompt. This is useful when you want to provide few shot examples\",\n            \"type\": \"code\",\n            \"hideCodeExecute\": true,\n            \"codeExample\": \"const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\\n\\nreturn [\\n    new HumanMessage(\\\"What is 333382 🦜 1932?\\\"),\\n    new AIMessage({\\n        content: \\\"\\\",\\n        tool_calls: [\\n        {\\n            id: \\\"12345\\\",\\n            name: \\\"calulator\\\",\\n            args: {\\n                number1: 333382,\\n                number2: 1932,\\n                operation: \\\"divide\\\",\\n            },\\n        },\\n        ],\\n    }),\\n    new ToolMessage({\\n        tool_call_id: \\\"12345\\\",\\n        content: \\\"The answer is 172.558.\\\",\\n    }),\\n    new AIMessage(\\\"The answer is 172.558.\\\"),\\n]\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_2-input-messageHistory-code\"\n          },\n          {\n            \"label\": \"Conversation History\",\n            \"name\": \"conversationHistorySelection\",\n            \"type\": \"options\",\n            \"options\": [\n              {\n                \"label\": \"User Question\",\n                \"name\": \"user_question\",\n                \"description\": \"Use the user question from the historical conversation messages as input.\"\n              },\n              {\n                \"label\": \"Last Conversation Message\",\n                \"name\": \"last_message\",\n                \"description\": \"Use the last conversation message from the historical conversation messages as input.\"\n              },\n              {\n                \"label\": \"All Conversation Messages\",\n                \"name\": \"all_messages\",\n                \"description\": \"Use all conversation messages from the historical conversation messages as input.\"\n              },\n              {\n                \"label\": \"Empty\",\n                \"name\": \"empty\",\n                \"description\": \"Do not use any messages from the conversation history. Ensure to use either System Prompt, Human Prompt, or Messages History.\"\n              }\n            ],\n            \"default\": \"all_messages\",\n            \"optional\": true,\n            \"description\": \"Select which messages from the conversation history to include in the prompt. The selected messages will be inserted between the System Prompt (if defined) and [Messages History, Human Prompt].\",\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_2-input-conversationHistorySelection-options\"\n          },\n          {\n            \"label\": \"Human Prompt\",\n            \"name\": \"humanMessagePrompt\",\n            \"type\": \"string\",\n            \"description\": \"This prompt will be added at the end of the messages as human message\",\n            \"rows\": 4,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_2-input-humanMessagePrompt-string\"\n          },\n          {\n            \"label\": \"Require Approval\",\n            \"name\": \"interrupt\",\n            \"description\": \"Pause execution and request user approval before running tools.\\nIf enabled, the agent will prompt the user with customizable approve/reject options\\nand will proceed only after approval. This requires a configured agent memory to manage\\nthe state and handle approval requests.\\nIf no tools are invoked, the agent proceeds without interruption.\",\n            \"type\": \"boolean\",\n            \"optional\": true,\n            \"id\": \"seqAgent_2-input-interrupt-boolean\"\n          },\n          {\n            \"label\": \"Format Prompt Values\",\n            \"name\": \"promptValues\",\n            \"description\": \"Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value\",\n            \"type\": \"json\",\n            \"optional\": true,\n            \"acceptVariable\": true,\n            \"list\": true,\n            \"id\": \"seqAgent_2-input-promptValues-json\"\n          },\n          {\n            \"label\": \"Approval Prompt\",\n            \"name\": \"approvalPrompt\",\n            \"description\": \"Prompt for approval. Only applicable if \\\"Require Approval\\\" is enabled\",\n            \"type\": \"string\",\n            \"default\": \"You are about to execute tool: {tools}. Ask if user want to proceed\",\n            \"rows\": 4,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_2-input-approvalPrompt-string\"\n          },\n          {\n            \"label\": \"Approve Button Text\",\n            \"name\": \"approveButtonText\",\n            \"description\": \"Text for approve button. Only applicable if \\\"Require Approval\\\" is enabled\",\n            \"type\": \"string\",\n            \"default\": \"Yes\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_2-input-approveButtonText-string\"\n          },\n          {\n            \"label\": \"Reject Button Text\",\n            \"name\": \"rejectButtonText\",\n            \"description\": \"Text for reject button. Only applicable if \\\"Require Approval\\\" is enabled\",\n            \"type\": \"string\",\n            \"default\": \"No\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_2-input-rejectButtonText-string\"\n          },\n          {\n            \"label\": \"Update State\",\n            \"name\": \"updateStateMemory\",\n            \"type\": \"tabs\",\n            \"tabIdentifier\": \"selectedUpdateStateMemoryTab\",\n            \"additionalParams\": true,\n            \"default\": \"updateStateMemoryUI\",\n            \"tabs\": [\n              {\n                \"label\": \"Update State (Table)\",\n                \"name\": \"updateStateMemoryUI\",\n                \"type\": \"datagrid\",\n                \"hint\": {\n                  \"label\": \"How to use\",\n                  \"value\": \"\\n1. Key and value pair to be updated. For example: if you have the following State:\\n    | Key       | Operation     | Default Value     |\\n    |-----------|---------------|-------------------|\\n    | user      | Replace       |                   |\\n\\n    You can update the \\\"user\\\" value with the following:\\n    | Key       | Value     |\\n    |-----------|-----------|\\n    | user      | john doe  |\\n\\n2. If you want to use the Agent's output as the value to update state, it is available as available as `$flow.output` with the following structure:\\n    ```json\\n    {\\n        \\\"content\\\": \\\"Hello! How can I assist you today?\\\",\\n        \\\"usedTools\\\": [\\n            {\\n                \\\"tool\\\": \\\"tool-name\\\",\\n                \\\"toolInput\\\": \\\"{foo: var}\\\",\\n                \\\"toolOutput\\\": \\\"This is the tool's output\\\"\\n            }\\n        ],\\n        \\\"sourceDocuments\\\": [\\n            {\\n                \\\"pageContent\\\": \\\"This is the page content\\\",\\n                \\\"metadata\\\": \\\"{foo: var}\\\"\\n            }\\n        ]\\n    }\\n    ```\\n\\n    For example, if the `toolOutput` is the value you want to update the state with, you can do the following:\\n    | Key       | Value                                     |\\n    |-----------|-------------------------------------------|\\n    | user      | `$flow.output.usedTools[0].toolOutput`  |\\n\\n3. You can get default flow config, including the current \\\"state\\\":\\n    - `$flow.sessionId`\\n    - `$flow.chatId`\\n    - `$flow.chatflowId`\\n    - `$flow.input`\\n    - `$flow.state`\\n\\n4. You can get custom variables: `$vars.<variable-name>`\\n\\n\"\n                },\n                \"description\": \"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values\",\n                \"datagrid\": [\n                  {\n                    \"field\": \"key\",\n                    \"headerName\": \"Key\",\n                    \"type\": \"asyncSingleSelect\",\n                    \"loadMethod\": \"loadStateKeys\",\n                    \"flex\": 0.5,\n                    \"editable\": true\n                  },\n                  {\n                    \"field\": \"value\",\n                    \"headerName\": \"Value\",\n                    \"type\": \"freeSolo\",\n                    \"valueOptions\": [\n                      {\n                        \"label\": \"Agent Output (string)\",\n                        \"value\": \"$flow.output.content\"\n                      },\n                      {\n                        \"label\": \"Used Tools (array)\",\n                        \"value\": \"$flow.output.usedTools\"\n                      },\n                      {\n                        \"label\": \"First Tool Output (string)\",\n                        \"value\": \"$flow.output.usedTools[0].toolOutput\"\n                      },\n                      {\n                        \"label\": \"Source Documents (array)\",\n                        \"value\": \"$flow.output.sourceDocuments\"\n                      },\n                      {\n                        \"label\": \"Global variable (string)\",\n                        \"value\": \"$vars.<variable-name>\"\n                      },\n                      {\n                        \"label\": \"Input Question (string)\",\n                        \"value\": \"$flow.input\"\n                      },\n                      {\n                        \"label\": \"Session Id (string)\",\n                        \"value\": \"$flow.sessionId\"\n                      },\n                      {\n                        \"label\": \"Chat Id (string)\",\n                        \"value\": \"$flow.chatId\"\n                      },\n                      {\n                        \"label\": \"Chatflow Id (string)\",\n                        \"value\": \"$flow.chatflowId\"\n                      }\n                    ],\n                    \"editable\": true,\n                    \"flex\": 1\n                  }\n                ],\n                \"optional\": true,\n                \"additionalParams\": true\n              },\n              {\n                \"label\": \"Update State (Code)\",\n                \"name\": \"updateStateMemoryCode\",\n                \"type\": \"code\",\n                \"hint\": {\n                  \"label\": \"How to use\",\n                  \"value\": \"\\n1. Return the key value JSON object. For example: if you have the following State:\\n    ```json\\n    {\\n        \\\"user\\\": null\\n    }\\n    ```\\n\\n    You can update the \\\"user\\\" value by returning the following:\\n    ```js\\n    return {\\n        \\\"user\\\": \\\"john doe\\\"\\n    }\\n    ```\\n\\n2. If you want to use the agent's output as the value to update state, it is available as `$flow.output` with the following structure:\\n    ```json\\n    {\\n        \\\"content\\\": \\\"Hello! How can I assist you today?\\\",\\n        \\\"usedTools\\\": [\\n            {\\n                \\\"tool\\\": \\\"tool-name\\\",\\n                \\\"toolInput\\\": \\\"{foo: var}\\\",\\n                \\\"toolOutput\\\": \\\"This is the tool's output\\\"\\n            }\\n        ],\\n        \\\"sourceDocuments\\\": [\\n            {\\n                \\\"pageContent\\\": \\\"This is the page content\\\",\\n                \\\"metadata\\\": \\\"{foo: var}\\\"\\n            }\\n        ]\\n    }\\n    ```\\n\\n    For example, if the `toolOutput` is the value you want to update the state with, you can return the following:\\n    ```js\\n    return {\\n        \\\"user\\\": $flow.output.usedTools[0].toolOutput\\n    }\\n    ```\\n\\n3. You can also get default flow config, including the current \\\"state\\\":\\n    - `$flow.sessionId`\\n    - `$flow.chatId`\\n    - `$flow.chatflowId`\\n    - `$flow.input`\\n    - `$flow.state`\\n\\n4. You can get custom variables: `$vars.<variable-name>`\\n\\n\"\n                },\n                \"description\": \"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. Must return an object representing the state\",\n                \"hideCodeExecute\": true,\n                \"codeExample\": \"const result = $flow.output;\\n\\n/* Suppose we have a custom State schema like this:\\n* {\\n    aggregate: {\\n        value: (x, y) => x.concat(y),\\n        default: () => []\\n    }\\n  }\\n*/\\n\\nreturn {\\n  aggregate: [result.content]\\n};\",\n                \"optional\": true,\n                \"additionalParams\": true\n              }\n            ],\n            \"id\": \"seqAgent_2-input-updateStateMemory-tabs\"\n          },\n          {\n            \"label\": \"Max Iterations\",\n            \"name\": \"maxIterations\",\n            \"type\": \"number\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_2-input-maxIterations-number\"\n          }\n        ],\n        \"inputAnchors\": [\n          {\n            \"label\": \"Tools\",\n            \"name\": \"tools\",\n            \"type\": \"Tool\",\n            \"list\": true,\n            \"optional\": true,\n            \"id\": \"seqAgent_2-input-tools-Tool\"\n          },\n          {\n            \"label\": \"Start | Agent | Condition | LLM | Tool Node\",\n            \"name\": \"sequentialNode\",\n            \"type\": \"Start | Agent | Condition | LLMNode | ToolNode\",\n            \"list\": true,\n            \"id\": \"seqAgent_2-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode\"\n          },\n          {\n            \"label\": \"Chat Model\",\n            \"name\": \"model\",\n            \"type\": \"BaseChatModel\",\n            \"optional\": true,\n            \"description\": \"Overwrite model to be used for this agent\",\n            \"id\": \"seqAgent_2-input-model-BaseChatModel\"\n          }\n        ],\n        \"inputs\": {\n          \"agentName\": \"gemma1\",\n          \"systemMessagePrompt\": \"You are a writer\",\n          \"messageHistory\": \"\",\n          \"conversationHistorySelection\": \"all_messages\",\n          \"humanMessagePrompt\": \"\",\n          \"tools\": [],\n          \"sequentialNode\": [\n            \"{{seqStart_0.data.instance}}\"\n          ],\n          \"model\": \"{{chatOllama_1.data.instance}}\",\n          \"interrupt\": \"\",\n          \"promptValues\": \"\",\n          \"approvalPrompt\": \"You are about to execute tool: {tools}. Ask if user want to proceed\",\n          \"approveButtonText\": \"Yes\",\n          \"rejectButtonText\": \"No\",\n          \"updateStateMemory\": \"updateStateMemoryUI\",\n          \"maxIterations\": \"\"\n        },\n        \"outputAnchors\": [\n          {\n            \"id\": \"seqAgent_2-output-seqAgent-Agent\",\n            \"name\": \"seqAgent\",\n            \"label\": \"Agent\",\n            \"description\": \"Agent that can execute tools\",\n            \"type\": \"Agent\"\n          }\n        ],\n        \"outputs\": {},\n        \"selected\": false\n      },\n      \"width\": 300,\n      \"height\": 879,\n      \"selected\": false,\n      \"positionAbsolute\": {\n        \"x\": 2081.0114946937774,\n        \"y\": -482.69137698865586\n      },\n      \"dragging\": false\n    },\n    {\n      \"id\": \"seqAgent_3\",\n      \"position\": {\n        \"x\": 4211.985811482824,\n        \"y\": -1070.8224093673928\n      },\n      \"type\": \"customNode\",\n      \"data\": {\n        \"id\": \"seqAgent_3\",\n        \"label\": \"Agent\",\n        \"version\": 4,\n        \"name\": \"seqAgent\",\n        \"type\": \"Agent\",\n        \"baseClasses\": [\n          \"Agent\"\n        ],\n        \"category\": \"Sequential Agents\",\n        \"description\": \"Agent that can execute tools\",\n        \"inputParams\": [\n          {\n            \"label\": \"Agent Name\",\n            \"name\": \"agentName\",\n            \"type\": \"string\",\n            \"placeholder\": \"Agent\",\n            \"id\": \"seqAgent_3-input-agentName-string\"\n          },\n          {\n            \"label\": \"System Prompt\",\n            \"name\": \"systemMessagePrompt\",\n            \"type\": \"string\",\n            \"rows\": 4,\n            \"optional\": true,\n            \"default\": \"You are a research assistant who can search for up-to-date info using search engine.\",\n            \"id\": \"seqAgent_3-input-systemMessagePrompt-string\"\n          },\n          {\n            \"label\": \"Prepend Messages History\",\n            \"name\": \"messageHistory\",\n            \"description\": \"Prepend a list of messages between System Prompt and Human Prompt. This is useful when you want to provide few shot examples\",\n            \"type\": \"code\",\n            \"hideCodeExecute\": true,\n            \"codeExample\": \"const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\\n\\nreturn [\\n    new HumanMessage(\\\"What is 333382 🦜 1932?\\\"),\\n    new AIMessage({\\n        content: \\\"\\\",\\n        tool_calls: [\\n        {\\n            id: \\\"12345\\\",\\n            name: \\\"calulator\\\",\\n            args: {\\n                number1: 333382,\\n                number2: 1932,\\n                operation: \\\"divide\\\",\\n            },\\n        },\\n        ],\\n    }),\\n    new ToolMessage({\\n        tool_call_id: \\\"12345\\\",\\n        content: \\\"The answer is 172.558.\\\",\\n    }),\\n    new AIMessage(\\\"The answer is 172.558.\\\"),\\n]\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_3-input-messageHistory-code\"\n          },\n          {\n            \"label\": \"Conversation History\",\n            \"name\": \"conversationHistorySelection\",\n            \"type\": \"options\",\n            \"options\": [\n              {\n                \"label\": \"User Question\",\n                \"name\": \"user_question\",\n                \"description\": \"Use the user question from the historical conversation messages as input.\"\n              },\n              {\n                \"label\": \"Last Conversation Message\",\n                \"name\": \"last_message\",\n                \"description\": \"Use the last conversation message from the historical conversation messages as input.\"\n              },\n              {\n                \"label\": \"All Conversation Messages\",\n                \"name\": \"all_messages\",\n                \"description\": \"Use all conversation messages from the historical conversation messages as input.\"\n              },\n              {\n                \"label\": \"Empty\",\n                \"name\": \"empty\",\n                \"description\": \"Do not use any messages from the conversation history. Ensure to use either System Prompt, Human Prompt, or Messages History.\"\n              }\n            ],\n            \"default\": \"all_messages\",\n            \"optional\": true,\n            \"description\": \"Select which messages from the conversation history to include in the prompt. The selected messages will be inserted between the System Prompt (if defined) and [Messages History, Human Prompt].\",\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_3-input-conversationHistorySelection-options\"\n          },\n          {\n            \"label\": \"Human Prompt\",\n            \"name\": \"humanMessagePrompt\",\n            \"type\": \"string\",\n            \"description\": \"This prompt will be added at the end of the messages as human message\",\n            \"rows\": 4,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_3-input-humanMessagePrompt-string\"\n          },\n          {\n            \"label\": \"Require Approval\",\n            \"name\": \"interrupt\",\n            \"description\": \"Pause execution and request user approval before running tools.\\nIf enabled, the agent will prompt the user with customizable approve/reject options\\nand will proceed only after approval. This requires a configured agent memory to manage\\nthe state and handle approval requests.\\nIf no tools are invoked, the agent proceeds without interruption.\",\n            \"type\": \"boolean\",\n            \"optional\": true,\n            \"id\": \"seqAgent_3-input-interrupt-boolean\"\n          },\n          {\n            \"label\": \"Format Prompt Values\",\n            \"name\": \"promptValues\",\n            \"description\": \"Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value\",\n            \"type\": \"json\",\n            \"optional\": true,\n            \"acceptVariable\": true,\n            \"list\": true,\n            \"id\": \"seqAgent_3-input-promptValues-json\"\n          },\n          {\n            \"label\": \"Approval Prompt\",\n            \"name\": \"approvalPrompt\",\n            \"description\": \"Prompt for approval. Only applicable if \\\"Require Approval\\\" is enabled\",\n            \"type\": \"string\",\n            \"default\": \"You are about to execute tool: {tools}. Ask if user want to proceed\",\n            \"rows\": 4,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_3-input-approvalPrompt-string\"\n          },\n          {\n            \"label\": \"Approve Button Text\",\n            \"name\": \"approveButtonText\",\n            \"description\": \"Text for approve button. Only applicable if \\\"Require Approval\\\" is enabled\",\n            \"type\": \"string\",\n            \"default\": \"Yes\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_3-input-approveButtonText-string\"\n          },\n          {\n            \"label\": \"Reject Button Text\",\n            \"name\": \"rejectButtonText\",\n            \"description\": \"Text for reject button. Only applicable if \\\"Require Approval\\\" is enabled\",\n            \"type\": \"string\",\n            \"default\": \"No\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_3-input-rejectButtonText-string\"\n          },\n          {\n            \"label\": \"Update State\",\n            \"name\": \"updateStateMemory\",\n            \"type\": \"tabs\",\n            \"tabIdentifier\": \"selectedUpdateStateMemoryTab\",\n            \"additionalParams\": true,\n            \"default\": \"updateStateMemoryUI\",\n            \"tabs\": [\n              {\n                \"label\": \"Update State (Table)\",\n                \"name\": \"updateStateMemoryUI\",\n                \"type\": \"datagrid\",\n                \"hint\": {\n                  \"label\": \"How to use\",\n                  \"value\": \"\\n1. Key and value pair to be updated. For example: if you have the following State:\\n    | Key       | Operation     | Default Value     |\\n    |-----------|---------------|-------------------|\\n    | user      | Replace       |                   |\\n\\n    You can update the \\\"user\\\" value with the following:\\n    | Key       | Value     |\\n    |-----------|-----------|\\n    | user      | john doe  |\\n\\n2. If you want to use the Agent's output as the value to update state, it is available as available as `$flow.output` with the following structure:\\n    ```json\\n    {\\n        \\\"content\\\": \\\"Hello! How can I assist you today?\\\",\\n        \\\"usedTools\\\": [\\n            {\\n                \\\"tool\\\": \\\"tool-name\\\",\\n                \\\"toolInput\\\": \\\"{foo: var}\\\",\\n                \\\"toolOutput\\\": \\\"This is the tool's output\\\"\\n            }\\n        ],\\n        \\\"sourceDocuments\\\": [\\n            {\\n                \\\"pageContent\\\": \\\"This is the page content\\\",\\n                \\\"metadata\\\": \\\"{foo: var}\\\"\\n            }\\n        ]\\n    }\\n    ```\\n\\n    For example, if the `toolOutput` is the value you want to update the state with, you can do the following:\\n    | Key       | Value                                     |\\n    |-----------|-------------------------------------------|\\n    | user      | `$flow.output.usedTools[0].toolOutput`  |\\n\\n3. You can get default flow config, including the current \\\"state\\\":\\n    - `$flow.sessionId`\\n    - `$flow.chatId`\\n    - `$flow.chatflowId`\\n    - `$flow.input`\\n    - `$flow.state`\\n\\n4. You can get custom variables: `$vars.<variable-name>`\\n\\n\"\n                },\n                \"description\": \"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values\",\n                \"datagrid\": [\n                  {\n                    \"field\": \"key\",\n                    \"headerName\": \"Key\",\n                    \"type\": \"asyncSingleSelect\",\n                    \"loadMethod\": \"loadStateKeys\",\n                    \"flex\": 0.5,\n                    \"editable\": true\n                  },\n                  {\n                    \"field\": \"value\",\n                    \"headerName\": \"Value\",\n                    \"type\": \"freeSolo\",\n                    \"valueOptions\": [\n                      {\n                        \"label\": \"Agent Output (string)\",\n                        \"value\": \"$flow.output.content\"\n                      },\n                      {\n                        \"label\": \"Used Tools (array)\",\n                        \"value\": \"$flow.output.usedTools\"\n                      },\n                      {\n                        \"label\": \"First Tool Output (string)\",\n                        \"value\": \"$flow.output.usedTools[0].toolOutput\"\n                      },\n                      {\n                        \"label\": \"Source Documents (array)\",\n                        \"value\": \"$flow.output.sourceDocuments\"\n                      },\n                      {\n                        \"label\": \"Global variable (string)\",\n                        \"value\": \"$vars.<variable-name>\"\n                      },\n                      {\n                        \"label\": \"Input Question (string)\",\n                        \"value\": \"$flow.input\"\n                      },\n                      {\n                        \"label\": \"Session Id (string)\",\n                        \"value\": \"$flow.sessionId\"\n                      },\n                      {\n                        \"label\": \"Chat Id (string)\",\n                        \"value\": \"$flow.chatId\"\n                      },\n                      {\n                        \"label\": \"Chatflow Id (string)\",\n                        \"value\": \"$flow.chatflowId\"\n                      }\n                    ],\n                    \"editable\": true,\n                    \"flex\": 1\n                  }\n                ],\n                \"optional\": true,\n                \"additionalParams\": true\n              },\n              {\n                \"label\": \"Update State (Code)\",\n                \"name\": \"updateStateMemoryCode\",\n                \"type\": \"code\",\n                \"hint\": {\n                  \"label\": \"How to use\",\n                  \"value\": \"\\n1. Return the key value JSON object. For example: if you have the following State:\\n    ```json\\n    {\\n        \\\"user\\\": null\\n    }\\n    ```\\n\\n    You can update the \\\"user\\\" value by returning the following:\\n    ```js\\n    return {\\n        \\\"user\\\": \\\"john doe\\\"\\n    }\\n    ```\\n\\n2. If you want to use the agent's output as the value to update state, it is available as `$flow.output` with the following structure:\\n    ```json\\n    {\\n        \\\"content\\\": \\\"Hello! How can I assist you today?\\\",\\n        \\\"usedTools\\\": [\\n            {\\n                \\\"tool\\\": \\\"tool-name\\\",\\n                \\\"toolInput\\\": \\\"{foo: var}\\\",\\n                \\\"toolOutput\\\": \\\"This is the tool's output\\\"\\n            }\\n        ],\\n        \\\"sourceDocuments\\\": [\\n            {\\n                \\\"pageContent\\\": \\\"This is the page content\\\",\\n                \\\"metadata\\\": \\\"{foo: var}\\\"\\n            }\\n        ]\\n    }\\n    ```\\n\\n    For example, if the `toolOutput` is the value you want to update the state with, you can return the following:\\n    ```js\\n    return {\\n        \\\"user\\\": $flow.output.usedTools[0].toolOutput\\n    }\\n    ```\\n\\n3. You can also get default flow config, including the current \\\"state\\\":\\n    - `$flow.sessionId`\\n    - `$flow.chatId`\\n    - `$flow.chatflowId`\\n    - `$flow.input`\\n    - `$flow.state`\\n\\n4. You can get custom variables: `$vars.<variable-name>`\\n\\n\"\n                },\n                \"description\": \"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. Must return an object representing the state\",\n                \"hideCodeExecute\": true,\n                \"codeExample\": \"const result = $flow.output;\\n\\n/* Suppose we have a custom State schema like this:\\n* {\\n    aggregate: {\\n        value: (x, y) => x.concat(y),\\n        default: () => []\\n    }\\n  }\\n*/\\n\\nreturn {\\n  aggregate: [result.content]\\n};\",\n                \"optional\": true,\n                \"additionalParams\": true\n              }\n            ],\n            \"id\": \"seqAgent_3-input-updateStateMemory-tabs\"\n          },\n          {\n            \"label\": \"Max Iterations\",\n            \"name\": \"maxIterations\",\n            \"type\": \"number\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_3-input-maxIterations-number\"\n          }\n        ],\n        \"inputAnchors\": [\n          {\n            \"label\": \"Tools\",\n            \"name\": \"tools\",\n            \"type\": \"Tool\",\n            \"list\": true,\n            \"optional\": true,\n            \"id\": \"seqAgent_3-input-tools-Tool\"\n          },\n          {\n            \"label\": \"Start | Agent | Condition | LLM | Tool Node\",\n            \"name\": \"sequentialNode\",\n            \"type\": \"Start | Agent | Condition | LLMNode | ToolNode\",\n            \"list\": true,\n            \"id\": \"seqAgent_3-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode\"\n          },\n          {\n            \"label\": \"Chat Model\",\n            \"name\": \"model\",\n            \"type\": \"BaseChatModel\",\n            \"optional\": true,\n            \"description\": \"Overwrite model to be used for this agent\",\n            \"id\": \"seqAgent_3-input-model-BaseChatModel\"\n          }\n        ],\n        \"inputs\": {\n          \"agentName\": \"lamma2\",\n          \"systemMessagePrompt\": \"You will edit and improve the previous response.\",\n          \"messageHistory\": \"\",\n          \"conversationHistorySelection\": \"all_messages\",\n          \"humanMessagePrompt\": \"\",\n          \"tools\": [\n            \"{{retrieverTool_0.data.instance}}\"\n          ],\n          \"sequentialNode\": [\n            \"{{seqAgent_5.data.instance}}\"\n          ],\n          \"model\": \"\",\n          \"interrupt\": \"\",\n          \"promptValues\": \"\",\n          \"approvalPrompt\": \"You are about to execute tool: {tools}. Ask if user want to proceed\",\n          \"approveButtonText\": \"Yes\",\n          \"rejectButtonText\": \"No\",\n          \"updateStateMemory\": \"updateStateMemoryUI\",\n          \"maxIterations\": \"\"\n        },\n        \"outputAnchors\": [\n          {\n            \"id\": \"seqAgent_3-output-seqAgent-Agent\",\n            \"name\": \"seqAgent\",\n            \"label\": \"Agent\",\n            \"description\": \"Agent that can execute tools\",\n            \"type\": \"Agent\"\n          }\n        ],\n        \"outputs\": {},\n        \"selected\": false\n      },\n      \"width\": 300,\n      \"height\": 879,\n      \"selected\": false,\n      \"positionAbsolute\": {\n        \"x\": 4211.985811482824,\n        \"y\": -1070.8224093673928\n      },\n      \"dragging\": false\n    },\n    {\n      \"id\": \"seqAgent_4\",\n      \"position\": {\n        \"x\": 4687.535437615793,\n        \"y\": -1227.0003213749455\n      },\n      \"type\": \"customNode\",\n      \"data\": {\n        \"id\": \"seqAgent_4\",\n        \"label\": \"Agent\",\n        \"version\": 4,\n        \"name\": \"seqAgent\",\n        \"type\": \"Agent\",\n        \"baseClasses\": [\n          \"Agent\"\n        ],\n        \"category\": \"Sequential Agents\",\n        \"description\": \"Agent that can execute tools\",\n        \"inputParams\": [\n          {\n            \"label\": \"Agent Name\",\n            \"name\": \"agentName\",\n            \"type\": \"string\",\n            \"placeholder\": \"Agent\",\n            \"id\": \"seqAgent_4-input-agentName-string\"\n          },\n          {\n            \"label\": \"System Prompt\",\n            \"name\": \"systemMessagePrompt\",\n            \"type\": \"string\",\n            \"rows\": 4,\n            \"optional\": true,\n            \"default\": \"You are a research assistant who can search for up-to-date info using search engine.\",\n            \"id\": \"seqAgent_4-input-systemMessagePrompt-string\"\n          },\n          {\n            \"label\": \"Prepend Messages History\",\n            \"name\": \"messageHistory\",\n            \"description\": \"Prepend a list of messages between System Prompt and Human Prompt. This is useful when you want to provide few shot examples\",\n            \"type\": \"code\",\n            \"hideCodeExecute\": true,\n            \"codeExample\": \"const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\\n\\nreturn [\\n    new HumanMessage(\\\"What is 333382 🦜 1932?\\\"),\\n    new AIMessage({\\n        content: \\\"\\\",\\n        tool_calls: [\\n        {\\n            id: \\\"12345\\\",\\n            name: \\\"calulator\\\",\\n            args: {\\n                number1: 333382,\\n                number2: 1932,\\n                operation: \\\"divide\\\",\\n            },\\n        },\\n        ],\\n    }),\\n    new ToolMessage({\\n        tool_call_id: \\\"12345\\\",\\n        content: \\\"The answer is 172.558.\\\",\\n    }),\\n    new AIMessage(\\\"The answer is 172.558.\\\"),\\n]\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_4-input-messageHistory-code\"\n          },\n          {\n            \"label\": \"Conversation History\",\n            \"name\": \"conversationHistorySelection\",\n            \"type\": \"options\",\n            \"options\": [\n              {\n                \"label\": \"User Question\",\n                \"name\": \"user_question\",\n                \"description\": \"Use the user question from the historical conversation messages as input.\"\n              },\n              {\n                \"label\": \"Last Conversation Message\",\n                \"name\": \"last_message\",\n                \"description\": \"Use the last conversation message from the historical conversation messages as input.\"\n              },\n              {\n                \"label\": \"All Conversation Messages\",\n                \"name\": \"all_messages\",\n                \"description\": \"Use all conversation messages from the historical conversation messages as input.\"\n              },\n              {\n                \"label\": \"Empty\",\n                \"name\": \"empty\",\n                \"description\": \"Do not use any messages from the conversation history. Ensure to use either System Prompt, Human Prompt, or Messages History.\"\n              }\n            ],\n            \"default\": \"all_messages\",\n            \"optional\": true,\n            \"description\": \"Select which messages from the conversation history to include in the prompt. The selected messages will be inserted between the System Prompt (if defined) and [Messages History, Human Prompt].\",\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_4-input-conversationHistorySelection-options\"\n          },\n          {\n            \"label\": \"Human Prompt\",\n            \"name\": \"humanMessagePrompt\",\n            \"type\": \"string\",\n            \"description\": \"This prompt will be added at the end of the messages as human message\",\n            \"rows\": 4,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_4-input-humanMessagePrompt-string\"\n          },\n          {\n            \"label\": \"Require Approval\",\n            \"name\": \"interrupt\",\n            \"description\": \"Pause execution and request user approval before running tools.\\nIf enabled, the agent will prompt the user with customizable approve/reject options\\nand will proceed only after approval. This requires a configured agent memory to manage\\nthe state and handle approval requests.\\nIf no tools are invoked, the agent proceeds without interruption.\",\n            \"type\": \"boolean\",\n            \"optional\": true,\n            \"id\": \"seqAgent_4-input-interrupt-boolean\"\n          },\n          {\n            \"label\": \"Format Prompt Values\",\n            \"name\": \"promptValues\",\n            \"description\": \"Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value\",\n            \"type\": \"json\",\n            \"optional\": true,\n            \"acceptVariable\": true,\n            \"list\": true,\n            \"id\": \"seqAgent_4-input-promptValues-json\"\n          },\n          {\n            \"label\": \"Approval Prompt\",\n            \"name\": \"approvalPrompt\",\n            \"description\": \"Prompt for approval. Only applicable if \\\"Require Approval\\\" is enabled\",\n            \"type\": \"string\",\n            \"default\": \"You are about to execute tool: {tools}. Ask if user want to proceed\",\n            \"rows\": 4,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_4-input-approvalPrompt-string\"\n          },\n          {\n            \"label\": \"Approve Button Text\",\n            \"name\": \"approveButtonText\",\n            \"description\": \"Text for approve button. Only applicable if \\\"Require Approval\\\" is enabled\",\n            \"type\": \"string\",\n            \"default\": \"Yes\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_4-input-approveButtonText-string\"\n          },\n          {\n            \"label\": \"Reject Button Text\",\n            \"name\": \"rejectButtonText\",\n            \"description\": \"Text for reject button. Only applicable if \\\"Require Approval\\\" is enabled\",\n            \"type\": \"string\",\n            \"default\": \"No\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_4-input-rejectButtonText-string\"\n          },\n          {\n            \"label\": \"Update State\",\n            \"name\": \"updateStateMemory\",\n            \"type\": \"tabs\",\n            \"tabIdentifier\": \"selectedUpdateStateMemoryTab\",\n            \"additionalParams\": true,\n            \"default\": \"updateStateMemoryUI\",\n            \"tabs\": [\n              {\n                \"label\": \"Update State (Table)\",\n                \"name\": \"updateStateMemoryUI\",\n                \"type\": \"datagrid\",\n                \"hint\": {\n                  \"label\": \"How to use\",\n                  \"value\": \"\\n1. Key and value pair to be updated. For example: if you have the following State:\\n    | Key       | Operation     | Default Value     |\\n    |-----------|---------------|-------------------|\\n    | user      | Replace       |                   |\\n\\n    You can update the \\\"user\\\" value with the following:\\n    | Key       | Value     |\\n    |-----------|-----------|\\n    | user      | john doe  |\\n\\n2. If you want to use the Agent's output as the value to update state, it is available as available as `$flow.output` with the following structure:\\n    ```json\\n    {\\n        \\\"content\\\": \\\"Hello! How can I assist you today?\\\",\\n        \\\"usedTools\\\": [\\n            {\\n                \\\"tool\\\": \\\"tool-name\\\",\\n                \\\"toolInput\\\": \\\"{foo: var}\\\",\\n                \\\"toolOutput\\\": \\\"This is the tool's output\\\"\\n            }\\n        ],\\n        \\\"sourceDocuments\\\": [\\n            {\\n                \\\"pageContent\\\": \\\"This is the page content\\\",\\n                \\\"metadata\\\": \\\"{foo: var}\\\"\\n            }\\n        ]\\n    }\\n    ```\\n\\n    For example, if the `toolOutput` is the value you want to update the state with, you can do the following:\\n    | Key       | Value                                     |\\n    |-----------|-------------------------------------------|\\n    | user      | `$flow.output.usedTools[0].toolOutput`  |\\n\\n3. You can get default flow config, including the current \\\"state\\\":\\n    - `$flow.sessionId`\\n    - `$flow.chatId`\\n    - `$flow.chatflowId`\\n    - `$flow.input`\\n    - `$flow.state`\\n\\n4. You can get custom variables: `$vars.<variable-name>`\\n\\n\"\n                },\n                \"description\": \"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values\",\n                \"datagrid\": [\n                  {\n                    \"field\": \"key\",\n                    \"headerName\": \"Key\",\n                    \"type\": \"asyncSingleSelect\",\n                    \"loadMethod\": \"loadStateKeys\",\n                    \"flex\": 0.5,\n                    \"editable\": true\n                  },\n                  {\n                    \"field\": \"value\",\n                    \"headerName\": \"Value\",\n                    \"type\": \"freeSolo\",\n                    \"valueOptions\": [\n                      {\n                        \"label\": \"Agent Output (string)\",\n                        \"value\": \"$flow.output.content\"\n                      },\n                      {\n                        \"label\": \"Used Tools (array)\",\n                        \"value\": \"$flow.output.usedTools\"\n                      },\n                      {\n                        \"label\": \"First Tool Output (string)\",\n                        \"value\": \"$flow.output.usedTools[0].toolOutput\"\n                      },\n                      {\n                        \"label\": \"Source Documents (array)\",\n                        \"value\": \"$flow.output.sourceDocuments\"\n                      },\n                      {\n                        \"label\": \"Global variable (string)\",\n                        \"value\": \"$vars.<variable-name>\"\n                      },\n                      {\n                        \"label\": \"Input Question (string)\",\n                        \"value\": \"$flow.input\"\n                      },\n                      {\n                        \"label\": \"Session Id (string)\",\n                        \"value\": \"$flow.sessionId\"\n                      },\n                      {\n                        \"label\": \"Chat Id (string)\",\n                        \"value\": \"$flow.chatId\"\n                      },\n                      {\n                        \"label\": \"Chatflow Id (string)\",\n                        \"value\": \"$flow.chatflowId\"\n                      }\n                    ],\n                    \"editable\": true,\n                    \"flex\": 1\n                  }\n                ],\n                \"optional\": true,\n                \"additionalParams\": true\n              },\n              {\n                \"label\": \"Update State (Code)\",\n                \"name\": \"updateStateMemoryCode\",\n                \"type\": \"code\",\n                \"hint\": {\n                  \"label\": \"How to use\",\n                  \"value\": \"\\n1. Return the key value JSON object. For example: if you have the following State:\\n    ```json\\n    {\\n        \\\"user\\\": null\\n    }\\n    ```\\n\\n    You can update the \\\"user\\\" value by returning the following:\\n    ```js\\n    return {\\n        \\\"user\\\": \\\"john doe\\\"\\n    }\\n    ```\\n\\n2. If you want to use the agent's output as the value to update state, it is available as `$flow.output` with the following structure:\\n    ```json\\n    {\\n        \\\"content\\\": \\\"Hello! How can I assist you today?\\\",\\n        \\\"usedTools\\\": [\\n            {\\n                \\\"tool\\\": \\\"tool-name\\\",\\n                \\\"toolInput\\\": \\\"{foo: var}\\\",\\n                \\\"toolOutput\\\": \\\"This is the tool's output\\\"\\n            }\\n        ],\\n        \\\"sourceDocuments\\\": [\\n            {\\n                \\\"pageContent\\\": \\\"This is the page content\\\",\\n                \\\"metadata\\\": \\\"{foo: var}\\\"\\n            }\\n        ]\\n    }\\n    ```\\n\\n    For example, if the `toolOutput` is the value you want to update the state with, you can return the following:\\n    ```js\\n    return {\\n        \\\"user\\\": $flow.output.usedTools[0].toolOutput\\n    }\\n    ```\\n\\n3. You can also get default flow config, including the current \\\"state\\\":\\n    - `$flow.sessionId`\\n    - `$flow.chatId`\\n    - `$flow.chatflowId`\\n    - `$flow.input`\\n    - `$flow.state`\\n\\n4. You can get custom variables: `$vars.<variable-name>`\\n\\n\"\n                },\n                \"description\": \"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. Must return an object representing the state\",\n                \"hideCodeExecute\": true,\n                \"codeExample\": \"const result = $flow.output;\\n\\n/* Suppose we have a custom State schema like this:\\n* {\\n    aggregate: {\\n        value: (x, y) => x.concat(y),\\n        default: () => []\\n    }\\n  }\\n*/\\n\\nreturn {\\n  aggregate: [result.content]\\n};\",\n                \"optional\": true,\n                \"additionalParams\": true\n              }\n            ],\n            \"id\": \"seqAgent_4-input-updateStateMemory-tabs\"\n          },\n          {\n            \"label\": \"Max Iterations\",\n            \"name\": \"maxIterations\",\n            \"type\": \"number\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_4-input-maxIterations-number\"\n          }\n        ],\n        \"inputAnchors\": [\n          {\n            \"label\": \"Tools\",\n            \"name\": \"tools\",\n            \"type\": \"Tool\",\n            \"list\": true,\n            \"optional\": true,\n            \"id\": \"seqAgent_4-input-tools-Tool\"\n          },\n          {\n            \"label\": \"Start | Agent | Condition | LLM | Tool Node\",\n            \"name\": \"sequentialNode\",\n            \"type\": \"Start | Agent | Condition | LLMNode | ToolNode\",\n            \"list\": true,\n            \"id\": \"seqAgent_4-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode\"\n          },\n          {\n            \"label\": \"Chat Model\",\n            \"name\": \"model\",\n            \"type\": \"BaseChatModel\",\n            \"optional\": true,\n            \"description\": \"Overwrite model to be used for this agent\",\n            \"id\": \"seqAgent_4-input-model-BaseChatModel\"\n          }\n        ],\n        \"inputs\": {\n          \"agentName\": \"mistral2\",\n          \"systemMessagePrompt\": \"You will edit and improve the previous response.\",\n          \"messageHistory\": \"\",\n          \"conversationHistorySelection\": \"all_messages\",\n          \"humanMessagePrompt\": \"\",\n          \"tools\": [\n            \"{{retrieverTool_0.data.instance}}\"\n          ],\n          \"sequentialNode\": [\n            \"{{seqAgent_3.data.instance}}\"\n          ],\n          \"model\": \"{{chatOllama_2.data.instance}}\",\n          \"interrupt\": \"\",\n          \"promptValues\": \"\",\n          \"approvalPrompt\": \"You are about to execute tool: {tools}. Ask if user want to proceed\",\n          \"approveButtonText\": \"Yes\",\n          \"rejectButtonText\": \"No\",\n          \"updateStateMemory\": \"updateStateMemoryUI\",\n          \"maxIterations\": \"\"\n        },\n        \"outputAnchors\": [\n          {\n            \"id\": \"seqAgent_4-output-seqAgent-Agent\",\n            \"name\": \"seqAgent\",\n            \"label\": \"Agent\",\n            \"description\": \"Agent that can execute tools\",\n            \"type\": \"Agent\"\n          }\n        ],\n        \"outputs\": {},\n        \"selected\": false\n      },\n      \"width\": 300,\n      \"height\": 879,\n      \"selected\": false,\n      \"positionAbsolute\": {\n        \"x\": 4687.535437615793,\n        \"y\": -1227.0003213749455\n      },\n      \"dragging\": false\n    },\n    {\n      \"id\": \"seqAgent_5\",\n      \"position\": {\n        \"x\": 3780.9837304604243,\n        \"y\": -850.6074044632425\n      },\n      \"type\": \"customNode\",\n      \"data\": {\n        \"id\": \"seqAgent_5\",\n        \"label\": \"Agent\",\n        \"version\": 4,\n        \"name\": \"seqAgent\",\n        \"type\": \"Agent\",\n        \"baseClasses\": [\n          \"Agent\"\n        ],\n        \"category\": \"Sequential Agents\",\n        \"description\": \"Agent that can execute tools\",\n        \"inputParams\": [\n          {\n            \"label\": \"Agent Name\",\n            \"name\": \"agentName\",\n            \"type\": \"string\",\n            \"placeholder\": \"Agent\",\n            \"id\": \"seqAgent_5-input-agentName-string\"\n          },\n          {\n            \"label\": \"System Prompt\",\n            \"name\": \"systemMessagePrompt\",\n            \"type\": \"string\",\n            \"rows\": 4,\n            \"optional\": true,\n            \"default\": \"You are a research assistant who can search for up-to-date info using search engine.\",\n            \"id\": \"seqAgent_5-input-systemMessagePrompt-string\"\n          },\n          {\n            \"label\": \"Prepend Messages History\",\n            \"name\": \"messageHistory\",\n            \"description\": \"Prepend a list of messages between System Prompt and Human Prompt. This is useful when you want to provide few shot examples\",\n            \"type\": \"code\",\n            \"hideCodeExecute\": true,\n            \"codeExample\": \"const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\\n\\nreturn [\\n    new HumanMessage(\\\"What is 333382 🦜 1932?\\\"),\\n    new AIMessage({\\n        content: \\\"\\\",\\n        tool_calls: [\\n        {\\n            id: \\\"12345\\\",\\n            name: \\\"calulator\\\",\\n            args: {\\n                number1: 333382,\\n                number2: 1932,\\n                operation: \\\"divide\\\",\\n            },\\n        },\\n        ],\\n    }),\\n    new ToolMessage({\\n        tool_call_id: \\\"12345\\\",\\n        content: \\\"The answer is 172.558.\\\",\\n    }),\\n    new AIMessage(\\\"The answer is 172.558.\\\"),\\n]\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_5-input-messageHistory-code\"\n          },\n          {\n            \"label\": \"Conversation History\",\n            \"name\": \"conversationHistorySelection\",\n            \"type\": \"options\",\n            \"options\": [\n              {\n                \"label\": \"User Question\",\n                \"name\": \"user_question\",\n                \"description\": \"Use the user question from the historical conversation messages as input.\"\n              },\n              {\n                \"label\": \"Last Conversation Message\",\n                \"name\": \"last_message\",\n                \"description\": \"Use the last conversation message from the historical conversation messages as input.\"\n              },\n              {\n                \"label\": \"All Conversation Messages\",\n                \"name\": \"all_messages\",\n                \"description\": \"Use all conversation messages from the historical conversation messages as input.\"\n              },\n              {\n                \"label\": \"Empty\",\n                \"name\": \"empty\",\n                \"description\": \"Do not use any messages from the conversation history. Ensure to use either System Prompt, Human Prompt, or Messages History.\"\n              }\n            ],\n            \"default\": \"all_messages\",\n            \"optional\": true,\n            \"description\": \"Select which messages from the conversation history to include in the prompt. The selected messages will be inserted between the System Prompt (if defined) and [Messages History, Human Prompt].\",\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_5-input-conversationHistorySelection-options\"\n          },\n          {\n            \"label\": \"Human Prompt\",\n            \"name\": \"humanMessagePrompt\",\n            \"type\": \"string\",\n            \"description\": \"This prompt will be added at the end of the messages as human message\",\n            \"rows\": 4,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_5-input-humanMessagePrompt-string\"\n          },\n          {\n            \"label\": \"Require Approval\",\n            \"name\": \"interrupt\",\n            \"description\": \"Pause execution and request user approval before running tools.\\nIf enabled, the agent will prompt the user with customizable approve/reject options\\nand will proceed only after approval. This requires a configured agent memory to manage\\nthe state and handle approval requests.\\nIf no tools are invoked, the agent proceeds without interruption.\",\n            \"type\": \"boolean\",\n            \"optional\": true,\n            \"id\": \"seqAgent_5-input-interrupt-boolean\"\n          },\n          {\n            \"label\": \"Format Prompt Values\",\n            \"name\": \"promptValues\",\n            \"description\": \"Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value\",\n            \"type\": \"json\",\n            \"optional\": true,\n            \"acceptVariable\": true,\n            \"list\": true,\n            \"id\": \"seqAgent_5-input-promptValues-json\"\n          },\n          {\n            \"label\": \"Approval Prompt\",\n            \"name\": \"approvalPrompt\",\n            \"description\": \"Prompt for approval. Only applicable if \\\"Require Approval\\\" is enabled\",\n            \"type\": \"string\",\n            \"default\": \"You are about to execute tool: {tools}. Ask if user want to proceed\",\n            \"rows\": 4,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_5-input-approvalPrompt-string\"\n          },\n          {\n            \"label\": \"Approve Button Text\",\n            \"name\": \"approveButtonText\",\n            \"description\": \"Text for approve button. Only applicable if \\\"Require Approval\\\" is enabled\",\n            \"type\": \"string\",\n            \"default\": \"Yes\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_5-input-approveButtonText-string\"\n          },\n          {\n            \"label\": \"Reject Button Text\",\n            \"name\": \"rejectButtonText\",\n            \"description\": \"Text for reject button. Only applicable if \\\"Require Approval\\\" is enabled\",\n            \"type\": \"string\",\n            \"default\": \"No\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_5-input-rejectButtonText-string\"\n          },\n          {\n            \"label\": \"Update State\",\n            \"name\": \"updateStateMemory\",\n            \"type\": \"tabs\",\n            \"tabIdentifier\": \"selectedUpdateStateMemoryTab\",\n            \"additionalParams\": true,\n            \"default\": \"updateStateMemoryUI\",\n            \"tabs\": [\n              {\n                \"label\": \"Update State (Table)\",\n                \"name\": \"updateStateMemoryUI\",\n                \"type\": \"datagrid\",\n                \"hint\": {\n                  \"label\": \"How to use\",\n                  \"value\": \"\\n1. Key and value pair to be updated. For example: if you have the following State:\\n    | Key       | Operation     | Default Value     |\\n    |-----------|---------------|-------------------|\\n    | user      | Replace       |                   |\\n\\n    You can update the \\\"user\\\" value with the following:\\n    | Key       | Value     |\\n    |-----------|-----------|\\n    | user      | john doe  |\\n\\n2. If you want to use the Agent's output as the value to update state, it is available as available as `$flow.output` with the following structure:\\n    ```json\\n    {\\n        \\\"content\\\": \\\"Hello! How can I assist you today?\\\",\\n        \\\"usedTools\\\": [\\n            {\\n                \\\"tool\\\": \\\"tool-name\\\",\\n                \\\"toolInput\\\": \\\"{foo: var}\\\",\\n                \\\"toolOutput\\\": \\\"This is the tool's output\\\"\\n            }\\n        ],\\n        \\\"sourceDocuments\\\": [\\n            {\\n                \\\"pageContent\\\": \\\"This is the page content\\\",\\n                \\\"metadata\\\": \\\"{foo: var}\\\"\\n            }\\n        ]\\n    }\\n    ```\\n\\n    For example, if the `toolOutput` is the value you want to update the state with, you can do the following:\\n    | Key       | Value                                     |\\n    |-----------|-------------------------------------------|\\n    | user      | `$flow.output.usedTools[0].toolOutput`  |\\n\\n3. You can get default flow config, including the current \\\"state\\\":\\n    - `$flow.sessionId`\\n    - `$flow.chatId`\\n    - `$flow.chatflowId`\\n    - `$flow.input`\\n    - `$flow.state`\\n\\n4. You can get custom variables: `$vars.<variable-name>`\\n\\n\"\n                },\n                \"description\": \"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values\",\n                \"datagrid\": [\n                  {\n                    \"field\": \"key\",\n                    \"headerName\": \"Key\",\n                    \"type\": \"asyncSingleSelect\",\n                    \"loadMethod\": \"loadStateKeys\",\n                    \"flex\": 0.5,\n                    \"editable\": true\n                  },\n                  {\n                    \"field\": \"value\",\n                    \"headerName\": \"Value\",\n                    \"type\": \"freeSolo\",\n                    \"valueOptions\": [\n                      {\n                        \"label\": \"Agent Output (string)\",\n                        \"value\": \"$flow.output.content\"\n                      },\n                      {\n                        \"label\": \"Used Tools (array)\",\n                        \"value\": \"$flow.output.usedTools\"\n                      },\n                      {\n                        \"label\": \"First Tool Output (string)\",\n                        \"value\": \"$flow.output.usedTools[0].toolOutput\"\n                      },\n                      {\n                        \"label\": \"Source Documents (array)\",\n                        \"value\": \"$flow.output.sourceDocuments\"\n                      },\n                      {\n                        \"label\": \"Global variable (string)\",\n                        \"value\": \"$vars.<variable-name>\"\n                      },\n                      {\n                        \"label\": \"Input Question (string)\",\n                        \"value\": \"$flow.input\"\n                      },\n                      {\n                        \"label\": \"Session Id (string)\",\n                        \"value\": \"$flow.sessionId\"\n                      },\n                      {\n                        \"label\": \"Chat Id (string)\",\n                        \"value\": \"$flow.chatId\"\n                      },\n                      {\n                        \"label\": \"Chatflow Id (string)\",\n                        \"value\": \"$flow.chatflowId\"\n                      }\n                    ],\n                    \"editable\": true,\n                    \"flex\": 1\n                  }\n                ],\n                \"optional\": true,\n                \"additionalParams\": true\n              },\n              {\n                \"label\": \"Update State (Code)\",\n                \"name\": \"updateStateMemoryCode\",\n                \"type\": \"code\",\n                \"hint\": {\n                  \"label\": \"How to use\",\n                  \"value\": \"\\n1. Return the key value JSON object. For example: if you have the following State:\\n    ```json\\n    {\\n        \\\"user\\\": null\\n    }\\n    ```\\n\\n    You can update the \\\"user\\\" value by returning the following:\\n    ```js\\n    return {\\n        \\\"user\\\": \\\"john doe\\\"\\n    }\\n    ```\\n\\n2. If you want to use the agent's output as the value to update state, it is available as `$flow.output` with the following structure:\\n    ```json\\n    {\\n        \\\"content\\\": \\\"Hello! How can I assist you today?\\\",\\n        \\\"usedTools\\\": [\\n            {\\n                \\\"tool\\\": \\\"tool-name\\\",\\n                \\\"toolInput\\\": \\\"{foo: var}\\\",\\n                \\\"toolOutput\\\": \\\"This is the tool's output\\\"\\n            }\\n        ],\\n        \\\"sourceDocuments\\\": [\\n            {\\n                \\\"pageContent\\\": \\\"This is the page content\\\",\\n                \\\"metadata\\\": \\\"{foo: var}\\\"\\n            }\\n        ]\\n    }\\n    ```\\n\\n    For example, if the `toolOutput` is the value you want to update the state with, you can return the following:\\n    ```js\\n    return {\\n        \\\"user\\\": $flow.output.usedTools[0].toolOutput\\n    }\\n    ```\\n\\n3. You can also get default flow config, including the current \\\"state\\\":\\n    - `$flow.sessionId`\\n    - `$flow.chatId`\\n    - `$flow.chatflowId`\\n    - `$flow.input`\\n    - `$flow.state`\\n\\n4. You can get custom variables: `$vars.<variable-name>`\\n\\n\"\n                },\n                \"description\": \"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. Must return an object representing the state\",\n                \"hideCodeExecute\": true,\n                \"codeExample\": \"const result = $flow.output;\\n\\n/* Suppose we have a custom State schema like this:\\n* {\\n    aggregate: {\\n        value: (x, y) => x.concat(y),\\n        default: () => []\\n    }\\n  }\\n*/\\n\\nreturn {\\n  aggregate: [result.content]\\n};\",\n                \"optional\": true,\n                \"additionalParams\": true\n              }\n            ],\n            \"id\": \"seqAgent_5-input-updateStateMemory-tabs\"\n          },\n          {\n            \"label\": \"Max Iterations\",\n            \"name\": \"maxIterations\",\n            \"type\": \"number\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_5-input-maxIterations-number\"\n          }\n        ],\n        \"inputAnchors\": [\n          {\n            \"label\": \"Tools\",\n            \"name\": \"tools\",\n            \"type\": \"Tool\",\n            \"list\": true,\n            \"optional\": true,\n            \"id\": \"seqAgent_5-input-tools-Tool\"\n          },\n          {\n            \"label\": \"Start | Agent | Condition | LLM | Tool Node\",\n            \"name\": \"sequentialNode\",\n            \"type\": \"Start | Agent | Condition | LLMNode | ToolNode\",\n            \"list\": true,\n            \"id\": \"seqAgent_5-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode\"\n          },\n          {\n            \"label\": \"Chat Model\",\n            \"name\": \"model\",\n            \"type\": \"BaseChatModel\",\n            \"optional\": true,\n            \"description\": \"Overwrite model to be used for this agent\",\n            \"id\": \"seqAgent_5-input-model-BaseChatModel\"\n          }\n        ],\n        \"inputs\": {\n          \"agentName\": \"gemma2\",\n          \"systemMessagePrompt\": \"You will edit and improve the previous response.\",\n          \"messageHistory\": \"\",\n          \"conversationHistorySelection\": \"all_messages\",\n          \"humanMessagePrompt\": \"\",\n          \"tools\": [],\n          \"sequentialNode\": [\n            \"{{seqAgent_1.data.instance}}\"\n          ],\n          \"model\": \"{{chatOllama_1.data.instance}}\",\n          \"interrupt\": \"\",\n          \"promptValues\": \"\",\n          \"approvalPrompt\": \"You are about to execute tool: {tools}. Ask if user want to proceed\",\n          \"approveButtonText\": \"Yes\",\n          \"rejectButtonText\": \"No\",\n          \"updateStateMemory\": \"updateStateMemoryUI\",\n          \"maxIterations\": \"\"\n        },\n        \"outputAnchors\": [\n          {\n            \"id\": \"seqAgent_5-output-seqAgent-Agent\",\n            \"name\": \"seqAgent\",\n            \"label\": \"Agent\",\n            \"description\": \"Agent that can execute tools\",\n            \"type\": \"Agent\"\n          }\n        ],\n        \"outputs\": {},\n        \"selected\": false\n      },\n      \"width\": 300,\n      \"height\": 879,\n      \"selected\": false,\n      \"positionAbsolute\": {\n        \"x\": 3780.9837304604243,\n        \"y\": -850.6074044632425\n      },\n      \"dragging\": false\n    },\n    {\n      \"id\": \"seqAgent_6\",\n      \"position\": {\n        \"x\": 5907.622615152902,\n        \"y\": -1002.2912313696522\n      },\n      \"type\": \"customNode\",\n      \"data\": {\n        \"id\": \"seqAgent_6\",\n        \"label\": \"Agent\",\n        \"version\": 4,\n        \"name\": \"seqAgent\",\n        \"type\": \"Agent\",\n        \"baseClasses\": [\n          \"Agent\"\n        ],\n        \"category\": \"Sequential Agents\",\n        \"description\": \"Agent that can execute tools\",\n        \"inputParams\": [\n          {\n            \"label\": \"Agent Name\",\n            \"name\": \"agentName\",\n            \"type\": \"string\",\n            \"placeholder\": \"Agent\",\n            \"id\": \"seqAgent_6-input-agentName-string\"\n          },\n          {\n            \"label\": \"System Prompt\",\n            \"name\": \"systemMessagePrompt\",\n            \"type\": \"string\",\n            \"rows\": 4,\n            \"optional\": true,\n            \"default\": \"You are a research assistant who can search for up-to-date info using search engine.\",\n            \"id\": \"seqAgent_6-input-systemMessagePrompt-string\"\n          },\n          {\n            \"label\": \"Prepend Messages History\",\n            \"name\": \"messageHistory\",\n            \"description\": \"Prepend a list of messages between System Prompt and Human Prompt. This is useful when you want to provide few shot examples\",\n            \"type\": \"code\",\n            \"hideCodeExecute\": true,\n            \"codeExample\": \"const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\\n\\nreturn [\\n    new HumanMessage(\\\"What is 333382 🦜 1932?\\\"),\\n    new AIMessage({\\n        content: \\\"\\\",\\n        tool_calls: [\\n        {\\n            id: \\\"12345\\\",\\n            name: \\\"calulator\\\",\\n            args: {\\n                number1: 333382,\\n                number2: 1932,\\n                operation: \\\"divide\\\",\\n            },\\n        },\\n        ],\\n    }),\\n    new ToolMessage({\\n        tool_call_id: \\\"12345\\\",\\n        content: \\\"The answer is 172.558.\\\",\\n    }),\\n    new AIMessage(\\\"The answer is 172.558.\\\"),\\n]\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_6-input-messageHistory-code\"\n          },\n          {\n            \"label\": \"Conversation History\",\n            \"name\": \"conversationHistorySelection\",\n            \"type\": \"options\",\n            \"options\": [\n              {\n                \"label\": \"User Question\",\n                \"name\": \"user_question\",\n                \"description\": \"Use the user question from the historical conversation messages as input.\"\n              },\n              {\n                \"label\": \"Last Conversation Message\",\n                \"name\": \"last_message\",\n                \"description\": \"Use the last conversation message from the historical conversation messages as input.\"\n              },\n              {\n                \"label\": \"All Conversation Messages\",\n                \"name\": \"all_messages\",\n                \"description\": \"Use all conversation messages from the historical conversation messages as input.\"\n              },\n              {\n                \"label\": \"Empty\",\n                \"name\": \"empty\",\n                \"description\": \"Do not use any messages from the conversation history. Ensure to use either System Prompt, Human Prompt, or Messages History.\"\n              }\n            ],\n            \"default\": \"all_messages\",\n            \"optional\": true,\n            \"description\": \"Select which messages from the conversation history to include in the prompt. The selected messages will be inserted between the System Prompt (if defined) and [Messages History, Human Prompt].\",\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_6-input-conversationHistorySelection-options\"\n          },\n          {\n            \"label\": \"Human Prompt\",\n            \"name\": \"humanMessagePrompt\",\n            \"type\": \"string\",\n            \"description\": \"This prompt will be added at the end of the messages as human message\",\n            \"rows\": 4,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_6-input-humanMessagePrompt-string\"\n          },\n          {\n            \"label\": \"Require Approval\",\n            \"name\": \"interrupt\",\n            \"description\": \"Pause execution and request user approval before running tools.\\nIf enabled, the agent will prompt the user with customizable approve/reject options\\nand will proceed only after approval. This requires a configured agent memory to manage\\nthe state and handle approval requests.\\nIf no tools are invoked, the agent proceeds without interruption.\",\n            \"type\": \"boolean\",\n            \"optional\": true,\n            \"id\": \"seqAgent_6-input-interrupt-boolean\"\n          },\n          {\n            \"label\": \"Format Prompt Values\",\n            \"name\": \"promptValues\",\n            \"description\": \"Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value\",\n            \"type\": \"json\",\n            \"optional\": true,\n            \"acceptVariable\": true,\n            \"list\": true,\n            \"id\": \"seqAgent_6-input-promptValues-json\"\n          },\n          {\n            \"label\": \"Approval Prompt\",\n            \"name\": \"approvalPrompt\",\n            \"description\": \"Prompt for approval. Only applicable if \\\"Require Approval\\\" is enabled\",\n            \"type\": \"string\",\n            \"default\": \"You are about to execute tool: {tools}. Ask if user want to proceed\",\n            \"rows\": 4,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_6-input-approvalPrompt-string\"\n          },\n          {\n            \"label\": \"Approve Button Text\",\n            \"name\": \"approveButtonText\",\n            \"description\": \"Text for approve button. Only applicable if \\\"Require Approval\\\" is enabled\",\n            \"type\": \"string\",\n            \"default\": \"Yes\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_6-input-approveButtonText-string\"\n          },\n          {\n            \"label\": \"Reject Button Text\",\n            \"name\": \"rejectButtonText\",\n            \"description\": \"Text for reject button. Only applicable if \\\"Require Approval\\\" is enabled\",\n            \"type\": \"string\",\n            \"default\": \"No\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_6-input-rejectButtonText-string\"\n          },\n          {\n            \"label\": \"Update State\",\n            \"name\": \"updateStateMemory\",\n            \"type\": \"tabs\",\n            \"tabIdentifier\": \"selectedUpdateStateMemoryTab\",\n            \"additionalParams\": true,\n            \"default\": \"updateStateMemoryUI\",\n            \"tabs\": [\n              {\n                \"label\": \"Update State (Table)\",\n                \"name\": \"updateStateMemoryUI\",\n                \"type\": \"datagrid\",\n                \"hint\": {\n                  \"label\": \"How to use\",\n                  \"value\": \"\\n1. Key and value pair to be updated. For example: if you have the following State:\\n    | Key       | Operation     | Default Value     |\\n    |-----------|---------------|-------------------|\\n    | user      | Replace       |                   |\\n\\n    You can update the \\\"user\\\" value with the following:\\n    | Key       | Value     |\\n    |-----------|-----------|\\n    | user      | john doe  |\\n\\n2. If you want to use the Agent's output as the value to update state, it is available as available as `$flow.output` with the following structure:\\n    ```json\\n    {\\n        \\\"content\\\": \\\"Hello! How can I assist you today?\\\",\\n        \\\"usedTools\\\": [\\n            {\\n                \\\"tool\\\": \\\"tool-name\\\",\\n                \\\"toolInput\\\": \\\"{foo: var}\\\",\\n                \\\"toolOutput\\\": \\\"This is the tool's output\\\"\\n            }\\n        ],\\n        \\\"sourceDocuments\\\": [\\n            {\\n                \\\"pageContent\\\": \\\"This is the page content\\\",\\n                \\\"metadata\\\": \\\"{foo: var}\\\"\\n            }\\n        ]\\n    }\\n    ```\\n\\n    For example, if the `toolOutput` is the value you want to update the state with, you can do the following:\\n    | Key       | Value                                     |\\n    |-----------|-------------------------------------------|\\n    | user      | `$flow.output.usedTools[0].toolOutput`  |\\n\\n3. You can get default flow config, including the current \\\"state\\\":\\n    - `$flow.sessionId`\\n    - `$flow.chatId`\\n    - `$flow.chatflowId`\\n    - `$flow.input`\\n    - `$flow.state`\\n\\n4. You can get custom variables: `$vars.<variable-name>`\\n\\n\"\n                },\n                \"description\": \"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values\",\n                \"datagrid\": [\n                  {\n                    \"field\": \"key\",\n                    \"headerName\": \"Key\",\n                    \"type\": \"asyncSingleSelect\",\n                    \"loadMethod\": \"loadStateKeys\",\n                    \"flex\": 0.5,\n                    \"editable\": true\n                  },\n                  {\n                    \"field\": \"value\",\n                    \"headerName\": \"Value\",\n                    \"type\": \"freeSolo\",\n                    \"valueOptions\": [\n                      {\n                        \"label\": \"Agent Output (string)\",\n                        \"value\": \"$flow.output.content\"\n                      },\n                      {\n                        \"label\": \"Used Tools (array)\",\n                        \"value\": \"$flow.output.usedTools\"\n                      },\n                      {\n                        \"label\": \"First Tool Output (string)\",\n                        \"value\": \"$flow.output.usedTools[0].toolOutput\"\n                      },\n                      {\n                        \"label\": \"Source Documents (array)\",\n                        \"value\": \"$flow.output.sourceDocuments\"\n                      },\n                      {\n                        \"label\": \"Global variable (string)\",\n                        \"value\": \"$vars.<variable-name>\"\n                      },\n                      {\n                        \"label\": \"Input Question (string)\",\n                        \"value\": \"$flow.input\"\n                      },\n                      {\n                        \"label\": \"Session Id (string)\",\n                        \"value\": \"$flow.sessionId\"\n                      },\n                      {\n                        \"label\": \"Chat Id (string)\",\n                        \"value\": \"$flow.chatId\"\n                      },\n                      {\n                        \"label\": \"Chatflow Id (string)\",\n                        \"value\": \"$flow.chatflowId\"\n                      }\n                    ],\n                    \"editable\": true,\n                    \"flex\": 1\n                  }\n                ],\n                \"optional\": true,\n                \"additionalParams\": true\n              },\n              {\n                \"label\": \"Update State (Code)\",\n                \"name\": \"updateStateMemoryCode\",\n                \"type\": \"code\",\n                \"hint\": {\n                  \"label\": \"How to use\",\n                  \"value\": \"\\n1. Return the key value JSON object. For example: if you have the following State:\\n    ```json\\n    {\\n        \\\"user\\\": null\\n    }\\n    ```\\n\\n    You can update the \\\"user\\\" value by returning the following:\\n    ```js\\n    return {\\n        \\\"user\\\": \\\"john doe\\\"\\n    }\\n    ```\\n\\n2. If you want to use the agent's output as the value to update state, it is available as `$flow.output` with the following structure:\\n    ```json\\n    {\\n        \\\"content\\\": \\\"Hello! How can I assist you today?\\\",\\n        \\\"usedTools\\\": [\\n            {\\n                \\\"tool\\\": \\\"tool-name\\\",\\n                \\\"toolInput\\\": \\\"{foo: var}\\\",\\n                \\\"toolOutput\\\": \\\"This is the tool's output\\\"\\n            }\\n        ],\\n        \\\"sourceDocuments\\\": [\\n            {\\n                \\\"pageContent\\\": \\\"This is the page content\\\",\\n                \\\"metadata\\\": \\\"{foo: var}\\\"\\n            }\\n        ]\\n    }\\n    ```\\n\\n    For example, if the `toolOutput` is the value you want to update the state with, you can return the following:\\n    ```js\\n    return {\\n        \\\"user\\\": $flow.output.usedTools[0].toolOutput\\n    }\\n    ```\\n\\n3. You can also get default flow config, including the current \\\"state\\\":\\n    - `$flow.sessionId`\\n    - `$flow.chatId`\\n    - `$flow.chatflowId`\\n    - `$flow.input`\\n    - `$flow.state`\\n\\n4. You can get custom variables: `$vars.<variable-name>`\\n\\n\"\n                },\n                \"description\": \"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. Must return an object representing the state\",\n                \"hideCodeExecute\": true,\n                \"codeExample\": \"const result = $flow.output;\\n\\n/* Suppose we have a custom State schema like this:\\n* {\\n    aggregate: {\\n        value: (x, y) => x.concat(y),\\n        default: () => []\\n    }\\n  }\\n*/\\n\\nreturn {\\n  aggregate: [result.content]\\n};\",\n                \"optional\": true,\n                \"additionalParams\": true\n              }\n            ],\n            \"id\": \"seqAgent_6-input-updateStateMemory-tabs\"\n          },\n          {\n            \"label\": \"Max Iterations\",\n            \"name\": \"maxIterations\",\n            \"type\": \"number\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_6-input-maxIterations-number\"\n          }\n        ],\n        \"inputAnchors\": [\n          {\n            \"label\": \"Tools\",\n            \"name\": \"tools\",\n            \"type\": \"Tool\",\n            \"list\": true,\n            \"optional\": true,\n            \"id\": \"seqAgent_6-input-tools-Tool\"\n          },\n          {\n            \"label\": \"Start | Agent | Condition | LLM | Tool Node\",\n            \"name\": \"sequentialNode\",\n            \"type\": \"Start | Agent | Condition | LLMNode | ToolNode\",\n            \"list\": true,\n            \"id\": \"seqAgent_6-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode\"\n          },\n          {\n            \"label\": \"Chat Model\",\n            \"name\": \"model\",\n            \"type\": \"BaseChatModel\",\n            \"optional\": true,\n            \"description\": \"Overwrite model to be used for this agent\",\n            \"id\": \"seqAgent_6-input-model-BaseChatModel\"\n          }\n        ],\n        \"inputs\": {\n          \"agentName\": \"llama3\",\n          \"systemMessagePrompt\": \"You will edit and improve the previous response.\",\n          \"messageHistory\": \"\",\n          \"conversationHistorySelection\": \"all_messages\",\n          \"humanMessagePrompt\": \"\",\n          \"tools\": [\n            \"{{retrieverTool_0.data.instance}}\"\n          ],\n          \"sequentialNode\": [\n            \"{{seqAgent_8.data.instance}}\"\n          ],\n          \"model\": \"\",\n          \"interrupt\": \"\",\n          \"promptValues\": \"\",\n          \"approvalPrompt\": \"You are about to execute tool: {tools}. Ask if user want to proceed\",\n          \"approveButtonText\": \"Yes\",\n          \"rejectButtonText\": \"No\",\n          \"updateStateMemory\": \"updateStateMemoryUI\",\n          \"maxIterations\": \"\"\n        },\n        \"outputAnchors\": [\n          {\n            \"id\": \"seqAgent_6-output-seqAgent-Agent\",\n            \"name\": \"seqAgent\",\n            \"label\": \"Agent\",\n            \"description\": \"Agent that can execute tools\",\n            \"type\": \"Agent\"\n          }\n        ],\n        \"outputs\": {},\n        \"selected\": false\n      },\n      \"width\": 300,\n      \"height\": 879,\n      \"selected\": false,\n      \"positionAbsolute\": {\n        \"x\": 5907.622615152902,\n        \"y\": -1002.2912313696522\n      },\n      \"dragging\": false\n    },\n    {\n      \"id\": \"seqAgent_7\",\n      \"position\": {\n        \"x\": 6639.8870163523,\n        \"y\": -1267.1620877607909\n      },\n      \"type\": \"customNode\",\n      \"data\": {\n        \"id\": \"seqAgent_7\",\n        \"label\": \"Agent\",\n        \"version\": 4,\n        \"name\": \"seqAgent\",\n        \"type\": \"Agent\",\n        \"baseClasses\": [\n          \"Agent\"\n        ],\n        \"category\": \"Sequential Agents\",\n        \"description\": \"Agent that can execute tools\",\n        \"inputParams\": [\n          {\n            \"label\": \"Agent Name\",\n            \"name\": \"agentName\",\n            \"type\": \"string\",\n            \"placeholder\": \"Agent\",\n            \"id\": \"seqAgent_7-input-agentName-string\"\n          },\n          {\n            \"label\": \"System Prompt\",\n            \"name\": \"systemMessagePrompt\",\n            \"type\": \"string\",\n            \"rows\": 4,\n            \"optional\": true,\n            \"default\": \"You are a research assistant who can search for up-to-date info using search engine.\",\n            \"id\": \"seqAgent_7-input-systemMessagePrompt-string\"\n          },\n          {\n            \"label\": \"Prepend Messages History\",\n            \"name\": \"messageHistory\",\n            \"description\": \"Prepend a list of messages between System Prompt and Human Prompt. This is useful when you want to provide few shot examples\",\n            \"type\": \"code\",\n            \"hideCodeExecute\": true,\n            \"codeExample\": \"const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\\n\\nreturn [\\n    new HumanMessage(\\\"What is 333382 🦜 1932?\\\"),\\n    new AIMessage({\\n        content: \\\"\\\",\\n        tool_calls: [\\n        {\\n            id: \\\"12345\\\",\\n            name: \\\"calulator\\\",\\n            args: {\\n                number1: 333382,\\n                number2: 1932,\\n                operation: \\\"divide\\\",\\n            },\\n        },\\n        ],\\n    }),\\n    new ToolMessage({\\n        tool_call_id: \\\"12345\\\",\\n        content: \\\"The answer is 172.558.\\\",\\n    }),\\n    new AIMessage(\\\"The answer is 172.558.\\\"),\\n]\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_7-input-messageHistory-code\"\n          },\n          {\n            \"label\": \"Conversation History\",\n            \"name\": \"conversationHistorySelection\",\n            \"type\": \"options\",\n            \"options\": [\n              {\n                \"label\": \"User Question\",\n                \"name\": \"user_question\",\n                \"description\": \"Use the user question from the historical conversation messages as input.\"\n              },\n              {\n                \"label\": \"Last Conversation Message\",\n                \"name\": \"last_message\",\n                \"description\": \"Use the last conversation message from the historical conversation messages as input.\"\n              },\n              {\n                \"label\": \"All Conversation Messages\",\n                \"name\": \"all_messages\",\n                \"description\": \"Use all conversation messages from the historical conversation messages as input.\"\n              },\n              {\n                \"label\": \"Empty\",\n                \"name\": \"empty\",\n                \"description\": \"Do not use any messages from the conversation history. Ensure to use either System Prompt, Human Prompt, or Messages History.\"\n              }\n            ],\n            \"default\": \"all_messages\",\n            \"optional\": true,\n            \"description\": \"Select which messages from the conversation history to include in the prompt. The selected messages will be inserted between the System Prompt (if defined) and [Messages History, Human Prompt].\",\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_7-input-conversationHistorySelection-options\"\n          },\n          {\n            \"label\": \"Human Prompt\",\n            \"name\": \"humanMessagePrompt\",\n            \"type\": \"string\",\n            \"description\": \"This prompt will be added at the end of the messages as human message\",\n            \"rows\": 4,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_7-input-humanMessagePrompt-string\"\n          },\n          {\n            \"label\": \"Require Approval\",\n            \"name\": \"interrupt\",\n            \"description\": \"Pause execution and request user approval before running tools.\\nIf enabled, the agent will prompt the user with customizable approve/reject options\\nand will proceed only after approval. This requires a configured agent memory to manage\\nthe state and handle approval requests.\\nIf no tools are invoked, the agent proceeds without interruption.\",\n            \"type\": \"boolean\",\n            \"optional\": true,\n            \"id\": \"seqAgent_7-input-interrupt-boolean\"\n          },\n          {\n            \"label\": \"Format Prompt Values\",\n            \"name\": \"promptValues\",\n            \"description\": \"Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value\",\n            \"type\": \"json\",\n            \"optional\": true,\n            \"acceptVariable\": true,\n            \"list\": true,\n            \"id\": \"seqAgent_7-input-promptValues-json\"\n          },\n          {\n            \"label\": \"Approval Prompt\",\n            \"name\": \"approvalPrompt\",\n            \"description\": \"Prompt for approval. Only applicable if \\\"Require Approval\\\" is enabled\",\n            \"type\": \"string\",\n            \"default\": \"You are about to execute tool: {tools}. Ask if user want to proceed\",\n            \"rows\": 4,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_7-input-approvalPrompt-string\"\n          },\n          {\n            \"label\": \"Approve Button Text\",\n            \"name\": \"approveButtonText\",\n            \"description\": \"Text for approve button. Only applicable if \\\"Require Approval\\\" is enabled\",\n            \"type\": \"string\",\n            \"default\": \"Yes\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_7-input-approveButtonText-string\"\n          },\n          {\n            \"label\": \"Reject Button Text\",\n            \"name\": \"rejectButtonText\",\n            \"description\": \"Text for reject button. Only applicable if \\\"Require Approval\\\" is enabled\",\n            \"type\": \"string\",\n            \"default\": \"No\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_7-input-rejectButtonText-string\"\n          },\n          {\n            \"label\": \"Update State\",\n            \"name\": \"updateStateMemory\",\n            \"type\": \"tabs\",\n            \"tabIdentifier\": \"selectedUpdateStateMemoryTab\",\n            \"additionalParams\": true,\n            \"default\": \"updateStateMemoryUI\",\n            \"tabs\": [\n              {\n                \"label\": \"Update State (Table)\",\n                \"name\": \"updateStateMemoryUI\",\n                \"type\": \"datagrid\",\n                \"hint\": {\n                  \"label\": \"How to use\",\n                  \"value\": \"\\n1. Key and value pair to be updated. For example: if you have the following State:\\n    | Key       | Operation     | Default Value     |\\n    |-----------|---------------|-------------------|\\n    | user      | Replace       |                   |\\n\\n    You can update the \\\"user\\\" value with the following:\\n    | Key       | Value     |\\n    |-----------|-----------|\\n    | user      | john doe  |\\n\\n2. If you want to use the Agent's output as the value to update state, it is available as available as `$flow.output` with the following structure:\\n    ```json\\n    {\\n        \\\"content\\\": \\\"Hello! How can I assist you today?\\\",\\n        \\\"usedTools\\\": [\\n            {\\n                \\\"tool\\\": \\\"tool-name\\\",\\n                \\\"toolInput\\\": \\\"{foo: var}\\\",\\n                \\\"toolOutput\\\": \\\"This is the tool's output\\\"\\n            }\\n        ],\\n        \\\"sourceDocuments\\\": [\\n            {\\n                \\\"pageContent\\\": \\\"This is the page content\\\",\\n                \\\"metadata\\\": \\\"{foo: var}\\\"\\n            }\\n        ]\\n    }\\n    ```\\n\\n    For example, if the `toolOutput` is the value you want to update the state with, you can do the following:\\n    | Key       | Value                                     |\\n    |-----------|-------------------------------------------|\\n    | user      | `$flow.output.usedTools[0].toolOutput`  |\\n\\n3. You can get default flow config, including the current \\\"state\\\":\\n    - `$flow.sessionId`\\n    - `$flow.chatId`\\n    - `$flow.chatflowId`\\n    - `$flow.input`\\n    - `$flow.state`\\n\\n4. You can get custom variables: `$vars.<variable-name>`\\n\\n\"\n                },\n                \"description\": \"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values\",\n                \"datagrid\": [\n                  {\n                    \"field\": \"key\",\n                    \"headerName\": \"Key\",\n                    \"type\": \"asyncSingleSelect\",\n                    \"loadMethod\": \"loadStateKeys\",\n                    \"flex\": 0.5,\n                    \"editable\": true\n                  },\n                  {\n                    \"field\": \"value\",\n                    \"headerName\": \"Value\",\n                    \"type\": \"freeSolo\",\n                    \"valueOptions\": [\n                      {\n                        \"label\": \"Agent Output (string)\",\n                        \"value\": \"$flow.output.content\"\n                      },\n                      {\n                        \"label\": \"Used Tools (array)\",\n                        \"value\": \"$flow.output.usedTools\"\n                      },\n                      {\n                        \"label\": \"First Tool Output (string)\",\n                        \"value\": \"$flow.output.usedTools[0].toolOutput\"\n                      },\n                      {\n                        \"label\": \"Source Documents (array)\",\n                        \"value\": \"$flow.output.sourceDocuments\"\n                      },\n                      {\n                        \"label\": \"Global variable (string)\",\n                        \"value\": \"$vars.<variable-name>\"\n                      },\n                      {\n                        \"label\": \"Input Question (string)\",\n                        \"value\": \"$flow.input\"\n                      },\n                      {\n                        \"label\": \"Session Id (string)\",\n                        \"value\": \"$flow.sessionId\"\n                      },\n                      {\n                        \"label\": \"Chat Id (string)\",\n                        \"value\": \"$flow.chatId\"\n                      },\n                      {\n                        \"label\": \"Chatflow Id (string)\",\n                        \"value\": \"$flow.chatflowId\"\n                      }\n                    ],\n                    \"editable\": true,\n                    \"flex\": 1\n                  }\n                ],\n                \"optional\": true,\n                \"additionalParams\": true\n              },\n              {\n                \"label\": \"Update State (Code)\",\n                \"name\": \"updateStateMemoryCode\",\n                \"type\": \"code\",\n                \"hint\": {\n                  \"label\": \"How to use\",\n                  \"value\": \"\\n1. Return the key value JSON object. For example: if you have the following State:\\n    ```json\\n    {\\n        \\\"user\\\": null\\n    }\\n    ```\\n\\n    You can update the \\\"user\\\" value by returning the following:\\n    ```js\\n    return {\\n        \\\"user\\\": \\\"john doe\\\"\\n    }\\n    ```\\n\\n2. If you want to use the agent's output as the value to update state, it is available as `$flow.output` with the following structure:\\n    ```json\\n    {\\n        \\\"content\\\": \\\"Hello! How can I assist you today?\\\",\\n        \\\"usedTools\\\": [\\n            {\\n                \\\"tool\\\": \\\"tool-name\\\",\\n                \\\"toolInput\\\": \\\"{foo: var}\\\",\\n                \\\"toolOutput\\\": \\\"This is the tool's output\\\"\\n            }\\n        ],\\n        \\\"sourceDocuments\\\": [\\n            {\\n                \\\"pageContent\\\": \\\"This is the page content\\\",\\n                \\\"metadata\\\": \\\"{foo: var}\\\"\\n            }\\n        ]\\n    }\\n    ```\\n\\n    For example, if the `toolOutput` is the value you want to update the state with, you can return the following:\\n    ```js\\n    return {\\n        \\\"user\\\": $flow.output.usedTools[0].toolOutput\\n    }\\n    ```\\n\\n3. You can also get default flow config, including the current \\\"state\\\":\\n    - `$flow.sessionId`\\n    - `$flow.chatId`\\n    - `$flow.chatflowId`\\n    - `$flow.input`\\n    - `$flow.state`\\n\\n4. You can get custom variables: `$vars.<variable-name>`\\n\\n\"\n                },\n                \"description\": \"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. Must return an object representing the state\",\n                \"hideCodeExecute\": true,\n                \"codeExample\": \"const result = $flow.output;\\n\\n/* Suppose we have a custom State schema like this:\\n* {\\n    aggregate: {\\n        value: (x, y) => x.concat(y),\\n        default: () => []\\n    }\\n  }\\n*/\\n\\nreturn {\\n  aggregate: [result.content]\\n};\",\n                \"optional\": true,\n                \"additionalParams\": true\n              }\n            ],\n            \"id\": \"seqAgent_7-input-updateStateMemory-tabs\"\n          },\n          {\n            \"label\": \"Max Iterations\",\n            \"name\": \"maxIterations\",\n            \"type\": \"number\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_7-input-maxIterations-number\"\n          }\n        ],\n        \"inputAnchors\": [\n          {\n            \"label\": \"Tools\",\n            \"name\": \"tools\",\n            \"type\": \"Tool\",\n            \"list\": true,\n            \"optional\": true,\n            \"id\": \"seqAgent_7-input-tools-Tool\"\n          },\n          {\n            \"label\": \"Start | Agent | Condition | LLM | Tool Node\",\n            \"name\": \"sequentialNode\",\n            \"type\": \"Start | Agent | Condition | LLMNode | ToolNode\",\n            \"list\": true,\n            \"id\": \"seqAgent_7-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode\"\n          },\n          {\n            \"label\": \"Chat Model\",\n            \"name\": \"model\",\n            \"type\": \"BaseChatModel\",\n            \"optional\": true,\n            \"description\": \"Overwrite model to be used for this agent\",\n            \"id\": \"seqAgent_7-input-model-BaseChatModel\"\n          }\n        ],\n        \"inputs\": {\n          \"agentName\": \"mistral3\",\n          \"systemMessagePrompt\": \"You will edit and improve the previous response.\",\n          \"messageHistory\": \"\",\n          \"conversationHistorySelection\": \"all_messages\",\n          \"humanMessagePrompt\": \"\",\n          \"tools\": [\n            \"{{retrieverTool_0.data.instance}}\"\n          ],\n          \"sequentialNode\": [\n            \"{{seqAgent_6.data.instance}}\"\n          ],\n          \"model\": \"{{chatOllama_2.data.instance}}\",\n          \"interrupt\": \"\",\n          \"promptValues\": \"\",\n          \"approvalPrompt\": \"You are about to execute tool: {tools}. Ask if user want to proceed\",\n          \"approveButtonText\": \"Yes\",\n          \"rejectButtonText\": \"No\",\n          \"updateStateMemory\": \"updateStateMemoryUI\",\n          \"maxIterations\": \"\"\n        },\n        \"outputAnchors\": [\n          {\n            \"id\": \"seqAgent_7-output-seqAgent-Agent\",\n            \"name\": \"seqAgent\",\n            \"label\": \"Agent\",\n            \"description\": \"Agent that can execute tools\",\n            \"type\": \"Agent\"\n          }\n        ],\n        \"outputs\": {},\n        \"selected\": false\n      },\n      \"width\": 300,\n      \"height\": 879,\n      \"selected\": false,\n      \"positionAbsolute\": {\n        \"x\": 6639.8870163523,\n        \"y\": -1267.1620877607909\n      },\n      \"dragging\": false\n    },\n    {\n      \"id\": \"seqAgent_8\",\n      \"position\": {\n        \"x\": 5167.261298040595,\n        \"y\": -793.2614467222759\n      },\n      \"type\": \"customNode\",\n      \"data\": {\n        \"id\": \"seqAgent_8\",\n        \"label\": \"Agent\",\n        \"version\": 4,\n        \"name\": \"seqAgent\",\n        \"type\": \"Agent\",\n        \"baseClasses\": [\n          \"Agent\"\n        ],\n        \"category\": \"Sequential Agents\",\n        \"description\": \"Agent that can execute tools\",\n        \"inputParams\": [\n          {\n            \"label\": \"Agent Name\",\n            \"name\": \"agentName\",\n            \"type\": \"string\",\n            \"placeholder\": \"Agent\",\n            \"id\": \"seqAgent_8-input-agentName-string\"\n          },\n          {\n            \"label\": \"System Prompt\",\n            \"name\": \"systemMessagePrompt\",\n            \"type\": \"string\",\n            \"rows\": 4,\n            \"optional\": true,\n            \"default\": \"You are a research assistant who can search for up-to-date info using search engine.\",\n            \"id\": \"seqAgent_8-input-systemMessagePrompt-string\"\n          },\n          {\n            \"label\": \"Prepend Messages History\",\n            \"name\": \"messageHistory\",\n            \"description\": \"Prepend a list of messages between System Prompt and Human Prompt. This is useful when you want to provide few shot examples\",\n            \"type\": \"code\",\n            \"hideCodeExecute\": true,\n            \"codeExample\": \"const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\\n\\nreturn [\\n    new HumanMessage(\\\"What is 333382 🦜 1932?\\\"),\\n    new AIMessage({\\n        content: \\\"\\\",\\n        tool_calls: [\\n        {\\n            id: \\\"12345\\\",\\n            name: \\\"calulator\\\",\\n            args: {\\n                number1: 333382,\\n                number2: 1932,\\n                operation: \\\"divide\\\",\\n            },\\n        },\\n        ],\\n    }),\\n    new ToolMessage({\\n        tool_call_id: \\\"12345\\\",\\n        content: \\\"The answer is 172.558.\\\",\\n    }),\\n    new AIMessage(\\\"The answer is 172.558.\\\"),\\n]\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_8-input-messageHistory-code\"\n          },\n          {\n            \"label\": \"Conversation History\",\n            \"name\": \"conversationHistorySelection\",\n            \"type\": \"options\",\n            \"options\": [\n              {\n                \"label\": \"User Question\",\n                \"name\": \"user_question\",\n                \"description\": \"Use the user question from the historical conversation messages as input.\"\n              },\n              {\n                \"label\": \"Last Conversation Message\",\n                \"name\": \"last_message\",\n                \"description\": \"Use the last conversation message from the historical conversation messages as input.\"\n              },\n              {\n                \"label\": \"All Conversation Messages\",\n                \"name\": \"all_messages\",\n                \"description\": \"Use all conversation messages from the historical conversation messages as input.\"\n              },\n              {\n                \"label\": \"Empty\",\n                \"name\": \"empty\",\n                \"description\": \"Do not use any messages from the conversation history. Ensure to use either System Prompt, Human Prompt, or Messages History.\"\n              }\n            ],\n            \"default\": \"all_messages\",\n            \"optional\": true,\n            \"description\": \"Select which messages from the conversation history to include in the prompt. The selected messages will be inserted between the System Prompt (if defined) and [Messages History, Human Prompt].\",\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_8-input-conversationHistorySelection-options\"\n          },\n          {\n            \"label\": \"Human Prompt\",\n            \"name\": \"humanMessagePrompt\",\n            \"type\": \"string\",\n            \"description\": \"This prompt will be added at the end of the messages as human message\",\n            \"rows\": 4,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_8-input-humanMessagePrompt-string\"\n          },\n          {\n            \"label\": \"Require Approval\",\n            \"name\": \"interrupt\",\n            \"description\": \"Pause execution and request user approval before running tools.\\nIf enabled, the agent will prompt the user with customizable approve/reject options\\nand will proceed only after approval. This requires a configured agent memory to manage\\nthe state and handle approval requests.\\nIf no tools are invoked, the agent proceeds without interruption.\",\n            \"type\": \"boolean\",\n            \"optional\": true,\n            \"id\": \"seqAgent_8-input-interrupt-boolean\"\n          },\n          {\n            \"label\": \"Format Prompt Values\",\n            \"name\": \"promptValues\",\n            \"description\": \"Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value\",\n            \"type\": \"json\",\n            \"optional\": true,\n            \"acceptVariable\": true,\n            \"list\": true,\n            \"id\": \"seqAgent_8-input-promptValues-json\"\n          },\n          {\n            \"label\": \"Approval Prompt\",\n            \"name\": \"approvalPrompt\",\n            \"description\": \"Prompt for approval. Only applicable if \\\"Require Approval\\\" is enabled\",\n            \"type\": \"string\",\n            \"default\": \"You are about to execute tool: {tools}. Ask if user want to proceed\",\n            \"rows\": 4,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_8-input-approvalPrompt-string\"\n          },\n          {\n            \"label\": \"Approve Button Text\",\n            \"name\": \"approveButtonText\",\n            \"description\": \"Text for approve button. Only applicable if \\\"Require Approval\\\" is enabled\",\n            \"type\": \"string\",\n            \"default\": \"Yes\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_8-input-approveButtonText-string\"\n          },\n          {\n            \"label\": \"Reject Button Text\",\n            \"name\": \"rejectButtonText\",\n            \"description\": \"Text for reject button. Only applicable if \\\"Require Approval\\\" is enabled\",\n            \"type\": \"string\",\n            \"default\": \"No\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_8-input-rejectButtonText-string\"\n          },\n          {\n            \"label\": \"Update State\",\n            \"name\": \"updateStateMemory\",\n            \"type\": \"tabs\",\n            \"tabIdentifier\": \"selectedUpdateStateMemoryTab\",\n            \"additionalParams\": true,\n            \"default\": \"updateStateMemoryUI\",\n            \"tabs\": [\n              {\n                \"label\": \"Update State (Table)\",\n                \"name\": \"updateStateMemoryUI\",\n                \"type\": \"datagrid\",\n                \"hint\": {\n                  \"label\": \"How to use\",\n                  \"value\": \"\\n1. Key and value pair to be updated. For example: if you have the following State:\\n    | Key       | Operation     | Default Value     |\\n    |-----------|---------------|-------------------|\\n    | user      | Replace       |                   |\\n\\n    You can update the \\\"user\\\" value with the following:\\n    | Key       | Value     |\\n    |-----------|-----------|\\n    | user      | john doe  |\\n\\n2. If you want to use the Agent's output as the value to update state, it is available as available as `$flow.output` with the following structure:\\n    ```json\\n    {\\n        \\\"content\\\": \\\"Hello! How can I assist you today?\\\",\\n        \\\"usedTools\\\": [\\n            {\\n                \\\"tool\\\": \\\"tool-name\\\",\\n                \\\"toolInput\\\": \\\"{foo: var}\\\",\\n                \\\"toolOutput\\\": \\\"This is the tool's output\\\"\\n            }\\n        ],\\n        \\\"sourceDocuments\\\": [\\n            {\\n                \\\"pageContent\\\": \\\"This is the page content\\\",\\n                \\\"metadata\\\": \\\"{foo: var}\\\"\\n            }\\n        ]\\n    }\\n    ```\\n\\n    For example, if the `toolOutput` is the value you want to update the state with, you can do the following:\\n    | Key       | Value                                     |\\n    |-----------|-------------------------------------------|\\n    | user      | `$flow.output.usedTools[0].toolOutput`  |\\n\\n3. You can get default flow config, including the current \\\"state\\\":\\n    - `$flow.sessionId`\\n    - `$flow.chatId`\\n    - `$flow.chatflowId`\\n    - `$flow.input`\\n    - `$flow.state`\\n\\n4. You can get custom variables: `$vars.<variable-name>`\\n\\n\"\n                },\n                \"description\": \"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values\",\n                \"datagrid\": [\n                  {\n                    \"field\": \"key\",\n                    \"headerName\": \"Key\",\n                    \"type\": \"asyncSingleSelect\",\n                    \"loadMethod\": \"loadStateKeys\",\n                    \"flex\": 0.5,\n                    \"editable\": true\n                  },\n                  {\n                    \"field\": \"value\",\n                    \"headerName\": \"Value\",\n                    \"type\": \"freeSolo\",\n                    \"valueOptions\": [\n                      {\n                        \"label\": \"Agent Output (string)\",\n                        \"value\": \"$flow.output.content\"\n                      },\n                      {\n                        \"label\": \"Used Tools (array)\",\n                        \"value\": \"$flow.output.usedTools\"\n                      },\n                      {\n                        \"label\": \"First Tool Output (string)\",\n                        \"value\": \"$flow.output.usedTools[0].toolOutput\"\n                      },\n                      {\n                        \"label\": \"Source Documents (array)\",\n                        \"value\": \"$flow.output.sourceDocuments\"\n                      },\n                      {\n                        \"label\": \"Global variable (string)\",\n                        \"value\": \"$vars.<variable-name>\"\n                      },\n                      {\n                        \"label\": \"Input Question (string)\",\n                        \"value\": \"$flow.input\"\n                      },\n                      {\n                        \"label\": \"Session Id (string)\",\n                        \"value\": \"$flow.sessionId\"\n                      },\n                      {\n                        \"label\": \"Chat Id (string)\",\n                        \"value\": \"$flow.chatId\"\n                      },\n                      {\n                        \"label\": \"Chatflow Id (string)\",\n                        \"value\": \"$flow.chatflowId\"\n                      }\n                    ],\n                    \"editable\": true,\n                    \"flex\": 1\n                  }\n                ],\n                \"optional\": true,\n                \"additionalParams\": true\n              },\n              {\n                \"label\": \"Update State (Code)\",\n                \"name\": \"updateStateMemoryCode\",\n                \"type\": \"code\",\n                \"hint\": {\n                  \"label\": \"How to use\",\n                  \"value\": \"\\n1. Return the key value JSON object. For example: if you have the following State:\\n    ```json\\n    {\\n        \\\"user\\\": null\\n    }\\n    ```\\n\\n    You can update the \\\"user\\\" value by returning the following:\\n    ```js\\n    return {\\n        \\\"user\\\": \\\"john doe\\\"\\n    }\\n    ```\\n\\n2. If you want to use the agent's output as the value to update state, it is available as `$flow.output` with the following structure:\\n    ```json\\n    {\\n        \\\"content\\\": \\\"Hello! How can I assist you today?\\\",\\n        \\\"usedTools\\\": [\\n            {\\n                \\\"tool\\\": \\\"tool-name\\\",\\n                \\\"toolInput\\\": \\\"{foo: var}\\\",\\n                \\\"toolOutput\\\": \\\"This is the tool's output\\\"\\n            }\\n        ],\\n        \\\"sourceDocuments\\\": [\\n            {\\n                \\\"pageContent\\\": \\\"This is the page content\\\",\\n                \\\"metadata\\\": \\\"{foo: var}\\\"\\n            }\\n        ]\\n    }\\n    ```\\n\\n    For example, if the `toolOutput` is the value you want to update the state with, you can return the following:\\n    ```js\\n    return {\\n        \\\"user\\\": $flow.output.usedTools[0].toolOutput\\n    }\\n    ```\\n\\n3. You can also get default flow config, including the current \\\"state\\\":\\n    - `$flow.sessionId`\\n    - `$flow.chatId`\\n    - `$flow.chatflowId`\\n    - `$flow.input`\\n    - `$flow.state`\\n\\n4. You can get custom variables: `$vars.<variable-name>`\\n\\n\"\n                },\n                \"description\": \"This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. Must return an object representing the state\",\n                \"hideCodeExecute\": true,\n                \"codeExample\": \"const result = $flow.output;\\n\\n/* Suppose we have a custom State schema like this:\\n* {\\n    aggregate: {\\n        value: (x, y) => x.concat(y),\\n        default: () => []\\n    }\\n  }\\n*/\\n\\nreturn {\\n  aggregate: [result.content]\\n};\",\n                \"optional\": true,\n                \"additionalParams\": true\n              }\n            ],\n            \"id\": \"seqAgent_8-input-updateStateMemory-tabs\"\n          },\n          {\n            \"label\": \"Max Iterations\",\n            \"name\": \"maxIterations\",\n            \"type\": \"number\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"seqAgent_8-input-maxIterations-number\"\n          }\n        ],\n        \"inputAnchors\": [\n          {\n            \"label\": \"Tools\",\n            \"name\": \"tools\",\n            \"type\": \"Tool\",\n            \"list\": true,\n            \"optional\": true,\n            \"id\": \"seqAgent_8-input-tools-Tool\"\n          },\n          {\n            \"label\": \"Start | Agent | Condition | LLM | Tool Node\",\n            \"name\": \"sequentialNode\",\n            \"type\": \"Start | Agent | Condition | LLMNode | ToolNode\",\n            \"list\": true,\n            \"id\": \"seqAgent_8-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode\"\n          },\n          {\n            \"label\": \"Chat Model\",\n            \"name\": \"model\",\n            \"type\": \"BaseChatModel\",\n            \"optional\": true,\n            \"description\": \"Overwrite model to be used for this agent\",\n            \"id\": \"seqAgent_8-input-model-BaseChatModel\"\n          }\n        ],\n        \"inputs\": {\n          \"agentName\": \"gemma3\",\n          \"systemMessagePrompt\": \"You will edit and improve the previous response.\",\n          \"messageHistory\": \"\",\n          \"conversationHistorySelection\": \"all_messages\",\n          \"humanMessagePrompt\": \"\",\n          \"tools\": [],\n          \"sequentialNode\": [\n            \"{{seqAgent_4.data.instance}}\"\n          ],\n          \"model\": \"{{chatOllama_1.data.instance}}\",\n          \"interrupt\": \"\",\n          \"promptValues\": \"\",\n          \"approvalPrompt\": \"You are about to execute tool: {tools}. Ask if user want to proceed\",\n          \"approveButtonText\": \"Yes\",\n          \"rejectButtonText\": \"No\",\n          \"updateStateMemory\": \"updateStateMemoryUI\",\n          \"maxIterations\": \"\"\n        },\n        \"outputAnchors\": [\n          {\n            \"id\": \"seqAgent_8-output-seqAgent-Agent\",\n            \"name\": \"seqAgent\",\n            \"label\": \"Agent\",\n            \"description\": \"Agent that can execute tools\",\n            \"type\": \"Agent\"\n          }\n        ],\n        \"outputs\": {},\n        \"selected\": false\n      },\n      \"width\": 300,\n      \"height\": 879,\n      \"selected\": false,\n      \"positionAbsolute\": {\n        \"x\": 5167.261298040595,\n        \"y\": -793.2614467222759\n      },\n      \"dragging\": false\n    }\n  ],\n  \"edges\": [\n    {\n      \"source\": \"chatOllama_0\",\n      \"sourceHandle\": \"chatOllama_0-output-chatOllama-ChatOllama|ChatOllama|BaseChatModel|BaseLanguageModel|Runnable\",\n      \"target\": \"seqStart_0\",\n      \"targetHandle\": \"seqStart_0-input-model-BaseChatModel\",\n      \"type\": \"buttonedge\",\n      \"id\": \"chatOllama_0-chatOllama_0-output-chatOllama-ChatOllama|ChatOllama|BaseChatModel|BaseLanguageModel|Runnable-seqStart_0-seqStart_0-input-model-BaseChatModel\"\n    },\n    {\n      \"source\": \"postgresAgentMemory_0\",\n      \"sourceHandle\": \"postgresAgentMemory_0-output-postgresAgentMemory-AgentMemory|BaseCheckpointSaver\",\n      \"target\": \"seqStart_0\",\n      \"targetHandle\": \"seqStart_0-input-agentMemory-BaseCheckpointSaver\",\n      \"type\": \"buttonedge\",\n      \"id\": \"postgresAgentMemory_0-postgresAgentMemory_0-output-postgresAgentMemory-AgentMemory|BaseCheckpointSaver-seqStart_0-seqStart_0-input-agentMemory-BaseCheckpointSaver\"\n    },\n    {\n      \"source\": \"documentStoreVS_0\",\n      \"sourceHandle\": \"documentStoreVS_0-output-retriever-BaseRetriever\",\n      \"target\": \"retrieverTool_0\",\n      \"targetHandle\": \"retrieverTool_0-input-retriever-BaseRetriever\",\n      \"type\": \"buttonedge\",\n      \"id\": \"documentStoreVS_0-documentStoreVS_0-output-retriever-BaseRetriever-retrieverTool_0-retrieverTool_0-input-retriever-BaseRetriever\"\n    },\n    {\n      \"source\": \"retrieverTool_0\",\n      \"sourceHandle\": \"retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable\",\n      \"target\": \"seqAgent_0\",\n      \"targetHandle\": \"seqAgent_0-input-tools-Tool\",\n      \"type\": \"buttonedge\",\n      \"id\": \"retrieverTool_0-retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable-seqAgent_0-seqAgent_0-input-tools-Tool\"\n    },\n    {\n      \"source\": \"seqAgent_0\",\n      \"sourceHandle\": \"seqAgent_0-output-seqAgent-Agent\",\n      \"target\": \"seqAgent_1\",\n      \"targetHandle\": \"seqAgent_1-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode\",\n      \"type\": \"buttonedge\",\n      \"id\": \"seqAgent_0-seqAgent_0-output-seqAgent-Agent-seqAgent_1-seqAgent_1-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode\"\n    },\n    {\n      \"source\": \"seqAgent_3\",\n      \"sourceHandle\": \"seqAgent_3-output-seqAgent-Agent\",\n      \"target\": \"seqAgent_4\",\n      \"targetHandle\": \"seqAgent_4-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode\",\n      \"type\": \"buttonedge\",\n      \"id\": \"seqAgent_3-seqAgent_3-output-seqAgent-Agent-seqAgent_4-seqAgent_4-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode\"\n    },\n    {\n      \"source\": \"seqAgent_6\",\n      \"sourceHandle\": \"seqAgent_6-output-seqAgent-Agent\",\n      \"target\": \"seqAgent_7\",\n      \"targetHandle\": \"seqAgent_7-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode\",\n      \"type\": \"buttonedge\",\n      \"id\": \"seqAgent_6-seqAgent_6-output-seqAgent-Agent-seqAgent_7-seqAgent_7-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode\"\n    },\n    {\n      \"source\": \"chatOllama_2\",\n      \"sourceHandle\": \"chatOllama_2-output-chatOllama-ChatOllama|ChatOllama|BaseChatModel|BaseLanguageModel|Runnable\",\n      \"target\": \"seqAgent_1\",\n      \"targetHandle\": \"seqAgent_1-input-model-BaseChatModel\",\n      \"type\": \"buttonedge\",\n      \"id\": \"chatOllama_2-chatOllama_2-output-chatOllama-ChatOllama|ChatOllama|BaseChatModel|BaseLanguageModel|Runnable-seqAgent_1-seqAgent_1-input-model-BaseChatModel\"\n    },\n    {\n      \"source\": \"chatOllama_1\",\n      \"sourceHandle\": \"chatOllama_1-output-chatOllama-ChatOllama|ChatOllama|BaseChatModel|BaseLanguageModel|Runnable\",\n      \"target\": \"seqAgent_2\",\n      \"targetHandle\": \"seqAgent_2-input-model-BaseChatModel\",\n      \"type\": \"buttonedge\",\n      \"id\": \"chatOllama_1-chatOllama_1-output-chatOllama-ChatOllama|ChatOllama|BaseChatModel|BaseLanguageModel|Runnable-seqAgent_2-seqAgent_2-input-model-BaseChatModel\"\n    },\n    {\n      \"source\": \"retrieverTool_0\",\n      \"sourceHandle\": \"retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable\",\n      \"target\": \"seqAgent_1\",\n      \"targetHandle\": \"seqAgent_1-input-tools-Tool\",\n      \"type\": \"buttonedge\",\n      \"id\": \"retrieverTool_0-retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable-seqAgent_1-seqAgent_1-input-tools-Tool\"\n    },\n    {\n      \"source\": \"retrieverTool_0\",\n      \"sourceHandle\": \"retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable\",\n      \"target\": \"seqAgent_3\",\n      \"targetHandle\": \"seqAgent_3-input-tools-Tool\",\n      \"type\": \"buttonedge\",\n      \"id\": \"retrieverTool_0-retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable-seqAgent_3-seqAgent_3-input-tools-Tool\"\n    },\n    {\n      \"source\": \"retrieverTool_0\",\n      \"sourceHandle\": \"retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable\",\n      \"target\": \"seqAgent_4\",\n      \"targetHandle\": \"seqAgent_4-input-tools-Tool\",\n      \"type\": \"buttonedge\",\n      \"id\": \"retrieverTool_0-retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable-seqAgent_4-seqAgent_4-input-tools-Tool\"\n    },\n    {\n      \"source\": \"retrieverTool_0\",\n      \"sourceHandle\": \"retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable\",\n      \"target\": \"seqAgent_6\",\n      \"targetHandle\": \"seqAgent_6-input-tools-Tool\",\n      \"type\": \"buttonedge\",\n      \"id\": \"retrieverTool_0-retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable-seqAgent_6-seqAgent_6-input-tools-Tool\"\n    },\n    {\n      \"source\": \"retrieverTool_0\",\n      \"sourceHandle\": \"retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable\",\n      \"target\": \"seqAgent_7\",\n      \"targetHandle\": \"seqAgent_7-input-tools-Tool\",\n      \"type\": \"buttonedge\",\n      \"id\": \"retrieverTool_0-retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable-seqAgent_7-seqAgent_7-input-tools-Tool\"\n    },\n    {\n      \"source\": \"chatOllama_2\",\n      \"sourceHandle\": \"chatOllama_2-output-chatOllama-ChatOllama|ChatOllama|BaseChatModel|BaseLanguageModel|Runnable\",\n      \"target\": \"seqAgent_4\",\n      \"targetHandle\": \"seqAgent_4-input-model-BaseChatModel\",\n      \"type\": \"buttonedge\",\n      \"id\": \"chatOllama_2-chatOllama_2-output-chatOllama-ChatOllama|ChatOllama|BaseChatModel|BaseLanguageModel|Runnable-seqAgent_4-seqAgent_4-input-model-BaseChatModel\"\n    },\n    {\n      \"source\": \"chatOllama_2\",\n      \"sourceHandle\": \"chatOllama_2-output-chatOllama-ChatOllama|ChatOllama|BaseChatModel|BaseLanguageModel|Runnable\",\n      \"target\": \"seqAgent_7\",\n      \"targetHandle\": \"seqAgent_7-input-model-BaseChatModel\",\n      \"type\": \"buttonedge\",\n      \"id\": \"chatOllama_2-chatOllama_2-output-chatOllama-ChatOllama|ChatOllama|BaseChatModel|BaseLanguageModel|Runnable-seqAgent_7-seqAgent_7-input-model-BaseChatModel\"\n    },\n    {\n      \"source\": \"chatOllama_1\",\n      \"sourceHandle\": \"chatOllama_1-output-chatOllama-ChatOllama|ChatOllama|BaseChatModel|BaseLanguageModel|Runnable\",\n      \"target\": \"seqAgent_5\",\n      \"targetHandle\": \"seqAgent_5-input-model-BaseChatModel\",\n      \"type\": \"buttonedge\",\n      \"id\": \"chatOllama_1-chatOllama_1-output-chatOllama-ChatOllama|ChatOllama|BaseChatModel|BaseLanguageModel|Runnable-seqAgent_5-seqAgent_5-input-model-BaseChatModel\"\n    },\n    {\n      \"source\": \"chatOllama_1\",\n      \"sourceHandle\": \"chatOllama_1-output-chatOllama-ChatOllama|ChatOllama|BaseChatModel|BaseLanguageModel|Runnable\",\n      \"target\": \"seqAgent_8\",\n      \"targetHandle\": \"seqAgent_8-input-model-BaseChatModel\",\n      \"type\": \"buttonedge\",\n      \"id\": \"chatOllama_1-chatOllama_1-output-chatOllama-ChatOllama|ChatOllama|BaseChatModel|BaseLanguageModel|Runnable-seqAgent_8-seqAgent_8-input-model-BaseChatModel\"\n    },\n    {\n      \"source\": \"seqAgent_2\",\n      \"sourceHandle\": \"seqAgent_2-output-seqAgent-Agent\",\n      \"target\": \"seqAgent_0\",\n      \"targetHandle\": \"seqAgent_0-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode\",\n      \"type\": \"buttonedge\",\n      \"id\": \"seqAgent_2-seqAgent_2-output-seqAgent-Agent-seqAgent_0-seqAgent_0-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode\"\n    },\n    {\n      \"source\": \"seqStart_0\",\n      \"sourceHandle\": \"seqStart_0-output-seqStart-Start\",\n      \"target\": \"seqAgent_2\",\n      \"targetHandle\": \"seqAgent_2-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode\",\n      \"type\": \"buttonedge\",\n      \"id\": \"seqStart_0-seqStart_0-output-seqStart-Start-seqAgent_2-seqAgent_2-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode\"\n    },\n    {\n      \"source\": \"seqAgent_1\",\n      \"sourceHandle\": \"seqAgent_1-output-seqAgent-Agent\",\n      \"target\": \"seqAgent_5\",\n      \"targetHandle\": \"seqAgent_5-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode\",\n      \"type\": \"buttonedge\",\n      \"id\": \"seqAgent_1-seqAgent_1-output-seqAgent-Agent-seqAgent_5-seqAgent_5-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode\"\n    },\n    {\n      \"source\": \"seqAgent_5\",\n      \"sourceHandle\": \"seqAgent_5-output-seqAgent-Agent\",\n      \"target\": \"seqAgent_3\",\n      \"targetHandle\": \"seqAgent_3-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode\",\n      \"type\": \"buttonedge\",\n      \"id\": \"seqAgent_5-seqAgent_5-output-seqAgent-Agent-seqAgent_3-seqAgent_3-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode\"\n    },\n    {\n      \"source\": \"seqAgent_4\",\n      \"sourceHandle\": \"seqAgent_4-output-seqAgent-Agent\",\n      \"target\": \"seqAgent_8\",\n      \"targetHandle\": \"seqAgent_8-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode\",\n      \"type\": \"buttonedge\",\n      \"id\": \"seqAgent_4-seqAgent_4-output-seqAgent-Agent-seqAgent_8-seqAgent_8-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode\"\n    },\n    {\n      \"source\": \"seqAgent_8\",\n      \"sourceHandle\": \"seqAgent_8-output-seqAgent-Agent\",\n      \"target\": \"seqAgent_6\",\n      \"targetHandle\": \"seqAgent_6-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode\",\n      \"type\": \"buttonedge\",\n      \"id\": \"seqAgent_8-seqAgent_8-output-seqAgent-Agent-seqAgent_6-seqAgent_6-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode\"\n    },\n    {\n      \"source\": \"seqAgent_7\",\n      \"sourceHandle\": \"seqAgent_7-output-seqAgent-Agent\",\n      \"target\": \"seqEnd_0\",\n      \"targetHandle\": \"seqEnd_0-input-sequentialNode-Agent | Condition | LLMNode | ToolNode\",\n      \"type\": \"buttonedge\",\n      \"id\": \"seqAgent_7-seqAgent_7-output-seqAgent-Agent-seqEnd_0-seqEnd_0-input-sequentialNode-Agent | Condition | LLMNode | ToolNode\"\n    }\n  ]\n}",
      "type": "MULTIAGENT"
    }
  ],
  "Variable": [],
  "Assistant": [
    {
      "id": "4adf6455-dad5-47b5-96c4-b8453b35ea28",
      "details": "{\"name\":\"probe\"}",
      "credential": "6b2fd163-28f5-4af7-9fbd-dd6836c221c4",
      "iconSrc": null
    }
  ]
}